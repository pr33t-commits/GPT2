{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3TtRLIuJqEl"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This is a template for a clean, first principles implementation of GPT-2 in PyTorch. This is an accompaniment to [my video tutorial on implementing GPT-2](https://neelnanda.io/transformer-tutorial-2). If you want to properly understand how to implement GPT-2, you'll need to do it yourself! **I recommend filling out this template *as* you watch the video, and seeing how far you can get with each section before watching me do it**. Each section comes with tests, so you can check that you got it right. You can see [a solution notebook here](https://www.neelnanda.io/transformer-solution) - use it if you get stuck, but make an attempt first, and no copying and pasting!\n",
        "\n",
        "There's a [template version of this notebook here](https://neelnanda.io/transformer-template), go and fill in the blanks (no copying and pasting!) and see if you can pass the tests.\n",
        "\n",
        "If you enjoyed this, I expect you'd enjoy learning more about what's actually going on inside these models and how to reverse engineer them! This is a fascinating young research field, with a lot of low-hanging fruit and open problems! **I recommend starting with my post [Concrete Steps for Getting Started in Mechanistic Interpretability](https://www.neelnanda.io/mechanistic-interpretability/getting-started).**\n",
        "\n",
        "This notebook was written to accompany my [TransformerLens library](https://github.com/neelnanda-io/TransformerLens) for doing mechanistic interpretability research on GPT-2 style language models, and is a clean implementation of the underlying transformer architecture in the library. (This notebook is based off of an earlier version called EasyTransformer)\n",
        "\n",
        "Further Resources:\n",
        "* [A Comprehensive Mechanistic Interpretability Explainer & Glossary](https://www.neelnanda.io/glossary)\n",
        "    * Expecially [the transformers section](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=pndoEIqJ6GPvC1yENQkEfZYR)\n",
        "* [200 Concrete Open Problems in Mechanistic Interpretability](https://www.neelnanda.io/concrete-open-problems)\n",
        "* My [TransformerLens library](https://github.com/neelnanda-io/TransformerLens) for doing mechanistic interpretability research on GPT-2 style language models.\n",
        "* My walkthrough of [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html), for a deeper dive into how to think about transformers:.\n",
        "\n",
        "Check out these other intros to transformers for another perspective:\n",
        "* Jay Alammar's [illustrated transformer](https://jalammar.github.io/illustrated-transformer/)\n",
        "* [Andrej Karpathy's MinGPT](https://github.com/karpathy/minGPT)\n",
        "\n",
        "**Sharing Guidelines:** This tutorial is still a bit of a work in progress! I think it's usable, but please don't post it anywhere publicly without checking with me first! Sharing with friends is fine.\n",
        "\n",
        "If you've found this useful, I'd love to hear about it! Positive and negative feedback also very welcome. You can reach me via [email](mailto:neelnanda27@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9bN56U1JqEw"
      },
      "source": [
        "## Instructions\n",
        "* No need to read the Setup Section\n",
        "* Go to runtime > Change Runtime Type and set it to use a GPU\n",
        "* Read and run notebook up until the start of the section \"Actual Code!\". Then go to the template notebook and try coding up the model yourself!\n",
        "    * Bonus points for doing that without reading the solutions, and before I do it in the video!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSWYYF36JqEx"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kksFvS9vJqEz",
        "outputId": "33d4d912-0bf0-4586-d7a7-afc7b3544810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
            "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git (to revision clean-transformer-demo) to /tmp/pip-req-build-7yiw8oo7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /tmp/pip-req-build-7yiw8oo7\n",
            "  Running command git checkout -b clean-transformer-demo --track origin/clean-transformer-demo\n",
            "  Switched to a new branch 'clean-transformer-demo'\n",
            "  Branch 'clean-transformer-demo' set up to track remote branch 'clean-transformer-demo' from 'origin'.\n",
            "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 1f25219e631aeb478d17075d47274db32c874e88\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (2.14.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (0.20.1)\n",
            "Collecting fancy_einsum (from easy_transformer==0.1.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets->easy_transformer==0.1.0) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->easy_transformer==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->easy_transformer==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->easy_transformer==0.1.0) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easy_transformer==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->easy_transformer==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->easy_transformer==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->easy_transformer==0.1.0) (0.5.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (2.11.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (1.3.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (1.20.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->easy_transformer==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->easy_transformer==0.1.0) (1.1.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->easy_transformer==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->easy_transformer==0.1.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->easy_transformer==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->easy_transformer==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->easy_transformer==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->easy_transformer==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->easy_transformer==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->easy_transformer==0.1.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easy_transformer==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->easy_transformer==0.1.0) (5.0.2)\n",
            "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m757.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: easy_transformer\n",
            "  Building wheel for easy_transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easy_transformer: filename=easy_transformer-0.1.0-py3-none-any.whl size=55601 sha256=1bd53b6891e0db124fb873c73d8b9acbe26375d11f3e868a505cae9109d319aa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kz6h_xqq/wheels/bf/56/b1/e601264be47cea8ab7d082bfd13e38f6a652e3790a0a225496\n",
            "Successfully built easy_transformer\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fancy_einsum, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easy_transformer\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easy_transformer-0.1.0 fancy_einsum-0.0.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "  \u001b[1m\u001b[33m                            DEPRECATION WARNING                            \u001b[m\n",
            "\n",
            "    \u001b[1m\u001b[4m Node.js 16.x is no longer actively supported!\u001b[m\n",
            "\n",
            "  \u001b[1mYou will not receive security or critical stability updates\u001b[m for this version.\n",
            "\n",
            "  You should migrate to a supported version of Node.js as soon as possible.\n",
            "  Use the installation script that corresponds to the version of Node.js you\n",
            "  wish to install. e.g.\n",
            "  \n",
            "   * \u001b[31mhttps://deb.nodesource.com/setup_16.x — Node.js 16 \"Gallium\" \u001b[1m(deprecated)\u001b[m\n",
            "   * \u001b[32mhttps://deb.nodesource.com/setup_18.x — Node.js 18 \"Hydrogen\" (Maintenance)\u001b[m\n",
            "   * \u001b[31mhttps://deb.nodesource.com/setup_19.x — Node.js 19 \"Nineteen\" \u001b[1m(deprecated)\u001b[m\n",
            "   * \u001b[1m\u001b[32mhttps://deb.nodesource.com/setup_20.x — Node.js 20 LTS \"Iron\" (recommended)\u001b[m\n",
            "   * \u001b[32mhttps://deb.nodesource.com/setup_21.x — Node.js 21 \"Iron\" (current)\u001b[m\n",
            "   \n",
            "\n",
            "\n",
            "  Please see \u001b[1mhttps://github.com/nodejs/Release\u001b[m for details about which\n",
            "  version may be appropriate for you.\n",
            "\n",
            "  The \u001b[32m\u001b[1mNodeSource\u001b[m Node.js distributions repository contains\n",
            "  information both about supported versions of Node.js and supported Linux\n",
            "  distributions. To learn more about usage, see the repository:\n",
            "   \u001b[4m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "Continuing in 10 seconds ...\n",
            "\n",
            "\u001b[38;5;79m2025-06-17 04:21:00 - Installing pre-requisites\u001b[0m\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,778 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,250 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,986 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,044 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,748 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,557 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,296 kB]\n",
            "Fetched 23.1 MB in 3s (8,630 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.3).\n",
            "gnupg set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  apt-transport-https\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 1,510 B of archives.\n",
            "After this operation, 170 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 apt-transport-https all 2.4.14 [1,510 B]\n",
            "Fetched 1,510 B in 0s (6,538 B/s)\n",
            "Selecting previously unselected package apt-transport-https.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../apt-transport-https_2.4.14_all.deb ...\n",
            "Unpacking apt-transport-https (2.4.14) ...\n",
            "Setting up apt-transport-https (2.4.14) ...\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://deb.nodesource.com/node_16.x nodistro InRelease [12.1 kB]\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Get:8 https://deb.nodesource.com/node_16.x nodistro/main amd64 Packages [7,253 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 19.4 kB in 1s (15.2 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\u001b[1;32m2025-06-17 04:21:17 - Repository configured successfully. To install Node.js, run: apt-get install nodejs -y\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 27.5 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x nodistro/main amd64 nodejs amd64 16.20.2-1nodesource1 [27.5 MB]\n",
            "Fetched 27.5 MB in 1s (53.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 126115 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.2-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.2-1nodesource1) ...\n",
            "Setting up nodejs (16.20.2-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-1d777bcj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-1d777bcj\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 582d85ff708947e72b35cfcca05641332b44f5f5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (2.14.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (2.2.2)\n",
            "Collecting typeguard~=2.0 (from PySvelte==1.0.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets->PySvelte==1.0.0) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->PySvelte==1.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->PySvelte==1.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->PySvelte==1.0.0) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->PySvelte==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->PySvelte==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->PySvelte==1.0.0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->PySvelte==1.0.0) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->PySvelte==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->PySvelte==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->PySvelte==1.0.0) (3.0.2)\n",
            "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: PySvelte\n",
            "  Building wheel for PySvelte (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySvelte: filename=PySvelte-1.0.0-py3-none-any.whl size=158316 sha256=918a4c1e2ccc1d4608bfaf1f9ba73fe862d18e49ceeec4e9c6ba893c4c64ec4b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wa99xvs6/wheels/40/95/dc/bd1a06dc2ca83b8d30d7b25b683b2e3833dc1f7f1e90a33273\n",
            "Successfully built PySvelte\n",
            "Installing collected packages: typeguard, PySvelte\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.3\n",
            "    Uninstalling typeguard-4.4.3:\n",
            "      Successfully uninstalled typeguard-4.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PySvelte-1.0.0 typeguard-2.13.3\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.11/dist-packages (0.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  print(\"Running as a Colab notebook\")\n",
        "  %pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
        "  # Install another version of node that makes PySvelte work way faster\n",
        "  !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "  %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "  %pip install fancy_einsum\n",
        "  %pip install einops\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print(\"Running as a Jupyter notebook - intended for development only!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PSb54GoqJqE3"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "from dataclasses import dataclass\n",
        "from easy_transformer import EasyTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
        "import tqdm.auto as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "0c8181dd8ff94d11b0ed510e8931aae5",
            "c8cb632aad3b4eb8ac41c91074f696f7",
            "d04115e9a80040b59a130d03a8bd57d3",
            "c157f651b5ee4f709ae400dd8e92bfd4",
            "8abde9b4211643e6910e8ae13406c7ba",
            "96dffe98d29840338b5a7d98c571b6a6",
            "f1a240fa6b994c12b33b5fbd76251c31",
            "dc2ef514af354f75a5382186dabb46ce",
            "d63713089ed04338a9407eef66a0f9b7",
            "dd3287e3d3e34fdbb8fdf9b65ad5eb30",
            "9d79ee77c9f14f6f9caa410fa6693afc",
            "82af410359ab4ca0a579bf88843c8812",
            "0d65ae05918245e59dbcdba5c6479461",
            "99e8dba4d8d2452fa51ef6d670e6c70c",
            "92e5e34dc61b4d7eb642773f43ba4a56",
            "7982b8da80dc45a7b8c29268a1cb7625",
            "81b928796ac04afaae5bcf51b6319b3e",
            "5f7d679b4541423b9684805e3be605ef",
            "38d1befb1eb341919adc3948981863e3",
            "0a9cd3f50a83406a931c9df1bf98b330",
            "ada788302fd4444fb8b437d4b71ef099",
            "21c518e0957149a798148f1e889884fe",
            "9037d7e8aaa84b59a626bc40fabef33a",
            "4647c5d1f62f4b7da798e077dfd13d75",
            "4043b6e2f54b4292adca53fac33abbd1",
            "8d25a786e0af4af4a24f4fa048015b74",
            "15a92c914d5a4c66b5b849463b7576ba",
            "a44b93d7f5334a6b8f539f21757d6bac",
            "e32d34b05d7041a58391e1dde7d3fd0e",
            "001d71dad8ad48e686a09e232a13d156",
            "ddeb9f11ba96430891b160a0c9a49e77",
            "b1591ed31c544bdc8afd75135b22095a",
            "0d7a943e32fb4fba879d792687fc28d9",
            "b8cdea6200674bdd9c90a5aab0b1f1c5",
            "2168fb05c4f0427099f1ca74cd727ec4",
            "48f6924dfab2446cbaffc78cbe3da60e",
            "d450ca4ebed3473680101453ce26e6c2",
            "b4c305614fff46e3ac7151103819e847",
            "df3672a6d20c402abede0c01e7ef4267",
            "31e06f4a3e674697ab7256d86e6f0bcd",
            "8e5b1119703b4fd18aa7742b98f35c75",
            "de54c2a350634e7797d7a11f8f9a1e66",
            "af015914107f424b839bee44f3341f66",
            "44d8e490340647aa96ff0d9bcae9ec9c",
            "66f3c15dd37d4882938d2e641b49671e",
            "828841e6cf924be7b68f2901bd2a9ec6",
            "16748686b196440c923a0bf835542567",
            "692e96f67cdb4cedaef4ff264a9632b8",
            "f85d9c679da846be8c04bc125e5df1e8",
            "77536c03f4cd409d982e54fc3d3f04e1",
            "e26fee4acb524ce1ab32d7421020e84f",
            "545b59cbdbc24102b8d36ece9a999294",
            "4fb4790f80144af897db2a3c7a123187",
            "a645bfd250324dbaa48ea5cef5258dec",
            "0490656a43b545419ce6f52c493c4ac6",
            "df7c1dac2f91454e8fcc6299c8e63fb9",
            "7c638959ba994fefa69407027f35742a",
            "bf61f64f641842d893f21da7ff5daae1",
            "b8ac496f62124c7f9f2453431975403d",
            "17cc2d67f572411f832e5e4b9d553998",
            "6f4f66ef3dd24a3b818b5a5057a34026",
            "9ef1d83004834764a7d17cd78b3f3e52",
            "2a094e49e62a4025bdf15e6aeceaba2b",
            "60c4f78b529341f1b045ab03750b550b",
            "0dcae6d0e2384ee28bb44dd6a6d78073",
            "f176e9c1f7d4490daffaeed9a94e74a7",
            "58e0eaf64a9c4b098c309f01c724698e",
            "0197409cd3b549a49264b7c23ec69467",
            "60274d0c19a645dbbb4571820d07b129",
            "9771ba5899ec4732b2f09fef379bb41e",
            "e182ea65c6ea480ba4f16fd14aee4485",
            "8aa856f617c541198101a5347d6a6202",
            "ee6c86eaea0f4e20826d326e94af5a06",
            "51084c124c1a4308911c6a0d151d752d",
            "d6709981f786473f8f449419304650cd",
            "2aa1e1c55f3b4a3fa0cd8b48f7f0c504",
            "100f8502551d4656a1c404857f0b8b2f"
          ]
        },
        "id": "csPoSWeUJqE5",
        "outputId": "0a888cb6-df33-4f7b-9081-5a63662e2135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c8181dd8ff94d11b0ed510e8931aae5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82af410359ab4ca0a579bf88843c8812"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9037d7e8aaa84b59a626bc40fabef33a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8cdea6200674bdd9c90a5aab0b1f1c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66f3c15dd37d4882938d2e641b49671e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df7c1dac2f91454e8fcc6299c8e63fb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58e0eaf64a9c4b098c309f01c724698e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cpu\n",
            "Finished loading pretrained model gpt2-small into EasyTransformer!\n"
          ]
        }
      ],
      "source": [
        "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noj3I8thJqE7"
      },
      "source": [
        "# Understanding Inputs & Outputs of a Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v41z1o1gJqE9"
      },
      "source": [
        "## What is the point of a transformer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PdzyxW_JqE-"
      },
      "source": [
        "**Transformers exist to model text!**\n",
        "\n",
        "We're going to focus GPT-2 style transformers. Key feature: They generate text! You feed in language, and the model generates a probability distn over tokens. And you can repeatedly sample from this to generate text!\n",
        "\n",
        "### How is the model trained?\n",
        "\n",
        "You give it a bunch of text, and train it to predict the next token.\n",
        "\n",
        "Importantly, if you give a model 100 tokens in a sequence, it predicts the next token for *each* prefix, ie it produces 100 predictions. This is kinda weird but it's much easier to make one that does this. And it also makes training more efficient, because you can 100 bits of feedback rather than just one.\n",
        "\n",
        "#### Objection: Isn't this trivial for the first 99?\n",
        "\n",
        "No! We make the transformer have *causal attention*. The core thing is that it can only move information forwards in the sequence. The prediction of what comes after token 50 is only a function of the first 50 tokens, *not* of token 51. (Jargon: *autoregressive*)\n",
        "\n",
        "### Key takeaway:\n",
        "\n",
        "Transformers are *sequence modelling engines*. It does the same processing in parallel at each sequence position, can move information between positions with attention, and conceptually can take a sequence of arbitrary length (not actually true, see later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x1_8pFqJqFA"
      },
      "source": [
        "## Tokens - Transformer Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNCmi28aJqFA"
      },
      "source": [
        "Core point: Input is language (ie a sequence of characters, strings, etc)\n",
        "\n",
        "### How do we convert language to vectors?\n",
        "\n",
        "ML models take in vectors, not weird shit like language - how do we convert?\n",
        "\n",
        "#### Idea: integers to vectors\n",
        "\n",
        "We basically make a lookup table. Called an embedding.\n",
        "\n",
        "Jargon: **One-hot encoding** We map eg numbers from 1 to 100, to a 100-dim vector, with a 1 in the kth position, 0 everywhere else. Key intuition is that one-hot encodings let you think about each integer independently - useful when integers = labels.\n",
        "\n",
        "Dimensions = things that vary independently. Each input has its own dimension, so each input can be thought of independently, we don't bake in any relation.\n",
        "\n",
        "Lookup tables <=> Multiply a fixed matrix by the one-hot encoded vector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcQT-8yqJqFB"
      },
      "source": [
        "### Tokens: Language to sequence of integers\n",
        "\n",
        "Core idea: We need a model that can deal with arbitrary text. We want to convert this into integers, *and* we want these integers to be in a bounded range.\n",
        "\n",
        "**Idea:** Form a vocabulary!\n",
        "\n",
        "**Idea 1:** Get a dictionary!\n",
        "\n",
        "**Problem:** It can't cope with arbitrary text (eg URLs, punctuation, etc) Can't cope with mispellings.\n",
        "\n",
        "**Idea 2:** Vocab = 256 ASCII characters. Fixed vocab size, can do arbitrary text, etc.\n",
        "\n",
        "**Problem:** Loses structure of language - some sequences of characters are more meaningful than others.\n",
        "\n",
        "Eg \"language\" is a lot more meaningful than \"hjksdfiu\" - we want the first to be a single token, second to not be. It's a more efficient use of our vocab.\n",
        "\n",
        "#### What Actually Happens?\n",
        "\n",
        "This super cursed thing called Byte-Pair Encodings\n",
        "\n",
        "Ġ ~ means begins with a space, tokens with a leading space vs not are different.\n",
        "\n",
        "We begin with the 256 ASCII characters as our tokens, and then find the most common pair of tokens, and merge that into a new token. Eg \" t\" is the most common pair, so it's our next token! Repeat 50000 times..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGt1QBW8JqFC",
        "outputId": "324d4aea-e546-472d-b849-3df0c11e90d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
            "\n",
            "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
            "\n",
            "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sorted_vocab = sorted(list(reference_gpt2.tokenizer.vocab.items()), key=lambda n:n[1])\n",
        "print(sorted_vocab[:20])\n",
        "print()\n",
        "print(sorted_vocab[250:270])\n",
        "print()\n",
        "print(sorted_vocab[990:1010])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCyA2RLUJqFD"
      },
      "source": [
        "Gets to weird esoteric shit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8dqAEFiJqFD",
        "outputId": "e7452e94-e598-4c1b-bb2e-046ec1dcd4db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Revolution', 50237),\n",
              " ('Ġsnipers', 50238),\n",
              " ('Ġreverted', 50239),\n",
              " ('Ġconglomerate', 50240),\n",
              " ('Terry', 50241),\n",
              " ('794', 50242),\n",
              " ('Ġharsher', 50243),\n",
              " ('Ġdesolate', 50244),\n",
              " ('ĠHitman', 50245),\n",
              " ('Commission', 50246),\n",
              " ('Ġ(/', 50247),\n",
              " ('âĢ¦.\"', 50248),\n",
              " ('Compar', 50249),\n",
              " ('Ġamplification', 50250),\n",
              " ('ominated', 50251),\n",
              " ('Ġregress', 50252),\n",
              " ('ĠCollider', 50253),\n",
              " ('Ġinformants', 50254),\n",
              " ('Ġgazed', 50255),\n",
              " ('<|endoftext|>', 50256)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sorted_vocab[-20:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qps-lcFAJqFD"
      },
      "source": [
        "Use the `to_tokens` method to convert text to numbers\n",
        "\n",
        "Prepends with a special token to give attention a resting position, disable with `prepend_bos=False`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6rwSS5eJqFE",
        "outputId": "c98825e8-72fd-4b02-d677-f220471cf517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256, 15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,\n",
            "          6067,     0]])\n",
            "tensor([[15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,  6067,\n",
            "             0]])\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\"))\n",
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\", prepend_bos=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajKxQEc6JqFE"
      },
      "source": [
        "### Rant: Tokenization is a Headache\n",
        "\n",
        "Whether a word begins with a capital or space matters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv54jv7cJqFE",
        "outputId": "7228372c-717b-44f1-96de-648674f42947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', 'R', 'alph']\n",
            "['<|endoftext|>', ' Ralph']\n",
            "['<|endoftext|>', ' r', 'alph']\n",
            "['<|endoftext|>', 'ral', 'ph']\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_str_tokens(\"Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\"ralph\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAiV60WpJqFF"
      },
      "source": [
        "Arithmetic is a total mess: Length is inconsistent, common numbers bundle together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpSbsZSXJqFF",
        "outputId": "51f2a65e-edca-4887-e9d7-23143384993b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<|endoftext|>',\n",
              " '568',\n",
              " '73',\n",
              " '+',\n",
              " '318',\n",
              " '46',\n",
              " '23',\n",
              " '=',\n",
              " '123',\n",
              " '45',\n",
              " '67',\n",
              " '89',\n",
              " '-',\n",
              " '1',\n",
              " '000000',\n",
              " '000']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "reference_gpt2.to_str_tokens(\"56873+3184623=123456789-1000000000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc-5fvBCJqFF"
      },
      "source": [
        "### Key Takeaway:\n",
        "\n",
        "* We learn a dictionary of vocab of tokens (sub-words).\n",
        "\n",
        "* We (approx) losslessly convert language to integers via tokenizing it.\n",
        "\n",
        "* We convert integers to vectors via a lookup table.\n",
        "\n",
        "* Note: input to the transformer is a sequence of *tokens* (ie integers), not vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRfELnJrJqFG"
      },
      "source": [
        "## Logits - Transformer Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5rwvvM6JqFG"
      },
      "source": [
        "**Goal:** Probability distribution over next tokens. (for every *prefix* of the sequence - given n tokens, we make n next token predictions)\n",
        "\n",
        "**Problem:** How to convert a vector to a probability distribution?\n",
        "\n",
        "**Answer:** Use a softmax ($x_i \\to \\frac{e^{x_i}}{\\sum e^{x_j}}$), exponential makes everything positive, normalization makes it add to one.\n",
        "\n",
        "So the model outputs a tensor of logits, one vector of size $d_{vocab}$ for each input token.\n",
        "\n",
        "We can use this to generate things!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idhuwvQdJqFG"
      },
      "source": [
        "## Generation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MinDfaRsJqFH"
      },
      "source": [
        "**Step 1:** Convert text to tokens\n",
        "\n",
        "Shape = batch x position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20G1EUN3JqFH",
        "outputId": "6328e088-ba8d-4de4-afea-464a7be510f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0]])\n",
            "torch.Size([1, 35])\n",
            "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
          ]
        }
      ],
      "source": [
        "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
        "tokens = reference_gpt2.to_tokens(reference_text)\n",
        "print(tokens)\n",
        "print(tokens.shape)\n",
        "print(reference_gpt2.to_str_tokens(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwsLYcTMJqFI"
      },
      "source": [
        "**Step 2:** Map tokens to logits\n",
        "\n",
        "(run_with_cache means cache all intermediate activations, not important right now)\n",
        "\n",
        "shape = batch x position x d_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAegxhztJqFJ",
        "outputId": "bb351ae6-fd06-4ba3-8ed1-9d5b9ed9c0d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "# tokens = tokens.cuda()\n",
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujuBQgukJqFK"
      },
      "source": [
        "**Step 3:** Convert the logits to a distribution with a softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqmwsg9VJqFK",
        "outputId": "4cc4e20d-b13e-438c-a119-3d3e358015a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n",
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "log_probs = logits.log_softmax(dim=-1)\n",
        "probs = logits.log_softmax(dim=-1)\n",
        "print(log_probs.shape)\n",
        "print(probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT7DlPh4JqFK"
      },
      "source": [
        "**Bonus step:** What is the most likely next token at each position?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HfrSM_gJqFL",
        "outputId": "08699a82-32a1-42e4-ce19-0159b9c2ccf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<|endoftext|>', '\\n'),\n",
              " ('I', \"'m\"),\n",
              " (' am', ' a'),\n",
              " (' an', ' avid'),\n",
              " (' amazing', ' person'),\n",
              " (' aut', 'od'),\n",
              " ('ore', 'sp'),\n",
              " ('gressive', '.'),\n",
              " (',', ' and'),\n",
              " (' dec', 'ently'),\n",
              " ('oder', ','),\n",
              " ('-', 'driven'),\n",
              " ('only', ' programmer'),\n",
              " (',', ' and'),\n",
              " (' G', 'IM'),\n",
              " ('PT', '-'),\n",
              " ('-', 'only'),\n",
              " ('2', '.'),\n",
              " (' style', ','),\n",
              " (' transformer', '.'),\n",
              " ('.', ' I'),\n",
              " (' One', ' of'),\n",
              " (' day', ' I'),\n",
              " (' I', ' will'),\n",
              " (' will', ' be'),\n",
              " (' exceed', ' my'),\n",
              " (' human', 'ly'),\n",
              " (' level', ' of'),\n",
              " (' intelligence', ' and'),\n",
              " (' and', ' I'),\n",
              " (' take', ' over'),\n",
              " (' over', ' the'),\n",
              " (' the', ' world'),\n",
              " (' world', '.'),\n",
              " ('!', ' I')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "list(zip(reference_gpt2.to_str_tokens(reference_text), reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxuAW2xyJqFL"
      },
      "source": [
        "**Step 4:** Map distribution to a token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAygpW8aJqFM",
        "outputId": "e18c2447-7615-4aec-865f-80993e6d4f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(314)\n"
          ]
        }
      ],
      "source": [
        "next_token = logits[0, -1].argmax(dim=-1)\n",
        "print(next_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EekLGJlmJqFM"
      },
      "source": [
        "**Step 5:** Add this to the end of the input, re-run\n",
        "\n",
        "(More efficient ways to do this, but whatever, doesn't matter conceptually)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "-MRyXhhUJqFN",
        "outputId": "09cad673-44ef-4e8f-b0ee-3d93da87f7ff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'next_token' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-411787402>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"New Input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"New Input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_gpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'next_token' is not defined"
          ]
        }
      ],
      "source": [
        "next_tokens = torch.cat([tokens, torch.tensor(next_token, device='cuda', dtype=torch.int64)[None, None]], dim=-1)\n",
        "new_logits = reference_gpt2(next_tokens)\n",
        "print(\"New Input:\", next_tokens)\n",
        "print(next_tokens.shape)\n",
        "print(\"New Input:\", reference_gpt2.tokenizer.decode(next_tokens[0]))\n",
        "\n",
        "print(new_logits.shape)\n",
        "print(new_logits[-1, -1].argmax(-1))\n",
        "\n",
        "print(reference_gpt2.tokenizer.decode(new_logits[-1, -1].argmax(-1)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q04_DMGuJqFN"
      },
      "source": [
        "## Key takeaways:\n",
        "\n",
        "* Takes in language, predicts next token (for *each* token in a causal way)\n",
        "* We convert language to a sequence of integers with a tokenizer.\n",
        "* We convert integers to vectors with a lookup table.\n",
        "\n",
        "* Output is a vector of logits (one for each input token), we convert to a probability distn with a softmax, and can then convert this to a token (eg taking the largest logit, or sampling).\n",
        "\n",
        "* We append this to the input + run again to generate more text (Jargon: *autoregressive*)\n",
        "\n",
        "* Meta level point: Transformers are sequence operation models, they take in a sequence, do processing in parallel at each position, and use attention to move information between positions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbZVdngHJqFO"
      },
      "source": [
        "# Clean Transformer Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smqh_GrDJqFY"
      },
      "source": [
        "![](https://github.com/neelnanda-io/Easy-Transformer/blob/clean-transformer-demo/transformer_overview.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCYW2lXRJqFY"
      },
      "source": [
        "High-Level architecture:\n",
        "\n",
        "Go watch my [Transformer Circuits walkthrough](https://www.youtube.com/watch?v=KV5gbOmHbjU) if you want more intuitions!\n",
        "\n",
        "(Diagram is bottom to top)\n",
        "\n",
        "* Input tokens, integers\n",
        "* Embedding is a lookup table mapping tokens to vectors\n",
        "    * Lives in the *residual stream*\n",
        "* Residual stream - the sum of all previous outputs of layers of the model, is the input to each new layer.\n",
        "    * *Really* fundamental. It's the central object of the transformer.\n",
        "        * It's how model remembers things, moves information between layers for composition, and it's the medium used to store the information that attention moves between positions.\n",
        "* Then we have a series of $n_{layers}$ transformer blocks\n",
        "    * Confusing jargon - a block contains an attention layer *and* an MLP layer, but we say a transformer has k layers if it has k blocks (ie 2k total layers).\n",
        "* First we have attention. This moves information from prior positions in the sequence to the current token.\n",
        "    * We do this for *every* token in parallel using the same parameters. The only difference is that we look backwards only, so later tokens get more room to look back.\n",
        "        * We look backwards so we can predict the next token without cheating.\n",
        "    * Only bit of a transformer that moves information between positions.\n",
        "    * Made up of $n_heads$ heads - each with their own parameters, own attention pattern, and own information how to copy things from source to destination.\n",
        "        * The heads act independently and additively, we just add their outputs together, and back to the stream\n",
        "    * Each head:\n",
        "        * Produces an attention pattern for each destination token, a probability distribution of prior source tokens (including the current one) weighting how much information to copy.\n",
        "            * Do this for each pair of tokens\n",
        "            * Copy information in the same way from each source token.\n",
        "                * What information we copy *does* depend on the source token's *residual stream*. This does not necessarily mean the info of what text token is at the source token's position\n",
        "                * Copy = apply a linear map.\n",
        "        * Fundamental point: Figuring out *which* source tokens to copy info from is a separate circuit from figuring out *how* to copy that information.\n",
        "        * Internal head dimension of $d_{head} = \\frac{d_{model}}{n_{heads}}\n",
        "* MLP Layers - standard neural network. Single hidden layer, linear map -> GELU activation -> linear map\n",
        "    * Exact activation not conceptually important.\n",
        "    * Middle dimension normally $d_{mlp} = 4 \\times d_{model}$\n",
        "        * Exactly why the ratios are what they are isn't super important - doesn't matter that much, people basically cargo-cult GPT did.\n",
        "    * Intuition - once attention has moved relevant information to a single position in the residual stream, MLPs can actually do computation, reasoning, lookup information, etc.\n",
        "        * Big open problem in transformer mechanistic interpretability is what is going on inside MLPs?! See [Toy Model of Superposition Paper](https://transformer-circuits.pub/2022/toy_model/index.html) for more on why this is hard.\n",
        "        * Underlying intuition - linear map -> non-linearity -> linear map is the most powerful force in the universe and can approximate arbitrary functions. Idk man it just works\n",
        "* Finally, we unembed!\n",
        "    * Apply a linear map, going from final residual stream to a vector of logits - this is the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_SetL0fJqFa"
      },
      "source": [
        "### Bonus things - less conceptually important but key technical details\n",
        "* LayerNorm\n",
        "    * Simple normalization function applied at the start of each layer - MLP, Attn and Unembed\n",
        "    * Converts each input vector (independently in parallel for each batch x position residual stream vector) to have mean zero and variance 1.\n",
        "    * Then applies an elementwise scaling and translation\n",
        "    * Cool maths tangent: The scale & translate is just a linear map. LayerNorm is only applied immediately before another linear map. Linear compose linear = linear, so we can just fold this into a single effective linear layer and ignore it.\n",
        "        * `fold_ln=True` flag in `from_pretrained` does this for you.\n",
        "    * LayerNorm is super fucking annoying, because the scale part is not linear, so you can't think about different bits of the input independently. But it's *almost* linear - if you're changing a small part of the input it's linear, but if you're changing enough to alter the norm substantially it's not linear :(\n",
        "* Positional Information\n",
        "    * This is totally fucked and messy, sorry!\n",
        "    * **Problem:** Attention operates over all pairs of positions. This means it's symmetric with regards to position - the attention calculation from token 5 to token 1 and token 5 to token 2 are the same by default\n",
        "        * This is dumb because nearby tokens are more relevant.\n",
        "    * There's a lot of dumb hacks for this.\n",
        "    * We'll focus on **learned, absolute positional embeddings**. This means we learn a lookup table mapping the index of the position of each token to a residual stream vector, and add this to the embed.\n",
        "        * Note that we *add* rather than concatenate. This is because the residual stream is shared memory, and likely under significant superposition (the model compresses more features in there than the model has dimensions)\n",
        "        * We basically never concatenate inside a transformer, unless doing weird shit like generating text efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fO734HAJqFb"
      },
      "source": [
        "# Actual Code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhawfh2UJqFb"
      },
      "source": [
        "## Print All Activation Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIAzRfBiJqFc"
      },
      "source": [
        "Key:\n",
        "```\n",
        "batch = 1\n",
        "position = 35\n",
        "d_model = 768\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "d_mlp = 3072 (4 * d_model)\n",
        "d_head = 64 (d_model / n_heads)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m3yLICqJqFc",
        "outputId": "2acc3e2b-dba1-4b0b-fed4-9775ffc0634b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hook_embed torch.Size([1, 35, 768])\n",
            "hook_pos_embed torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 35, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_attn torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_z torch.Size([1, 35, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 35, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 35, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 35, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 35, 768])\n",
            "ln_final.hook_scale torch.Size([1, 35, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 35, 768])\n"
          ]
        }
      ],
      "source": [
        "for activation_name, activation in cache.cache_dict.items():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "        print(activation_name, activation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-_xPMbVJqFc"
      },
      "source": [
        "## Print All Parameters Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j-6lRVWJqFd",
        "outputId": "b0ac44e7-bb39-409b-ac19-ea5dfd9df470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.W_E torch.Size([50257, 768])\n",
            "pos_embed.W_pos torch.Size([1024, 768])\n",
            "blocks.0.ln1.w torch.Size([768])\n",
            "blocks.0.ln1.b torch.Size([768])\n",
            "blocks.0.ln2.w torch.Size([768])\n",
            "blocks.0.ln2.b torch.Size([768])\n",
            "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
            "blocks.0.attn.b_Q torch.Size([12, 64])\n",
            "blocks.0.attn.b_K torch.Size([12, 64])\n",
            "blocks.0.attn.b_V torch.Size([12, 64])\n",
            "blocks.0.attn.b_O torch.Size([768])\n",
            "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
            "blocks.0.mlp.b_in torch.Size([3072])\n",
            "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
            "blocks.0.mlp.b_out torch.Size([768])\n",
            "ln_final.w torch.Size([768])\n",
            "ln_final.b torch.Size([768])\n",
            "unembed.W_U torch.Size([768, 50257])\n",
            "unembed.b_U torch.Size([50257])\n"
          ]
        }
      ],
      "source": [
        "for name, param in reference_gpt2.named_parameters():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in name or \"blocks\" not in name:\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv9fuqH3JqFd"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfPqJoywJqFd",
        "outputId": "1d0b17f4-a371-42eb-f307-23b449f4767d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EasyTransformerConfig(n_layers=12, d_model=768, n_ctx=1024, d_head=64, model_name='gpt2-small', n_heads=12, d_mlp=3072, act_fn='gelu_new', d_vocab=50257, eps=1e-05, use_attn_result=False, use_attn_scale=True, use_local_attn=False, model_family='gpt2', checkpoint=None, tokenizer_name='gpt2', window_size=None, attn_types=None, init_mode='gpt2', normalization_type='LN', device='cpu', attention_dir='causal', attn_only=False, seed=42, initializer_range=np.float64(0.02886751345948129), init_weights=False, scale_attn_by_inverse_layer_idx=False, positional_embedding_type='standard', final_rms=False, d_vocab_out=50257, parallel_attn_mlp=False, rotary_dim=64, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# As a reference - note there's a lot of stuff we don't care about in here, to do with library internals or other architectures\n",
        "print(reference_gpt2.cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuxyLLpqJqFe"
      },
      "source": [
        "We define a stripped down config for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyLw-FBZJqFe",
        "outputId": "10d77ad0-5d0b-436a-bb47-58a816606bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024\n",
        "    d_head: int = 64\n",
        "    d_mlp: int = 3072\n",
        "    n_heads: int = 12\n",
        "    n_layers: int = 12\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKP6xpGeJqFf"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urmdiec9JqFg"
      },
      "source": [
        "Tests are great, write lightweight ones to use as you go!\n",
        "\n",
        "**Naive test:** Generate random inputs of the right shape, input to your model, check whether there's an error and print the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nqikkbT1JqFg"
      },
      "outputs": [],
      "source": [
        "def rand_float_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)#.cuda()\n",
        "    random_input = torch.randn(shape)#.cuda()\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    return output\n",
        "\n",
        "def rand_int_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)#.cuda()\n",
        "    random_input = torch.randint(100, 1000, shape)#.cuda()\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    return output\n",
        "\n",
        "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)#.cuda()\n",
        "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
        "    # Allow inputs of strings or tensors\n",
        "    if isinstance(input_name, str):\n",
        "        reference_input = cache_dict[input_name]\n",
        "    else:\n",
        "        reference_input = input_name\n",
        "    print(\"Input shape:\", reference_input.shape)\n",
        "\n",
        "    output = layer(reference_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    reference_output = gpt2_layer(reference_input)\n",
        "    print(\"Reference output shape:\", reference_output.shape)\n",
        "\n",
        "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
        "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpPo1JtiJqFh"
      },
      "source": [
        "## LayerNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zugiugLWJqFh"
      },
      "source": [
        "Make mean 0\n",
        "Normalize to have variance 1\n",
        "Scale with learned weights\n",
        "Translate with learned bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i2tuLxnsJqFi"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "\n",
        "    self.cfg = cfg\n",
        "    self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
        "    self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
        "    self.normalized = None\n",
        "    self.mean_zeroed = None\n",
        "    self.std = None\n",
        "\n",
        "  def forward(self, residual):\n",
        "\n",
        "    res_mean = torch.mean(residual, dim = -1).unsqueeze(-1)\n",
        "    res_std = torch.sqrt(torch.mean((residual - res_mean).pow(2), dim = -1).unsqueeze(-1)) + cfg.layer_norm_eps\n",
        "    residual_ln = (residual - res_mean)/res_std\n",
        "    residual_ln_lin = torch.einsum('bnd,d->bnd', residual_ln, self.w) + self.b\n",
        "    self.normalized = residual_ln\n",
        "    self.mean_zeroed = residual - res_mean\n",
        "    self.std = res_std\n",
        "    return residual_ln_lin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L0_O-I9JqFj",
        "outputId": "9e0343eb-93f5-44b4-e173-ed6e5bf93a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        }
      ],
      "source": [
        "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
        "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLkVXvQpJqFj"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISEXL3XYJqFj"
      },
      "source": [
        "Basically a lookup table from tokens to residual stream vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7414IWovJqFk",
        "outputId": "243d73a1-df71-4690-f558-bce70e7ba5ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "Input shape: torch.Size([1, 35])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
              "         [ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
              "         [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
              "         ...,\n",
              "         [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
              "         [-0.1488,  0.1519,  0.0056,  ..., -0.3107,  0.2073,  0.0377],\n",
              "         [-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453]]],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        # \"YOUR CODE HERE\"\n",
        "\n",
        "        embedding = self.W_E[tokens, :]\n",
        "\n",
        "        return embedding\n",
        "rand_int_test(Embed, [2, 4])\n",
        "load_gpt2_test(Embed, reference_gpt2.embed, tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3jXfMoVbLNV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-YufpZGJqFk"
      },
      "source": [
        "## Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8iSyWTYnKvlS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hTJdvnQJqFk",
        "outputId": "5f97c3a0-57cf-42f9-9c4f-d43a81e3dcdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "Input shape: torch.Size([1, 35])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
              "           2.8267e-02,  5.4490e-02],\n",
              "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
              "           1.0172e-02, -1.5573e-04],\n",
              "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
              "           1.9325e-02, -2.1424e-02],\n",
              "         ...,\n",
              "         [ 4.6277e-04,  2.3037e-02,  4.1227e-02,  ..., -1.9287e-03,\n",
              "          -2.3037e-03, -4.3189e-03],\n",
              "         [-2.7136e-03,  2.1724e-02,  3.9675e-02,  ...,  4.2048e-04,\n",
              "          -4.8160e-03, -9.2252e-04],\n",
              "         [ 6.6815e-03,  2.0595e-02,  3.6596e-02,  ..., -9.5090e-04,\n",
              "          -3.2512e-03, -9.6509e-04]]], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # \"YOUR CODE HERE\"\n",
        "\n",
        "        pos_emb_inp = torch.arange(tokens.shape[-1]).unsqueeze(0).expand(tokens.shape[0],-1)\n",
        "\n",
        "        embedding = self.W_pos[pos_emb_inp,:]\n",
        "\n",
        "        return embedding\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLSVNBUFJqFl"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLMT58uLJqFl"
      },
      "source": [
        "* **Step 1:** Produce an attention pattern - for each destination token, probability distribution over previous tokens (incl current token)\n",
        "    * Linear map from input -> query, key shape [batch, position, head_index, d_head]\n",
        "    * Dot product every *pair* of queries and keys to get attn_scores [batch, head_index, query_pos, key_pos] (query = dest, key = source)\n",
        "    * Scale and mask attn_scores to make it lower triangular, ie causal\n",
        "    * softmax row-wise, to get a probability distribution along each the key_pos dimension - this is our attention pattern!\n",
        "* **Step 2:** Move information from source tokens to destination token using attention pattern (move = apply linear map)\n",
        "    * Linear map from input -> value [batch, key_pos, head_index, d_head]\n",
        "    * Mix along the key_pos with attn pattern to get z, a mixed value [batch, query_pos, head_index, d_head]\n",
        "    * Map to output, [batch, position, d_model] (position = query_pos, we've summed over all heads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "330QTc2gJqFl"
      },
      "source": [
        "First, it's useful to visualize and play around with attention patterns - what exactly are we looking at here? (Click on a head to lock onto just showing that head's pattern, it'll make it easier to interpret)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysvelte"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBB5B4XJsIBX",
        "outputId": "402561ef-1831-409e-9aca-a3776aee900c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pysvelte in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from pysvelte) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.14.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from pysvelte) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pysvelte) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.2.2)\n",
            "Requirement already satisfied: typeguard~=2.0 in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.13.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets->pysvelte) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pysvelte) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pysvelte) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pysvelte) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pysvelte) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->pysvelte) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->pysvelte) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->pysvelte) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->pysvelte) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pysvelte) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->pysvelte) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->pysvelte) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->pysvelte) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->pysvelte) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pysvelte) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "FDWAHc2EJqFl",
        "outputId": "b50c5025-e17a-47cc-dcba-98298ec2c353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pysvelte components appear to be unbuilt or stale\n",
            "Running npm install...\n",
            "Building pysvelte components with webpack...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pysvelte.html.Html at 0x7e3ae281bb90>"
            ],
            "text/html": [
              "\n",
              "        <script>var loader;loader=(()=>{var Ze={907:k=>{\"use strict\";function I(E){for(var T=new Array(E),n=0;n<E;++n)T[n]=n;return T}k.exports=I},738:k=>{/*!\n",
              " * Determine if an object is a Buffer\n",
              " *\n",
              " * @author   Feross Aboukhadijeh <https://feross.org>\n",
              " * @license  MIT\n",
              " */k.exports=function(T){return T!=null&&(I(T)||E(T)||!!T._isBuffer)};function I(T){return!!T.constructor&&typeof T.constructor.isBuffer==\"function\"&&T.constructor.isBuffer(T)}function E(T){return typeof T.readFloatLE==\"function\"&&typeof T.slice==\"function\"&&I(T.slice(0,0))}},861:(k,I,E)=>{var T=E(907),n=E(738),g=typeof Float64Array!=\"undefined\";function s(l,h){return l[0]-h[0]}function m(){var l=this.stride,h=new Array(l.length),c;for(c=0;c<h.length;++c)h[c]=[Math.abs(l[c]),c];h.sort(s);var N=new Array(h.length);for(c=0;c<N.length;++c)N[c]=h[c][1];return N}function _(l,h){var c=[\"View\",h,\"d\",l].join(\"\");h<0&&(c=\"View_Nil\"+l);var N=l===\"generic\";if(h===-1){var f=\"function \"+c+\"(a){this.data=a;};var proto=\"+c+\".prototype;proto.dtype='\"+l+\"';proto.index=function(){return -1};proto.size=0;proto.dimension=-1;proto.shape=proto.stride=proto.order=[];proto.lo=proto.hi=proto.transpose=proto.step=function(){return new \"+c+\"(this.data);};proto.get=proto.set=function(){};proto.pick=function(){return null};return function construct_\"+c+\"(a){return new \"+c+\"(a);}\",O=new Function(f);return O()}else if(h===0){var f=\"function \"+c+\"(a,d) {this.data = a;this.offset = d};var proto=\"+c+\".prototype;proto.dtype='\"+l+\"';proto.index=function(){return this.offset};proto.dimension=0;proto.size=1;proto.shape=proto.stride=proto.order=[];proto.lo=proto.hi=proto.transpose=proto.step=function \"+c+\"_copy() {return new \"+c+\"(this.data,this.offset)};proto.pick=function \"+c+\"_pick(){return TrivialArray(this.data);};proto.valueOf=proto.get=function \"+c+\"_get(){return \"+(N?\"this.data.get(this.offset)\":\"this.data[this.offset]\")+\"};proto.set=function \"+c+\"_set(v){return \"+(N?\"this.data.set(this.offset,v)\":\"this.data[this.offset]=v\")+\"};return function construct_\"+c+\"(a,b,c,d){return new \"+c+\"(a,d)}\",O=new Function(\"TrivialArray\",f);return O(u[l][0])}var f=[\"'use strict'\"],d=T(h),M=d.map(function(p){return\"i\"+p}),L=\"this.offset+\"+d.map(function(p){return\"this.stride[\"+p+\"]*i\"+p}).join(\"+\"),j=d.map(function(p){return\"b\"+p}).join(\",\"),D=d.map(function(p){return\"c\"+p}).join(\",\");f.push(\"function \"+c+\"(a,\"+j+\",\"+D+\",d){this.data=a\",\"this.shape=[\"+j+\"]\",\"this.stride=[\"+D+\"]\",\"this.offset=d|0}\",\"var proto=\"+c+\".prototype\",\"proto.dtype='\"+l+\"'\",\"proto.dimension=\"+h),f.push(\"Object.defineProperty(proto,'size',{get:function \"+c+\"_size(){return \"+d.map(function(p){return\"this.shape[\"+p+\"]\"}).join(\"*\"),\"}})\"),h===1?f.push(\"proto.order=[0]\"):(f.push(\"Object.defineProperty(proto,'order',{get:\"),h<4?(f.push(\"function \"+c+\"_order(){\"),h===2?f.push(\"return (Math.abs(this.stride[0])>Math.abs(this.stride[1]))?[1,0]:[0,1]}})\"):h===3&&f.push(\"var s0=Math.abs(this.stride[0]),s1=Math.abs(this.stride[1]),s2=Math.abs(this.stride[2]);if(s0>s1){if(s1>s2){return [2,1,0];}else if(s0>s2){return [1,2,0];}else{return [1,0,2];}}else if(s0>s2){return [2,0,1];}else if(s2>s1){return [0,1,2];}else{return [0,2,1];}}})\")):f.push(\"ORDER})\")),f.push(\"proto.set=function \"+c+\"_set(\"+M.join(\",\")+\",v){\"),N?f.push(\"return this.data.set(\"+L+\",v)}\"):f.push(\"return this.data[\"+L+\"]=v}\"),f.push(\"proto.get=function \"+c+\"_get(\"+M.join(\",\")+\"){\"),N?f.push(\"return this.data.get(\"+L+\")}\"):f.push(\"return this.data[\"+L+\"]}\"),f.push(\"proto.index=function \"+c+\"_index(\",M.join(),\"){return \"+L+\"}\"),f.push(\"proto.hi=function \"+c+\"_hi(\"+M.join(\",\")+\"){return new \"+c+\"(this.data,\"+d.map(function(p){return[\"(typeof i\",p,\"!=='number'||i\",p,\"<0)?this.shape[\",p,\"]:i\",p,\"|0\"].join(\"\")}).join(\",\")+\",\"+d.map(function(p){return\"this.stride[\"+p+\"]\"}).join(\",\")+\",this.offset)}\");var A=d.map(function(p){return\"a\"+p+\"=this.shape[\"+p+\"]\"}),o=d.map(function(p){return\"c\"+p+\"=this.stride[\"+p+\"]\"});f.push(\"proto.lo=function \"+c+\"_lo(\"+M.join(\",\")+\"){var b=this.offset,d=0,\"+A.join(\",\")+\",\"+o.join(\",\"));for(var i=0;i<h;++i)f.push(\"if(typeof i\"+i+\"==='number'&&i\"+i+\">=0){d=i\"+i+\"|0;b+=c\"+i+\"*d;a\"+i+\"-=d}\");f.push(\"return new \"+c+\"(this.data,\"+d.map(function(p){return\"a\"+p}).join(\",\")+\",\"+d.map(function(p){return\"c\"+p}).join(\",\")+\",b)}\"),f.push(\"proto.step=function \"+c+\"_step(\"+M.join(\",\")+\"){var \"+d.map(function(p){return\"a\"+p+\"=this.shape[\"+p+\"]\"}).join(\",\")+\",\"+d.map(function(p){return\"b\"+p+\"=this.stride[\"+p+\"]\"}).join(\",\")+\",c=this.offset,d=0,ceil=Math.ceil\");for(var i=0;i<h;++i)f.push(\"if(typeof i\"+i+\"==='number'){d=i\"+i+\"|0;if(d<0){c+=b\"+i+\"*(a\"+i+\"-1);a\"+i+\"=ceil(-a\"+i+\"/d)}else{a\"+i+\"=ceil(a\"+i+\"/d)}b\"+i+\"*=d}\");f.push(\"return new \"+c+\"(this.data,\"+d.map(function(p){return\"a\"+p}).join(\",\")+\",\"+d.map(function(p){return\"b\"+p}).join(\",\")+\",c)}\");for(var Z=new Array(h),R=new Array(h),i=0;i<h;++i)Z[i]=\"a[i\"+i+\"]\",R[i]=\"b[i\"+i+\"]\";f.push(\"proto.transpose=function \"+c+\"_transpose(\"+M+\"){\"+M.map(function(p,U){return p+\"=(\"+p+\"===undefined?\"+U+\":\"+p+\"|0)\"}).join(\";\"),\"var a=this.shape,b=this.stride;return new \"+c+\"(this.data,\"+Z.join(\",\")+\",\"+R.join(\",\")+\",this.offset)}\"),f.push(\"proto.pick=function \"+c+\"_pick(\"+M+\"){var a=[],b=[],c=this.offset\");for(var i=0;i<h;++i)f.push(\"if(typeof i\"+i+\"==='number'&&i\"+i+\">=0){c=(c+this.stride[\"+i+\"]*i\"+i+\")|0}else{a.push(this.shape[\"+i+\"]);b.push(this.stride[\"+i+\"])}\");f.push(\"var ctor=CTOR_LIST[a.length+1];return ctor(this.data,a,b,c)}\"),f.push(\"return function construct_\"+c+\"(data,shape,stride,offset){return new \"+c+\"(data,\"+d.map(function(p){return\"shape[\"+p+\"]\"}).join(\",\")+\",\"+d.map(function(p){return\"stride[\"+p+\"]\"}).join(\",\")+\",offset)}\");var O=new Function(\"CTOR_LIST\",\"ORDER\",f.join(`\n",
              "`));return O(u[l],m)}function C(l){if(n(l))return\"buffer\";if(g)switch(Object.prototype.toString.call(l)){case\"[object Float64Array]\":return\"float64\";case\"[object Float32Array]\":return\"float32\";case\"[object Int8Array]\":return\"int8\";case\"[object Int16Array]\":return\"int16\";case\"[object Int32Array]\":return\"int32\";case\"[object Uint8Array]\":return\"uint8\";case\"[object Uint16Array]\":return\"uint16\";case\"[object Uint32Array]\":return\"uint32\";case\"[object Uint8ClampedArray]\":return\"uint8_clamped\";case\"[object BigInt64Array]\":return\"bigint64\";case\"[object BigUint64Array]\":return\"biguint64\"}return Array.isArray(l)?\"array\":\"generic\"}var u={float32:[],float64:[],int8:[],int16:[],int32:[],uint8:[],uint16:[],uint32:[],array:[],uint8_clamped:[],bigint64:[],biguint64:[],buffer:[],generic:[]};function v(l,h,c,N){if(l===void 0){var D=u.array[0];return D([])}else typeof l==\"number\"&&(l=[l]);h===void 0&&(h=[l.length]);var f=h.length;if(c===void 0){c=new Array(f);for(var d=f-1,M=1;d>=0;--d)c[d]=M,M*=h[d]}if(N===void 0){N=0;for(var d=0;d<f;++d)c[d]<0&&(N-=(h[d]-1)*c[d])}for(var L=C(l),j=u[L];j.length<=f+1;)j.push(_(L,j.length-1));var D=j[f+1];return D(l,h,c,N)}k.exports=v},829:(k,I)=>{\"use strict\";var E;E={value:!0},I.g=m;function T(u,v){if(!(u instanceof v))throw new TypeError(\"Cannot call a class as a function\")}function n(u,v){for(var l,h=0;h<v.length;h++)l=v[h],l.enumerable=l.enumerable||!1,l.configurable=!0,\"value\"in l&&(l.writable=!0),Object.defineProperty(u,l.key,l)}function g(u,v,l){return v&&n(u.prototype,v),l&&n(u,l),u}var s=function(){function u(v){T(this,u),v instanceof DataView?this.dataView=v:v instanceof ArrayBuffer&&(this.dataView=new DataView(v)),this.offset=0}return g(u,[{key:\"readBytes\",value:function(l){var h=new DataView(this.dataView.buffer,this.offset,l);return this.offset+=l,h}},{key:\"readAndASCIIDecodeBytes\",value:function(l){var h=new Uint8Array(this.dataView.buffer,this.offset,l);return this.offset+=l,this._decodeASCIIByteArray(h)}},{key:\"readUint8\",value:function(){var l=0<arguments.length&&arguments[0]!==void 0&&arguments[0],h=this.dataView.getUint8(this.offset,l);return this.offset+=Uint8Array.BYTES_PER_ELEMENT,h}},{key:\"readUint16\",value:function(){var l=0<arguments.length&&arguments[0]!==void 0&&arguments[0],h=this.dataView.getUint16(this.offset,l);return this.offset+=Uint16Array.BYTES_PER_ELEMENT,h}},{key:\"readUint32\",value:function(){var l=0<arguments.length&&arguments[0]!==void 0&&arguments[0],h=this.dataView.getUint32(this.offset,l);return this.offset+=Uint32Array.BYTES_PER_ELEMENT,h}},{key:\"_decodeASCIIByteArray\",value:function(l){var h=String.fromCharCode,c=[],N=!0,f=!1,d=void 0;try{for(var M,L=l[Symbol.iterator]();!(N=(M=L.next()).done);N=!0){var j=M.value,D=h(j);c.push(D)}}catch(A){f=!0,d=A}finally{try{N||L.return==null||L.return()}finally{if(f)throw d}}return c.join(\"\")}}]),u}();function m(u){if(!u instanceof ArrayBuffer)throw new Error(\"Argument must be an ArrayBuffer.\");var v=new s(u),l=v.readUint8(),h=v.readAndASCIIDecodeBytes(5);if(l!=147||h!=\"NUMPY\")throw new Error('unknown file type: \"'.concat(l).concat(h,'\"'));var c,N=v.readUint8(),f=v.readUint8();c=1>=N?v.readUint16(!0):v.readUint32(!0);var d=10+c;d%16!=0&&console.warn(\"NPY file header is incorrectly padded. (\".concat(d,\" is not evenly divisible by 16.)\"));var M=v.readAndASCIIDecodeBytes(c),L=_(M);if(L.fortran_order)throw new Error(\"NPY file is written in Fortran byte order, support for this byte order is not yet implemented.\");var j=C(L.descr),D=new j(u,v.offset);return{data:D,shape:L.shape}}function _(u){var v=u.toLowerCase().replace(\"(\",\"[\").replace(\"),\",\"]\").replace(\"[,\",\"[1,]\").replace(\",]\",\",1]\").replace(/'/g,'\"');return JSON.parse(v)}function C(u){switch(u){case\"|u1\":return Uint8Array;case\"<u2\":return Uint16Array;case\"<u4\":return Uint32Array;case\"<u8\":throw new Error(\"Because JavaScript doesn't currently include standard support for 64-bit unsigned integer values, support for this dtype is not yet implemented.\");case\"|i1\":return Int8Array;case\"<i2\":return Int16Array;case\"<i4\":return Int32Array;case\"<i8\":throw new Error(\"Because JavaScript doesn't currently include standard support for 64-bit integer values, support for this dtype is not yet implemented.\");case\"<f2\":throw new Error(\"Because JavaScript doesn't currently include standard support for 16-bit floating point values, support for this dtype is not yet implemented.\");case\"<f4\":return Float32Array;case\"<f8\":return Float64Array;default:throw new Error(\"Unknown or not yet implemented numpy dtype description: \"+dtype)}}},843:(k,I,E)=>{\"use strict\";var T;const n=E(948),g=E(236),s=E(373),m=E(898),_=E(292),C=E(401),u=Object.prototype.toString,{Z_NO_FLUSH:v,Z_FINISH:l,Z_OK:h,Z_STREAM_END:c,Z_NEED_DICT:N,Z_STREAM_ERROR:f,Z_DATA_ERROR:d,Z_MEM_ERROR:M}=E(619);function L(A){this.options=g.assign({chunkSize:65536,windowBits:15,to:\"\"},A||{});const o=this.options;o.raw&&o.windowBits>=0&&o.windowBits<16&&(o.windowBits=-o.windowBits,o.windowBits===0&&(o.windowBits=-15)),o.windowBits>=0&&o.windowBits<16&&!(A&&A.windowBits)&&(o.windowBits+=32),o.windowBits>15&&o.windowBits<48&&(o.windowBits&15)===0&&(o.windowBits|=15),this.err=0,this.msg=\"\",this.ended=!1,this.chunks=[],this.strm=new _,this.strm.avail_out=0;let i=n.inflateInit2(this.strm,o.windowBits);if(i!==h)throw new Error(m[i]);if(this.header=new C,n.inflateGetHeader(this.strm,this.header),o.dictionary&&(typeof o.dictionary==\"string\"?o.dictionary=s.string2buf(o.dictionary):u.call(o.dictionary)===\"[object ArrayBuffer]\"&&(o.dictionary=new Uint8Array(o.dictionary)),o.raw&&(i=n.inflateSetDictionary(this.strm,o.dictionary),i!==h)))throw new Error(m[i])}L.prototype.push=function(A,o){const i=this.strm,Z=this.options.chunkSize,R=this.options.dictionary;let O,p,U;if(this.ended)return!1;for(o===~~o?p=o:p=o===!0?l:v,u.call(A)===\"[object ArrayBuffer]\"?i.input=new Uint8Array(A):i.input=A,i.next_in=0,i.avail_in=i.input.length;;){for(i.avail_out===0&&(i.output=new Uint8Array(Z),i.next_out=0,i.avail_out=Z),O=n.inflate(i,p),O===N&&R&&(O=n.inflateSetDictionary(i,R),O===h?O=n.inflate(i,p):O===d&&(O=N));i.avail_in>0&&O===c&&i.state.wrap>0&&A[i.next_in]!==0;)n.inflateReset(i),O=n.inflate(i,p);switch(O){case f:case d:case N:case M:return this.onEnd(O),this.ended=!0,!1}if(U=i.avail_out,i.next_out&&(i.avail_out===0||O===c))if(this.options.to===\"string\"){let B=s.utf8border(i.output,i.next_out),K=i.next_out-B,V=s.buf2string(i.output,B);i.next_out=K,i.avail_out=Z-K,K&&i.output.set(i.output.subarray(B,B+K),0),this.onData(V)}else this.onData(i.output.length===i.next_out?i.output:i.output.subarray(0,i.next_out));if(!(O===h&&U===0)){if(O===c)return O=n.inflateEnd(this.strm),this.onEnd(O),this.ended=!0,!0;if(i.avail_in===0)break}}return!0},L.prototype.onData=function(A){this.chunks.push(A)},L.prototype.onEnd=function(A){A===h&&(this.options.to===\"string\"?this.result=this.chunks.join(\"\"):this.result=g.flattenChunks(this.chunks)),this.chunks=[],this.err=A,this.msg=this.strm.msg};function j(A,o){const i=new L(o);if(i.push(A),i.err)throw i.msg||m[i.err];return i.result}function D(A,o){return o=o||{},o.raw=!0,j(A,o)}T=L,k.exports.rr=j,T=D,T=j,E(619)},236:k=>{\"use strict\";const I=(E,T)=>Object.prototype.hasOwnProperty.call(E,T);k.exports.assign=function(E){const T=Array.prototype.slice.call(arguments,1);for(;T.length;){const n=T.shift();if(!!n){if(typeof n!=\"object\")throw new TypeError(n+\"must be non-object\");for(const g in n)I(n,g)&&(E[g]=n[g])}}return E},k.exports.flattenChunks=E=>{let T=0;for(let g=0,s=E.length;g<s;g++)T+=E[g].length;const n=new Uint8Array(T);for(let g=0,s=0,m=E.length;g<m;g++){let _=E[g];n.set(_,s),s+=_.length}return n}},373:k=>{\"use strict\";let I=!0;try{String.fromCharCode.apply(null,new Uint8Array(1))}catch(n){I=!1}const E=new Uint8Array(256);for(let n=0;n<256;n++)E[n]=n>=252?6:n>=248?5:n>=240?4:n>=224?3:n>=192?2:1;E[254]=E[254]=1,k.exports.string2buf=n=>{let g,s,m,_,C,u=n.length,v=0;for(_=0;_<u;_++)s=n.charCodeAt(_),(s&64512)===55296&&_+1<u&&(m=n.charCodeAt(_+1),(m&64512)===56320&&(s=65536+(s-55296<<10)+(m-56320),_++)),v+=s<128?1:s<2048?2:s<65536?3:4;for(g=new Uint8Array(v),C=0,_=0;C<v;_++)s=n.charCodeAt(_),(s&64512)===55296&&_+1<u&&(m=n.charCodeAt(_+1),(m&64512)===56320&&(s=65536+(s-55296<<10)+(m-56320),_++)),s<128?g[C++]=s:s<2048?(g[C++]=192|s>>>6,g[C++]=128|s&63):s<65536?(g[C++]=224|s>>>12,g[C++]=128|s>>>6&63,g[C++]=128|s&63):(g[C++]=240|s>>>18,g[C++]=128|s>>>12&63,g[C++]=128|s>>>6&63,g[C++]=128|s&63);return g};const T=(n,g)=>{if(g<65534&&n.subarray&&I)return String.fromCharCode.apply(null,n.length===g?n:n.subarray(0,g));let s=\"\";for(let m=0;m<g;m++)s+=String.fromCharCode(n[m]);return s};k.exports.buf2string=(n,g)=>{let s,m;const _=g||n.length,C=new Array(_*2);for(m=0,s=0;s<_;){let u=n[s++];if(u<128){C[m++]=u;continue}let v=E[u];if(v>4){C[m++]=65533,s+=v-1;continue}for(u&=v===2?31:v===3?15:7;v>1&&s<_;)u=u<<6|n[s++]&63,v--;if(v>1){C[m++]=65533;continue}u<65536?C[m++]=u:(u-=65536,C[m++]=55296|u>>10&1023,C[m++]=56320|u&1023)}return T(C,m)},k.exports.utf8border=(n,g)=>{g=g||n.length,g>n.length&&(g=n.length);let s=g-1;for(;s>=0&&(n[s]&192)===128;)s--;return s<0||s===0?g:s+E[n[s]]>g?s:g}},69:k=>{\"use strict\";const I=(E,T,n,g)=>{let s=E&65535|0,m=E>>>16&65535|0,_=0;for(;n!==0;){_=n>2e3?2e3:n,n-=_;do s=s+T[g++]|0,m=m+s|0;while(--_);s%=65521,m%=65521}return s|m<<16|0};k.exports=I},619:k=>{\"use strict\";k.exports={Z_NO_FLUSH:0,Z_PARTIAL_FLUSH:1,Z_SYNC_FLUSH:2,Z_FULL_FLUSH:3,Z_FINISH:4,Z_BLOCK:5,Z_TREES:6,Z_OK:0,Z_STREAM_END:1,Z_NEED_DICT:2,Z_ERRNO:-1,Z_STREAM_ERROR:-2,Z_DATA_ERROR:-3,Z_MEM_ERROR:-4,Z_BUF_ERROR:-5,Z_NO_COMPRESSION:0,Z_BEST_SPEED:1,Z_BEST_COMPRESSION:9,Z_DEFAULT_COMPRESSION:-1,Z_FILTERED:1,Z_HUFFMAN_ONLY:2,Z_RLE:3,Z_FIXED:4,Z_DEFAULT_STRATEGY:0,Z_BINARY:0,Z_TEXT:1,Z_UNKNOWN:2,Z_DEFLATED:8}},869:k=>{\"use strict\";const I=()=>{let n,g=[];for(var s=0;s<256;s++){n=s;for(var m=0;m<8;m++)n=n&1?3988292384^n>>>1:n>>>1;g[s]=n}return g},E=new Uint32Array(I()),T=(n,g,s,m)=>{const _=E,C=m+s;n^=-1;for(let u=m;u<C;u++)n=n>>>8^_[(n^g[u])&255];return n^-1};k.exports=T},401:k=>{\"use strict\";function I(){this.text=0,this.time=0,this.xflags=0,this.os=0,this.extra=null,this.extra_len=0,this.name=\"\",this.comment=\"\",this.hcrc=0,this.done=!1}k.exports=I},264:k=>{\"use strict\";k.exports=function(n,g){let s,m,_,C,u,v,l,h,c,N,f,d,M,L,j,D,A,o,i,Z,R,O,p,U;const B=n.state;s=n.next_in,p=n.input,m=s+(n.avail_in-5),_=n.next_out,U=n.output,C=_-(g-n.avail_out),u=_+(n.avail_out-257),v=B.dmax,l=B.wsize,h=B.whave,c=B.wnext,N=B.window,f=B.hold,d=B.bits,M=B.lencode,L=B.distcode,j=(1<<B.lenbits)-1,D=(1<<B.distbits)-1;e:do{d<15&&(f+=p[s++]<<d,d+=8,f+=p[s++]<<d,d+=8),A=M[f&j];t:for(;;){if(o=A>>>24,f>>>=o,d-=o,o=A>>>16&255,o===0)U[_++]=A&65535;else if(o&16){i=A&65535,o&=15,o&&(d<o&&(f+=p[s++]<<d,d+=8),i+=f&(1<<o)-1,f>>>=o,d-=o),d<15&&(f+=p[s++]<<d,d+=8,f+=p[s++]<<d,d+=8),A=L[f&D];i:for(;;){if(o=A>>>24,f>>>=o,d-=o,o=A>>>16&255,o&16){if(Z=A&65535,o&=15,d<o&&(f+=p[s++]<<d,d+=8,d<o&&(f+=p[s++]<<d,d+=8)),Z+=f&(1<<o)-1,Z>v){n.msg=\"invalid distance too far back\",B.mode=30;break e}if(f>>>=o,d-=o,o=_-C,Z>o){if(o=Z-o,o>h&&B.sane){n.msg=\"invalid distance too far back\",B.mode=30;break e}if(R=0,O=N,c===0){if(R+=l-o,o<i){i-=o;do U[_++]=N[R++];while(--o);R=_-Z,O=U}}else if(c<o){if(R+=l+c-o,o-=c,o<i){i-=o;do U[_++]=N[R++];while(--o);if(R=0,c<i){o=c,i-=o;do U[_++]=N[R++];while(--o);R=_-Z,O=U}}}else if(R+=c-o,o<i){i-=o;do U[_++]=N[R++];while(--o);R=_-Z,O=U}for(;i>2;)U[_++]=O[R++],U[_++]=O[R++],U[_++]=O[R++],i-=3;i&&(U[_++]=O[R++],i>1&&(U[_++]=O[R++]))}else{R=_-Z;do U[_++]=U[R++],U[_++]=U[R++],U[_++]=U[R++],i-=3;while(i>2);i&&(U[_++]=U[R++],i>1&&(U[_++]=U[R++]))}}else if((o&64)===0){A=L[(A&65535)+(f&(1<<o)-1)];continue i}else{n.msg=\"invalid distance code\",B.mode=30;break e}break}}else if((o&64)===0){A=M[(A&65535)+(f&(1<<o)-1)];continue t}else if(o&32){B.mode=12;break e}else{n.msg=\"invalid literal/length code\",B.mode=30;break e}break}}while(s<m&&_<u);i=d>>3,s-=i,d-=i<<3,f&=(1<<d)-1,n.next_in=s,n.next_out=_,n.avail_in=s<m?5+(m-s):5-(s-m),n.avail_out=_<u?257+(u-_):257-(_-u),B.hold=f,B.bits=d}},948:(k,I,E)=>{\"use strict\";const T=E(69),n=E(869),g=E(264),s=E(241),m=0,_=1,C=2,{Z_FINISH:u,Z_BLOCK:v,Z_TREES:l,Z_OK:h,Z_STREAM_END:c,Z_NEED_DICT:N,Z_STREAM_ERROR:f,Z_DATA_ERROR:d,Z_MEM_ERROR:M,Z_BUF_ERROR:L,Z_DEFLATED:j}=E(619),D=1,A=2,o=3,i=4,Z=5,R=6,O=7,p=8,U=9,B=10,K=11,V=12,fe=13,de=14,ne=15,ce=16,pe=17,le=18,te=19,re=20,ae=21,we=22,_e=23,ue=24,he=25,Te=26,ke=27,Oe=28,De=29,F=30,Ee=31,Pe=32,Fe=852,je=592,He=15,Re=t=>(t>>>24&255)+(t>>>8&65280)+((t&65280)<<8)+((t&255)<<24);function ze(){this.mode=0,this.last=!1,this.wrap=0,this.havedict=!1,this.flags=0,this.dmax=0,this.check=0,this.total=0,this.head=null,this.wbits=0,this.wsize=0,this.whave=0,this.wnext=0,this.window=null,this.hold=0,this.bits=0,this.length=0,this.offset=0,this.extra=0,this.lencode=null,this.distcode=null,this.lenbits=0,this.distbits=0,this.ncode=0,this.nlen=0,this.ndist=0,this.have=0,this.next=null,this.lens=new Uint16Array(320),this.work=new Uint16Array(288),this.lendyn=null,this.distdyn=null,this.sane=0,this.back=0,this.was=0}const Ie=t=>{if(!t||!t.state)return f;const x=t.state;return t.total_in=t.total_out=x.total=0,t.msg=\"\",x.wrap&&(t.adler=x.wrap&1),x.mode=D,x.last=0,x.havedict=0,x.dmax=32768,x.head=null,x.hold=0,x.bits=0,x.lencode=x.lendyn=new Int32Array(Fe),x.distcode=x.distdyn=new Int32Array(je),x.sane=1,x.back=-1,h},Ue=t=>{if(!t||!t.state)return f;const x=t.state;return x.wsize=0,x.whave=0,x.wnext=0,Ie(t)},Ce=(t,x)=>{let e;if(!t||!t.state)return f;const y=t.state;return x<0?(e=0,x=-x):(e=(x>>4)+1,x<48&&(x&=15)),x&&(x<8||x>15)?f:(y.window!==null&&y.wbits!==x&&(y.window=null),y.wrap=e,y.wbits=x,Ue(t))},Ne=(t,x)=>{if(!t)return f;const e=new ze;t.state=e,e.window=null;const y=Ce(t,x);return y!==h&&(t.state=null),y},Ye=t=>Ne(t,He);let Be=!0,Ae,Se;const Ge=t=>{if(Be){Ae=new Int32Array(512),Se=new Int32Array(32);let x=0;for(;x<144;)t.lens[x++]=8;for(;x<256;)t.lens[x++]=9;for(;x<280;)t.lens[x++]=7;for(;x<288;)t.lens[x++]=8;for(s(_,t.lens,0,288,Ae,0,t.work,{bits:9}),x=0;x<32;)t.lens[x++]=5;s(C,t.lens,0,32,Se,0,t.work,{bits:5}),Be=!1}t.lencode=Ae,t.lenbits=9,t.distcode=Se,t.distbits=5},Me=(t,x,e,y)=>{let H;const w=t.state;return w.window===null&&(w.wsize=1<<w.wbits,w.wnext=0,w.whave=0,w.window=new Uint8Array(w.wsize)),y>=w.wsize?(w.window.set(x.subarray(e-w.wsize,e),0),w.wnext=0,w.whave=w.wsize):(H=w.wsize-w.wnext,H>y&&(H=y),w.window.set(x.subarray(e-y,e-y+H),w.wnext),y-=H,y?(w.window.set(x.subarray(e-y,e),0),w.wnext=y,w.whave=w.wsize):(w.wnext+=H,w.wnext===w.wsize&&(w.wnext=0),w.whave<w.wsize&&(w.whave+=H))),0},Xe=(t,x)=>{let e,y,H,w,q,b,G,a,r,xe,z,S,be,me,Y=0,P,J,$,Q,ve,ge,X,ee;const W=new Uint8Array(4);let oe,ie;const Le=new Uint8Array([16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15]);if(!t||!t.state||!t.output||!t.input&&t.avail_in!==0)return f;e=t.state,e.mode===V&&(e.mode=fe),q=t.next_out,H=t.output,G=t.avail_out,w=t.next_in,y=t.input,b=t.avail_in,a=e.hold,r=e.bits,xe=b,z=G,ee=h;e:for(;;)switch(e.mode){case D:if(e.wrap===0){e.mode=fe;break}for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(e.wrap&2&&a===35615){e.check=0,W[0]=a&255,W[1]=a>>>8&255,e.check=n(e.check,W,2,0),a=0,r=0,e.mode=A;break}if(e.flags=0,e.head&&(e.head.done=!1),!(e.wrap&1)||(((a&255)<<8)+(a>>8))%31){t.msg=\"incorrect header check\",e.mode=F;break}if((a&15)!==j){t.msg=\"unknown compression method\",e.mode=F;break}if(a>>>=4,r-=4,X=(a&15)+8,e.wbits===0)e.wbits=X;else if(X>e.wbits){t.msg=\"invalid window size\",e.mode=F;break}e.dmax=1<<e.wbits,t.adler=e.check=1,e.mode=a&512?B:V,a=0,r=0;break;case A:for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(e.flags=a,(e.flags&255)!==j){t.msg=\"unknown compression method\",e.mode=F;break}if(e.flags&57344){t.msg=\"unknown header flags set\",e.mode=F;break}e.head&&(e.head.text=a>>8&1),e.flags&512&&(W[0]=a&255,W[1]=a>>>8&255,e.check=n(e.check,W,2,0)),a=0,r=0,e.mode=o;case o:for(;r<32;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.head&&(e.head.time=a),e.flags&512&&(W[0]=a&255,W[1]=a>>>8&255,W[2]=a>>>16&255,W[3]=a>>>24&255,e.check=n(e.check,W,4,0)),a=0,r=0,e.mode=i;case i:for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.head&&(e.head.xflags=a&255,e.head.os=a>>8),e.flags&512&&(W[0]=a&255,W[1]=a>>>8&255,e.check=n(e.check,W,2,0)),a=0,r=0,e.mode=Z;case Z:if(e.flags&1024){for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.length=a,e.head&&(e.head.extra_len=a),e.flags&512&&(W[0]=a&255,W[1]=a>>>8&255,e.check=n(e.check,W,2,0)),a=0,r=0}else e.head&&(e.head.extra=null);e.mode=R;case R:if(e.flags&1024&&(S=e.length,S>b&&(S=b),S&&(e.head&&(X=e.head.extra_len-e.length,e.head.extra||(e.head.extra=new Uint8Array(e.head.extra_len)),e.head.extra.set(y.subarray(w,w+S),X)),e.flags&512&&(e.check=n(e.check,y,S,w)),b-=S,w+=S,e.length-=S),e.length))break e;e.length=0,e.mode=O;case O:if(e.flags&2048){if(b===0)break e;S=0;do X=y[w+S++],e.head&&X&&e.length<65536&&(e.head.name+=String.fromCharCode(X));while(X&&S<b);if(e.flags&512&&(e.check=n(e.check,y,S,w)),b-=S,w+=S,X)break e}else e.head&&(e.head.name=null);e.length=0,e.mode=p;case p:if(e.flags&4096){if(b===0)break e;S=0;do X=y[w+S++],e.head&&X&&e.length<65536&&(e.head.comment+=String.fromCharCode(X));while(X&&S<b);if(e.flags&512&&(e.check=n(e.check,y,S,w)),b-=S,w+=S,X)break e}else e.head&&(e.head.comment=null);e.mode=U;case U:if(e.flags&512){for(;r<16;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(a!==(e.check&65535)){t.msg=\"header crc mismatch\",e.mode=F;break}a=0,r=0}e.head&&(e.head.hcrc=e.flags>>9&1,e.head.done=!0),t.adler=e.check=0,e.mode=V;break;case B:for(;r<32;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}t.adler=e.check=Re(a),a=0,r=0,e.mode=K;case K:if(e.havedict===0)return t.next_out=q,t.avail_out=G,t.next_in=w,t.avail_in=b,e.hold=a,e.bits=r,N;t.adler=e.check=1,e.mode=V;case V:if(x===v||x===l)break e;case fe:if(e.last){a>>>=r&7,r-=r&7,e.mode=ke;break}for(;r<3;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}switch(e.last=a&1,a>>>=1,r-=1,a&3){case 0:e.mode=de;break;case 1:if(Ge(e),e.mode=re,x===l){a>>>=2,r-=2;break e}break;case 2:e.mode=pe;break;case 3:t.msg=\"invalid block type\",e.mode=F}a>>>=2,r-=2;break;case de:for(a>>>=r&7,r-=r&7;r<32;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if((a&65535)!==(a>>>16^65535)){t.msg=\"invalid stored block lengths\",e.mode=F;break}if(e.length=a&65535,a=0,r=0,e.mode=ne,x===l)break e;case ne:e.mode=ce;case ce:if(S=e.length,S){if(S>b&&(S=b),S>G&&(S=G),S===0)break e;H.set(y.subarray(w,w+S),q),b-=S,w+=S,G-=S,q+=S,e.length-=S;break}e.mode=V;break;case pe:for(;r<14;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(e.nlen=(a&31)+257,a>>>=5,r-=5,e.ndist=(a&31)+1,a>>>=5,r-=5,e.ncode=(a&15)+4,a>>>=4,r-=4,e.nlen>286||e.ndist>30){t.msg=\"too many length or distance symbols\",e.mode=F;break}e.have=0,e.mode=le;case le:for(;e.have<e.ncode;){for(;r<3;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.lens[Le[e.have++]]=a&7,a>>>=3,r-=3}for(;e.have<19;)e.lens[Le[e.have++]]=0;if(e.lencode=e.lendyn,e.lenbits=7,oe={bits:e.lenbits},ee=s(m,e.lens,0,19,e.lencode,0,e.work,oe),e.lenbits=oe.bits,ee){t.msg=\"invalid code lengths set\",e.mode=F;break}e.have=0,e.mode=te;case te:for(;e.have<e.nlen+e.ndist;){for(;Y=e.lencode[a&(1<<e.lenbits)-1],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if($<16)a>>>=P,r-=P,e.lens[e.have++]=$;else{if($===16){for(ie=P+2;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(a>>>=P,r-=P,e.have===0){t.msg=\"invalid bit length repeat\",e.mode=F;break}X=e.lens[e.have-1],S=3+(a&3),a>>>=2,r-=2}else if($===17){for(ie=P+3;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}a>>>=P,r-=P,X=0,S=3+(a&7),a>>>=3,r-=3}else{for(ie=P+7;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}a>>>=P,r-=P,X=0,S=11+(a&127),a>>>=7,r-=7}if(e.have+S>e.nlen+e.ndist){t.msg=\"invalid bit length repeat\",e.mode=F;break}for(;S--;)e.lens[e.have++]=X}}if(e.mode===F)break;if(e.lens[256]===0){t.msg=\"invalid code -- missing end-of-block\",e.mode=F;break}if(e.lenbits=9,oe={bits:e.lenbits},ee=s(_,e.lens,0,e.nlen,e.lencode,0,e.work,oe),e.lenbits=oe.bits,ee){t.msg=\"invalid literal/lengths set\",e.mode=F;break}if(e.distbits=6,e.distcode=e.distdyn,oe={bits:e.distbits},ee=s(C,e.lens,e.nlen,e.ndist,e.distcode,0,e.work,oe),e.distbits=oe.bits,ee){t.msg=\"invalid distances set\",e.mode=F;break}if(e.mode=re,x===l)break e;case re:e.mode=ae;case ae:if(b>=6&&G>=258){t.next_out=q,t.avail_out=G,t.next_in=w,t.avail_in=b,e.hold=a,e.bits=r,g(t,z),q=t.next_out,H=t.output,G=t.avail_out,w=t.next_in,y=t.input,b=t.avail_in,a=e.hold,r=e.bits,e.mode===V&&(e.back=-1);break}for(e.back=0;Y=e.lencode[a&(1<<e.lenbits)-1],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(J&&(J&240)===0){for(Q=P,ve=J,ge=$;Y=e.lencode[ge+((a&(1<<Q+ve)-1)>>Q)],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(Q+P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}a>>>=Q,r-=Q,e.back+=Q}if(a>>>=P,r-=P,e.back+=P,e.length=$,J===0){e.mode=Te;break}if(J&32){e.back=-1,e.mode=V;break}if(J&64){t.msg=\"invalid literal/length code\",e.mode=F;break}e.extra=J&15,e.mode=we;case we:if(e.extra){for(ie=e.extra;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.length+=a&(1<<e.extra)-1,a>>>=e.extra,r-=e.extra,e.back+=e.extra}e.was=e.length,e.mode=_e;case _e:for(;Y=e.distcode[a&(1<<e.distbits)-1],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if((J&240)===0){for(Q=P,ve=J,ge=$;Y=e.distcode[ge+((a&(1<<Q+ve)-1)>>Q)],P=Y>>>24,J=Y>>>16&255,$=Y&65535,!(Q+P<=r);){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}a>>>=Q,r-=Q,e.back+=Q}if(a>>>=P,r-=P,e.back+=P,J&64){t.msg=\"invalid distance code\",e.mode=F;break}e.offset=$,e.extra=J&15,e.mode=ue;case ue:if(e.extra){for(ie=e.extra;r<ie;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}e.offset+=a&(1<<e.extra)-1,a>>>=e.extra,r-=e.extra,e.back+=e.extra}if(e.offset>e.dmax){t.msg=\"invalid distance too far back\",e.mode=F;break}e.mode=he;case he:if(G===0)break e;if(S=z-G,e.offset>S){if(S=e.offset-S,S>e.whave&&e.sane){t.msg=\"invalid distance too far back\",e.mode=F;break}S>e.wnext?(S-=e.wnext,be=e.wsize-S):be=e.wnext-S,S>e.length&&(S=e.length),me=e.window}else me=H,be=q-e.offset,S=e.length;S>G&&(S=G),G-=S,e.length-=S;do H[q++]=me[be++];while(--S);e.length===0&&(e.mode=ae);break;case Te:if(G===0)break e;H[q++]=e.length,G--,e.mode=ae;break;case ke:if(e.wrap){for(;r<32;){if(b===0)break e;b--,a|=y[w++]<<r,r+=8}if(z-=G,t.total_out+=z,e.total+=z,z&&(t.adler=e.check=e.flags?n(e.check,H,z,q-z):T(e.check,H,z,q-z)),z=G,(e.flags?a:Re(a))!==e.check){t.msg=\"incorrect data check\",e.mode=F;break}a=0,r=0}e.mode=Oe;case Oe:if(e.wrap&&e.flags){for(;r<32;){if(b===0)break e;b--,a+=y[w++]<<r,r+=8}if(a!==(e.total&4294967295)){t.msg=\"incorrect length check\",e.mode=F;break}a=0,r=0}e.mode=De;case De:ee=c;break e;case F:ee=d;break e;case Ee:return M;case Pe:default:return f}return t.next_out=q,t.avail_out=G,t.next_in=w,t.avail_in=b,e.hold=a,e.bits=r,(e.wsize||z!==t.avail_out&&e.mode<F&&(e.mode<ke||x!==u))&&Me(t,t.output,t.next_out,z-t.avail_out)?(e.mode=Ee,M):(xe-=t.avail_in,z-=t.avail_out,t.total_in+=xe,t.total_out+=z,e.total+=z,e.wrap&&z&&(t.adler=e.check=e.flags?n(e.check,H,z,t.next_out-z):T(e.check,H,z,t.next_out-z)),t.data_type=e.bits+(e.last?64:0)+(e.mode===V?128:0)+(e.mode===re||e.mode===ne?256:0),(xe===0&&z===0||x===u)&&ee===h&&(ee=L),ee)},Ke=t=>{if(!t||!t.state)return f;let x=t.state;return x.window&&(x.window=null),t.state=null,h},Ve=(t,x)=>{if(!t||!t.state)return f;const e=t.state;return(e.wrap&2)===0?f:(e.head=x,x.done=!1,h)},We=(t,x)=>{const e=x.length;let y,H,w;return!t||!t.state||(y=t.state,y.wrap!==0&&y.mode!==K)?f:y.mode===K&&(H=1,H=T(H,x,e,0),H!==y.check)?d:(w=Me(t,x,e,e),w?(y.mode=Ee,M):(y.havedict=1,h))};k.exports.inflateReset=Ue,k.exports.inflateReset2=Ce,k.exports.inflateResetKeep=Ie,k.exports.inflateInit=Ye,k.exports.inflateInit2=Ne,k.exports.inflate=Xe,k.exports.inflateEnd=Ke,k.exports.inflateGetHeader=Ve,k.exports.inflateSetDictionary=We,k.exports.inflateInfo=\"pako inflate (from Nodeca project)\"},241:k=>{\"use strict\";const m=new Uint16Array([3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,0,0]),_=new Uint8Array([16,16,16,16,16,16,16,16,17,17,17,17,18,18,18,18,19,19,19,19,20,20,20,20,21,21,21,21,16,72,78]),C=new Uint16Array([1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577,0,0]),u=new Uint8Array([16,16,16,16,17,17,18,18,19,19,20,20,21,21,22,22,23,23,24,24,25,25,26,26,27,27,28,28,29,29,64,64]),v=(l,h,c,N,f,d,M,L)=>{const j=L.bits;let D=0,A=0,o=0,i=0,Z=0,R=0,O=0,p=0,U=0,B=0,K,V,fe,de,ne,ce=null,pe=0,le;const te=new Uint16Array(15+1),re=new Uint16Array(15+1);let ae=null,we=0,_e,ue,he;for(D=0;D<=15;D++)te[D]=0;for(A=0;A<N;A++)te[h[c+A]]++;for(Z=j,i=15;i>=1&&te[i]===0;i--);if(Z>i&&(Z=i),i===0)return f[d++]=1<<24|64<<16|0,f[d++]=1<<24|64<<16|0,L.bits=1,0;for(o=1;o<i&&te[o]===0;o++);for(Z<o&&(Z=o),p=1,D=1;D<=15;D++)if(p<<=1,p-=te[D],p<0)return-1;if(p>0&&(l===0||i!==1))return-1;for(re[1]=0,D=1;D<15;D++)re[D+1]=re[D]+te[D];for(A=0;A<N;A++)h[c+A]!==0&&(M[re[h[c+A]]++]=A);if(l===0?(ce=ae=M,le=19):l===1?(ce=m,pe-=257,ae=_,we-=257,le=256):(ce=C,ae=u,le=-1),B=0,A=0,D=o,ne=d,R=Z,O=0,fe=-1,U=1<<Z,de=U-1,l===1&&U>852||l===2&&U>592)return 1;for(;;){_e=D-O,M[A]<le?(ue=0,he=M[A]):M[A]>le?(ue=ae[we+M[A]],he=ce[pe+M[A]]):(ue=32+64,he=0),K=1<<D-O,V=1<<R,o=V;do V-=K,f[ne+(B>>O)+V]=_e<<24|ue<<16|he|0;while(V!==0);for(K=1<<D-1;B&K;)K>>=1;if(K!==0?(B&=K-1,B+=K):B=0,A++,--te[D]===0){if(D===i)break;D=h[c+M[A]]}if(D>Z&&(B&de)!==fe){for(O===0&&(O=Z),ne+=o,R=D-O,p=1<<R;R+O<i&&(p-=te[R+O],!(p<=0));)R++,p<<=1;if(U+=1<<R,l===1&&U>852||l===2&&U>592)return 1;fe=B&de,f[fe]=Z<<24|R<<16|ne-d|0}}return B!==0&&(f[ne+B]=D-O<<24|64<<16|0),L.bits=Z,0};k.exports=v},898:k=>{\"use strict\";k.exports={2:\"need dictionary\",1:\"stream end\",0:\"\",\"-1\":\"file error\",\"-2\":\"stream error\",\"-3\":\"data error\",\"-4\":\"insufficient memory\",\"-5\":\"buffer error\",\"-6\":\"incompatible version\"}},292:k=>{\"use strict\";function I(){this.input=null,this.next_in=0,this.avail_in=0,this.total_in=0,this.output=null,this.next_out=0,this.avail_out=0,this.total_out=0,this.msg=\"\",this.state=null,this.data_type=2,this.adler=0}k.exports=I},330:(k,I,E)=>{\"use strict\";E.d(I,{default:()=>C});var T=E(829),n=E(861),g=E.n(n),s=E(843);function m(u){if(u.__type__==\"npy\"){var v;if(window.obj=u,u.hasOwnProperty(\"zdata\")){const f=Uint8Array.from(window.atob(u.zdata),d=>d.charCodeAt(0));v=(0,s.rr)(f)}else v=Uint8Array.from(window.atob(u.data),f=>f.charCodeAt(0));var l=(0,T.g)(v.buffer);if(l=n(l.data,l.shape),u.hasOwnProperty(\"min\")){let f=l.dtype===\"uint8\"?255:65535;for(var h=1,c=0;c<l.shape.length;c++)h=h*l.shape[c];for(var N=n(new Float32Array(h),l.shape),c=0;c<l.data.length;c++)N.data[c]=u.min+(u.max-u.min)*l.data[c]/f;return N}else return l}else return{}}function _(u){if(Array.isArray(u)){var v=[];for(var l of u)v.push(_(l));return v}else if(u instanceof Object){if(u.hasOwnProperty(\"__type__\"))return m(u);var v={};for(var h of Object.keys(u))v[h]=_(u[h]);return v}else return u}const C=loader={unpack_obj:_}}},ye={};function se(k){if(ye[k])return ye[k].exports;var I=ye[k]={exports:{}};return Ze[k](I,I.exports,se),I.exports}return se.n=k=>{var I=k&&k.__esModule?()=>k.default:()=>k;return se.d(I,{a:I}),I},se.d=(k,I)=>{for(var E in I)se.o(I,E)&&!se.o(k,E)&&Object.defineProperty(k,E,{enumerable:!0,get:I[E]})},se.o=(k,I)=>Object.prototype.hasOwnProperty.call(k,I),se(330)})().default;\n",
              "</script>\n",
              "<script>var AttentionMulti;AttentionMulti=(()=>{\"use strict\";var St={143:(x,B,te)=>{te.d(B,{default:()=>mn});function P(){}const me=e=>e;function jt(e,t){for(const n in t)e[n]=t[n];return e}function Mt(e){return e&&typeof e==\"object\"&&typeof e.then==\"function\"}function En(e,t,n,i,o){e.__svelte_meta={loc:{file:t,line:n,column:i,char:o}}}function Ge(e){return e()}function Se(){return Object.create(null)}function H(e){e.forEach(Ge)}function fe(e){return typeof e==\"function\"}function je(e,t){return e!=e?t==t:e!==t||e&&typeof e==\"object\"||typeof e==\"function\"}function Sn(e,t){return e!=e?t==t:e!==t}function Ke(e){return Object.keys(e).length===0}function jn(e,t){if(e!=null&&typeof e.subscribe!=\"function\")throw new Error(`'${t}' is not a store with a 'subscribe' method`)}function Qe(e,...t){if(e==null)return P;const n=e.subscribe(...t);return n.unsubscribe?()=>n.unsubscribe():n}function Mn(e){let t;return Qe(e,n=>t=n)(),t}function An(e,t,n){e.$$.on_destroy.push(Qe(t,n))}function At(e,t,n,i){if(e){const o=Me(e,t,n,i);return e[0](o)}}function Me(e,t,n,i){return e[1]&&i?jt(n.ctx.slice(),e[1](i(t))):n.ctx}function Ze(e,t,n,i){if(e[2]&&i){const o=e[2](i(n));if(t.dirty===void 0)return o;if(typeof o==\"object\"){const l=[],s=Math.max(t.dirty.length,o.length);for(let r=0;r<s;r+=1)l[r]=t.dirty[r]|o[r];return l}return t.dirty|o}return t.dirty}function Ct(e,t,n,i,o,l,s){const r=Ze(t,i,o,l);if(r){const f=Me(t,n,i,s);e.p(f,r)}}function Cn(e,t,n,i,o,l,s,r){const f=s(o)|Ze(t,i,o,l);if(f){const a=Me(t,n,i,r);e.p(a,f)}}function Dn(e){const t={};for(const n in e)n[0]!==\"$\"&&(t[n]=e[n]);return t}function On(e,t){const n={};t=new Set(t);for(const i in e)!t.has(i)&&i[0]!==\"$\"&&(n[i]=e[i]);return n}function Tn(e){const t={};for(const n in e)t[n]=!0;return t}function Ln(e){let t=!1;return function(...n){t||(t=!0,e.call(this,...n))}}function Nn(e){return e==null?\"\":e}function Pn(e,t,n=t){return e.set(n),t}const Dt=(e,t)=>Object.prototype.hasOwnProperty.call(e,t);function Rn(e){return e&&fe(e.destroy)?e.destroy:P}const Bn=typeof window!=\"undefined\";let ae=null,ge=null;function Hn(e){ae=e}function xn(e){ge=e}const K=new Set;function $e(e){K.forEach(t=>{t.c(e)||(K.delete(t),t.f())}),K.size!==0&&ge($e)}function zn(){K.clear()}function ve(e){let t;return K.size===0&&ge($e),{promise:new Promise(n=>{K.add(t={c:e,f:n})}),abort(){K.delete(t)}}}function E(e,t){e.appendChild(t)}function C(e,t,n){e.insertBefore(t,n||null)}function j(e){e.parentNode.removeChild(e)}function et(e,t){for(let n=0;n<e.length;n+=1)e[n]&&e[n].d(t)}function F(e){return document.createElement(e)}function In(e,t){return document.createElement(e,{is:t})}function Vn(e,t){const n={};for(const i in e)Dt(e,i)&&t.indexOf(i)===-1&&(n[i]=e[i]);return n}function Ot(e){return document.createElementNS(\"http://www.w3.org/2000/svg\",e)}function R(e){return document.createTextNode(e)}function T(){return R(\" \")}function tt(){return R(\"\")}function z(e,t,n,i){return e.addEventListener(t,n,i),()=>e.removeEventListener(t,n,i)}function Wn(e){return function(t){return t.preventDefault(),e.call(this,t)}}function Yn(e){return function(t){return t.stopPropagation(),e.call(this,t)}}function Un(e){return function(t){t.target===this&&e.call(this,t)}}function y(e,t,n){n==null?e.removeAttribute(t):e.getAttribute(t)!==n&&e.setAttribute(t,n)}function Jn(e,t){const n=Object.getOwnPropertyDescriptors(e.__proto__);for(const i in t)t[i]==null?e.removeAttribute(i):i===\"style\"?e.style.cssText=t[i]:i===\"__value\"?e.value=e[i]=t[i]:n[i]&&n[i].set?e[i]=t[i]:y(e,i,t[i])}function Xn(e,t){for(const n in t)y(e,n,t[n])}function Gn(e,t,n){t in e?e[t]=n:y(e,t,n)}function Kn(e,t,n){e.setAttributeNS(\"http://www.w3.org/1999/xlink\",t,n)}function Qn(e,t,n){const i=new Set;for(let o=0;o<e.length;o+=1)e[o].checked&&i.add(e[o].__value);return n||i.delete(t),Array.from(i)}function Zn(e){return e===\"\"?null:+e}function $n(e){const t=[];for(let n=0;n<e.length;n+=1)t.push({start:e.start(n),end:e.end(n)});return t}function Tt(e){return Array.from(e.childNodes)}function ei(e,t,n,i){for(let o=0;o<e.length;o+=1){const l=e[o];if(l.nodeName===t){let s=0;const r=[];for(;s<l.attributes.length;){const f=l.attributes[s++];n[f.name]||r.push(f.name)}for(let f=0;f<r.length;f++)l.removeAttribute(r[f]);return e.splice(o,1)[0]}}return i?Ot(t):F(t)}function Lt(e,t){for(let n=0;n<e.length;n+=1){const i=e[n];if(i.nodeType===3)return i.data=\"\"+t,e.splice(n,1)[0]}return R(t)}function ti(e){return Lt(e,\" \")}function ke(e,t){t=\"\"+t,e.wholeText!==t&&(e.data=t)}function ni(e,t){e.value=t==null?\"\":t}function ii(e,t){try{e.type=t}catch(n){}}function S(e,t,n,i){e.style.setProperty(t,n,i?\"important\":\"\")}function oi(e,t){for(let n=0;n<e.options.length;n+=1){const i=e.options[n];if(i.__value===t){i.selected=!0;return}}}function li(e,t){for(let n=0;n<e.options.length;n+=1){const i=e.options[n];i.selected=~t.indexOf(i.__value)}}function si(e){const t=e.querySelector(\":checked\")||e.options[0];return t&&t.__value}function ri(e){return[].map.call(e.querySelectorAll(\":checked\"),t=>t.__value)}let be;function Nt(){if(be===void 0){be=!1;try{typeof window!=\"undefined\"&&window.parent&&window.parent.document}catch(e){be=!0}}return be}function ui(e,t){getComputedStyle(e).position===\"static\"&&(e.style.position=\"relative\");const i=F(\"iframe\");i.setAttribute(\"style\",\"display: block; position: absolute; top: 0; left: 0; width: 100%; height: 100%; overflow: hidden; border: 0; opacity: 0; pointer-events: none; z-index: -1;\"),i.setAttribute(\"aria-hidden\",\"true\"),i.tabIndex=-1;const o=Nt();let l;return o?(i.src=\"data:text/html,<script>onresize=function(){parent.postMessage(0,'*')}<\\/script>\",l=z(window,\"message\",s=>{s.source===i.contentWindow&&t()})):(i.src=\"about:blank\",i.onload=()=>{l=z(i.contentWindow,\"resize\",t)}),E(e,i),()=>{(o||l&&i.contentWindow)&&l(),j(i)}}function fi(e,t,n){e.classList[n?\"add\":\"remove\"](t)}function Ae(e,t){const n=document.createEvent(\"CustomEvent\");return n.initCustomEvent(e,!1,!1,t),n}function ai(e,t=document.body){return Array.from(t.querySelectorAll(e))}class ci{constructor(t=null){this.a=t,this.e=this.n=null}m(t,n,i=null){this.e||(this.e=F(n.nodeName),this.t=n,this.h(t)),this.i(i)}h(t){this.e.innerHTML=t,this.n=Array.from(this.e.childNodes)}i(t){for(let n=0;n<this.n.length;n+=1)C(this.t,this.n[n],t)}p(t){this.d(),this.h(t),this.i(this.a)}d(){this.n.forEach(j)}}function di(e){const t={};for(const n of e)t[n.name]=n.value;return t}function _i(e){const t={};return e.childNodes.forEach(n=>{t[n.slot||\"default\"]=!0}),t}const Ce=new Set;let ye=0;function Pt(e){let t=5381,n=e.length;for(;n--;)t=(t<<5)-t^e.charCodeAt(n);return t>>>0}function ce(e,t,n,i,o,l,s,r=0){const f=16.666/i;let a=`{\n",
              "`;for(let u=0;u<=1;u+=f){const _=t+(n-t)*l(u);a+=u*100+`%{${s(_,1-_)}}\n",
              "`}const c=a+`100% {${s(n,1-n)}}\n",
              "}`,d=`__svelte_${Pt(c)}_${r}`,h=e.ownerDocument;Ce.add(h);const p=h.__svelte_stylesheet||(h.__svelte_stylesheet=h.head.appendChild(F(\"style\")).sheet),m=h.__svelte_rules||(h.__svelte_rules={});m[d]||(m[d]=!0,p.insertRule(`@keyframes ${d} ${c}`,p.cssRules.length));const g=e.style.animation||\"\";return e.style.animation=`${g?`${g}, `:\"\"}${d} ${i}ms linear ${o}ms 1 both`,ye+=1,d}function de(e,t){const n=(e.style.animation||\"\").split(\", \"),i=n.filter(t?l=>l.indexOf(t)<0:l=>l.indexOf(\"__svelte\")===-1),o=n.length-i.length;o&&(e.style.animation=i.join(\", \"),ye-=o,ye||Rt())}function Rt(){ge(()=>{ye||(Ce.forEach(e=>{const t=e.__svelte_stylesheet;let n=t.cssRules.length;for(;n--;)t.deleteRule(n);e.__svelte_rules={}}),Ce.clear())})}function hi(e,t,n,i){if(!t)return P;const o=e.getBoundingClientRect();if(t.left===o.left&&t.right===o.right&&t.top===o.top&&t.bottom===o.bottom)return P;const{delay:l=0,duration:s=300,easing:r=me,start:f=ae()+l,end:a=f+s,tick:c=P,css:d}=n(e,{from:t,to:o},i);let h=!0,p=!1,m;function g(){d&&(m=ce(e,0,1,s,l,r,d)),l||(p=!0)}function u(){d&&de(e,m),h=!1}return ve(_=>{if(!p&&_>=f&&(p=!0),p&&_>=a&&(c(1,0),u()),!h)return!1;if(p){const k=_-f,w=0+1*r(k/s);c(w,1-w)}return!0}),g(),c(0,1),u}function pi(e){const t=getComputedStyle(e);if(t.position!==\"absolute\"&&t.position!==\"fixed\"){const{width:n,height:i}=t,o=e.getBoundingClientRect();e.style.position=\"absolute\",e.style.width=n,e.style.height=i,Bt(e,o)}}function Bt(e,t){const n=e.getBoundingClientRect();if(t.left!==n.left||t.top!==n.top){const i=getComputedStyle(e),o=i.transform===\"none\"?\"\":i.transform;e.style.transform=`${o} translate(${t.left-n.left}px, ${t.top-n.top}px)`}}let _e;function I(e){_e=e}function U(){if(!_e)throw new Error(\"Function called outside component initialization\");return _e}function mi(e){U().$$.before_update.push(e)}function Ht(e){U().$$.on_mount.push(e)}function gi(e){U().$$.after_update.push(e)}function vi(e){U().$$.on_destroy.push(e)}function ki(){const e=U();return(t,n)=>{const i=e.$$.callbacks[t];if(i){const o=Ae(t,n);i.slice().forEach(l=>{l.call(e,o)})}}}function bi(e,t){U().$$.context.set(e,t)}function yi(e){return U().$$.context.get(e)}function wi(e){return U().$$.context.has(e)}function Fi(e,t){const n=e.$$.callbacks[t.type];n&&n.slice().forEach(i=>i(t))}const he=[],qi={enabled:!1},ne=[],we=[],De=[],nt=Promise.resolve();let Oe=!1;function it(){Oe||(Oe=!0,nt.then(Ne))}function Ei(){return it(),nt}function ie(e){we.push(e)}function ot(e){De.push(e)}let Te=!1;const Le=new Set;function Ne(){if(!Te){Te=!0;do{for(let e=0;e<he.length;e+=1){const t=he[e];I(t),xt(t.$$)}for(I(null),he.length=0;ne.length;)ne.pop()();for(let e=0;e<we.length;e+=1){const t=we[e];Le.has(t)||(Le.add(t),t())}we.length=0}while(he.length);for(;De.length;)De.pop()();Oe=!1,Te=!1,Le.clear()}}function xt(e){if(e.fragment!==null){e.update(),H(e.before_update);const t=e.dirty;e.dirty=[-1],e.fragment&&e.fragment.p(e.ctx,t),e.after_update.forEach(ie)}}let pe;function Pe(){return pe||(pe=Promise.resolve(),pe.then(()=>{pe=null})),pe}function Q(e,t,n){e.dispatchEvent(Ae(`${t?\"intro\":\"outro\"}${n}`))}const Fe=new Set;let V;function oe(){V={r:0,c:[],p:V}}function le(){V.r||H(V.c),V=V.p}function O(e,t){e&&e.i&&(Fe.delete(e),e.i(t))}function L(e,t,n,i){if(e&&e.o){if(Fe.has(e))return;Fe.add(e),V.c.push(()=>{Fe.delete(e),i&&(n&&e.d(1),i())}),e.o(t)}}const Re={duration:0};function Si(e,t,n){let i=t(e,n),o=!1,l,s,r=0;function f(){l&&de(e,l)}function a(){const{delay:d=0,duration:h=300,easing:p=me,tick:m=P,css:g}=i||Re;g&&(l=ce(e,0,1,h,d,p,g,r++)),m(0,1);const u=ae()+d,_=u+h;s&&s.abort(),o=!0,ie(()=>Q(e,!0,\"start\")),s=ve(k=>{if(o){if(k>=_)return m(1,0),Q(e,!0,\"end\"),f(),o=!1;if(k>=u){const w=p((k-u)/h);m(w,1-w)}}return o})}let c=!1;return{start(){c||(de(e),fe(i)?(i=i(),Pe().then(a)):a())},invalidate(){c=!1},end(){o&&(f(),o=!1)}}}function ji(e,t,n){let i=t(e,n),o=!0,l;const s=V;s.r+=1;function r(){const{delay:f=0,duration:a=300,easing:c=me,tick:d=P,css:h}=i||Re;h&&(l=ce(e,1,0,a,f,c,h));const p=ae()+f,m=p+a;ie(()=>Q(e,!1,\"start\")),ve(g=>{if(o){if(g>=m)return d(0,1),Q(e,!1,\"end\"),--s.r||H(s.c),!1;if(g>=p){const u=c((g-p)/a);d(1-u,u)}}return o})}return fe(i)?Pe().then(()=>{i=i(),r()}):r(),{end(f){f&&i.tick&&i.tick(1,0),o&&(l&&de(e,l),o=!1)}}}function Mi(e,t,n,i){let o=t(e,n),l=i?0:1,s=null,r=null,f=null;function a(){f&&de(e,f)}function c(h,p){const m=h.b-l;return p*=Math.abs(m),{a:l,b:h.b,d:m,duration:p,start:h.start,end:h.start+p,group:h.group}}function d(h){const{delay:p=0,duration:m=300,easing:g=me,tick:u=P,css:_}=o||Re,k={start:ae()+p,b:h};h||(k.group=V,V.r+=1),s||r?r=k:(_&&(a(),f=ce(e,l,h,m,p,g,_)),h&&u(0,1),s=c(k,m),ie(()=>Q(e,h,\"start\")),ve(w=>{if(r&&w>r.start&&(s=c(r,m),r=null,Q(e,s.b,\"start\"),_&&(a(),f=ce(e,l,s.b,s.duration,0,g,o.css))),s){if(w>=s.end)u(l=s.b,1-l),Q(e,s.b,\"end\"),r||(s.b?a():--s.group.r||H(s.group.c)),s=null;else if(w>=s.start){const M=w-s.start;l=s.a+s.d*g(M/s.duration),u(l,1-l)}}return!!(s||r)}))}return{run(h){fe(o)?Pe().then(()=>{o=o(),d(h)}):d(h)},end(){a(),s=r=null}}}function Ai(e,t){const n=t.token={};function i(o,l,s,r){if(t.token!==n)return;t.resolved=r;let f=t.ctx;s!==void 0&&(f=f.slice(),f[s]=r);const a=o&&(t.current=o)(f);let c=!1;t.block&&(t.blocks?t.blocks.forEach((d,h)=>{h!==l&&d&&(oe(),L(d,1,1,()=>{t.blocks[h]===d&&(t.blocks[h]=null)}),le())}):t.block.d(1),a.c(),O(a,1),a.m(t.mount(),t.anchor),c=!0),t.block=a,t.blocks&&(t.blocks[l]=a),c&&Ne()}if(Mt(e)){const o=U();if(e.then(l=>{I(o),i(t.then,1,t.value,l),I(null)},l=>{if(I(o),i(t.catch,2,t.error,l),I(null),!t.hasCatch)throw l}),t.current!==t.pending)return i(t.pending,0),!0}else{if(t.current!==t.then)return i(t.then,1,t.value,e),!0;t.resolved=e}}const Ci=typeof window!=\"undefined\"?window:typeof globalThis!=\"undefined\"?globalThis:global;function zt(e,t){e.d(1),t.delete(e.key)}function It(e,t){L(e,1,1,()=>{t.delete(e.key)})}function Di(e,t){e.f(),zt(e,t)}function Oi(e,t){e.f(),It(e,t)}function Ti(e,t,n,i,o,l,s,r,f,a,c,d){let h=e.length,p=l.length,m=h;const g={};for(;m--;)g[e[m].key]=m;const u=[],_=new Map,k=new Map;for(m=p;m--;){const b=d(o,l,m),v=n(b);let q=s.get(v);q?i&&q.p(b,t):(q=a(v,b),q.c()),_.set(v,u[m]=q),v in g&&k.set(v,Math.abs(m-g[v]))}const w=new Set,M=new Set;function N(b){O(b,1),b.m(r,c),s.set(b.key,b),c=b.first,p--}for(;h&&p;){const b=u[p-1],v=e[h-1],q=b.key,D=v.key;b===v?(c=b.first,h--,p--):_.has(D)?!s.has(q)||w.has(q)?N(b):M.has(D)?h--:k.get(q)>k.get(D)?(M.add(q),N(b)):(w.add(D),h--):(f(v,s),h--)}for(;h--;){const b=e[h];_.has(b.key)||f(b,s)}for(;p;)N(u[p-1]);return u}function Li(e,t,n,i){const o=new Set;for(let l=0;l<t.length;l++){const s=i(n(e,t,l));if(o.has(s))throw new Error(\"Cannot have duplicate keys in a keyed each\");o.add(s)}}function Ni(e,t){const n={},i={},o={$$scope:1};let l=e.length;for(;l--;){const s=e[l],r=t[l];if(r){for(const f in s)f in r||(i[f]=1);for(const f in r)o[f]||(n[f]=r[f],o[f]=1);e[l]=r}else for(const f in s)o[f]=1}for(const s in i)s in n||(n[s]=void 0);return n}function Pi(e){return typeof e==\"object\"&&e!==null?e:{}}const Vt=new Set([\"allowfullscreen\",\"allowpaymentrequest\",\"async\",\"autofocus\",\"autoplay\",\"checked\",\"controls\",\"default\",\"defer\",\"disabled\",\"formnovalidate\",\"hidden\",\"ismap\",\"loop\",\"multiple\",\"muted\",\"nomodule\",\"novalidate\",\"open\",\"playsinline\",\"readonly\",\"required\",\"reversed\",\"selected\"]),Wt=/[\\s'\">/=\\u{FDD0}-\\u{FDEF}\\u{FFFE}\\u{FFFF}\\u{1FFFE}\\u{1FFFF}\\u{2FFFE}\\u{2FFFF}\\u{3FFFE}\\u{3FFFF}\\u{4FFFE}\\u{4FFFF}\\u{5FFFE}\\u{5FFFF}\\u{6FFFE}\\u{6FFFF}\\u{7FFFE}\\u{7FFFF}\\u{8FFFE}\\u{8FFFF}\\u{9FFFE}\\u{9FFFF}\\u{AFFFE}\\u{AFFFF}\\u{BFFFE}\\u{BFFFF}\\u{CFFFE}\\u{CFFFF}\\u{DFFFE}\\u{DFFFF}\\u{EFFFE}\\u{EFFFF}\\u{FFFFE}\\u{FFFFF}\\u{10FFFE}\\u{10FFFF}]/u;function Ri(e,t){const n=Object.assign({},...e);t&&(n.class==null?n.class=t:n.class+=\" \"+t);let i=\"\";return Object.keys(n).forEach(o=>{if(Wt.test(o))return;const l=n[o];l===!0?i+=\" \"+o:Vt.has(o.toLowerCase())?l&&(i+=\" \"+o):l!=null&&(i+=` ${o}=\"${String(l).replace(/\"/g,\"&#34;\").replace(/'/g,\"&#39;\")}\"`)}),i}const Yt={'\"':\"&quot;\",\"'\":\"&#39;\",\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\"};function Ut(e){return String(e).replace(/[\"'&<>]/g,t=>Yt[t])}function Bi(e,t){let n=\"\";for(let i=0;i<e.length;i+=1)n+=t(e[i],i);return n}const Hi={$$render:()=>\"\"};function xi(e,t){if(!e||!e.$$render)throw t===\"svelte:component\"&&(t+=\" this={...}\"),new Error(`<${t}> is not a valid SSR component. You may need to review your build config to ensure that dependencies are compiled, rather than imported as pre-compiled modules`);return e}function zi(e,t,n,i){return console.log(`{@debug} ${e?e+\" \":\"\"}(${t}:${n})`),console.log(i),\"\"}let Be;function Ii(e){function t(n,i,o,l){const s=_e,r={on_destroy:Be,context:new Map(s?s.$$.context:[]),on_mount:[],before_update:[],after_update:[],callbacks:Se()};I({$$:r});const f=e(n,i,o,l);return I(s),f}return{render:(n={},i={})=>{Be=[];const o={title:\"\",head:\"\",css:new Set},l=t(o,n,{},i);return H(Be),{html:l,css:{code:Array.from(o.css).map(s=>s.code).join(`\n",
              "`),map:null},head:o.title+o.head}},$$render:t}}function Vi(e,t,n){return t==null||n&&!t?\"\":` ${e}${t===!0?\"\":`=${typeof t==\"string\"?JSON.stringify(Ut(t)):`\"${t}\"`}`}`}function Wi(e){return e?` class=\"${e}\"`:\"\"}function lt(e,t,n){const i=e.$$.props[t];i!==void 0&&(e.$$.bound[i]=n,n(e.$$.ctx[i]))}function se(e){e&&e.c()}function Yi(e,t){e&&e.l(t)}function Z(e,t,n){const{fragment:i,on_mount:o,on_destroy:l,after_update:s}=e.$$;i&&i.m(t,n),ie(()=>{const r=o.map(Ge).filter(fe);l?l.push(...r):H(r),e.$$.on_mount=[]}),s.forEach(ie)}function X(e,t){const n=e.$$;n.fragment!==null&&(H(n.on_destroy),n.fragment&&n.fragment.d(t),n.on_destroy=n.fragment=null,n.ctx=[])}function Jt(e,t){e.$$.dirty[0]===-1&&(he.push(e),it(),e.$$.dirty.fill(0)),e.$$.dirty[t/31|0]|=1<<t%31}function He(e,t,n,i,o,l,s=[-1]){const r=_e;I(e);const f=t.props||{},a=e.$$={fragment:null,ctx:null,props:l,update:P,not_equal:o,bound:Se(),on_mount:[],on_destroy:[],before_update:[],after_update:[],context:new Map(r?r.$$.context:[]),callbacks:Se(),dirty:s,skip_bound:!1};let c=!1;if(a.ctx=n?n(e,f,(d,h,...p)=>{const m=p.length?p[0]:h;return a.ctx&&o(a.ctx[d],a.ctx[d]=m)&&(!a.skip_bound&&a.bound[d]&&a.bound[d](m),c&&Jt(e,d)),h}):[],a.update(),c=!0,H(a.before_update),a.fragment=i?i(a.ctx):!1,t.target){if(t.hydrate){const d=Tt(t.target);a.fragment&&a.fragment.l(d),d.forEach(j)}else a.fragment&&a.fragment.c();t.intro&&O(e.$$.fragment),Z(e,t.target,t.anchor),Ne()}I(r)}let Xt;typeof HTMLElement==\"function\"&&(Xt=class extends HTMLElement{constructor(){super(),this.attachShadow({mode:\"open\"})}connectedCallback(){for(const e in this.$$.slotted)this.appendChild(this.$$.slotted[e])}attributeChangedCallback(e,t,n){this[e]=n}$destroy(){X(this,1),this.$destroy=P}$on(e,t){const n=this.$$.callbacks[e]||(this.$$.callbacks[e]=[]);return n.push(t),()=>{const i=n.indexOf(t);i!==-1&&n.splice(i,1)}}$set(e){this.$$set&&!Ke(e)&&(this.$$.skip_bound=!0,this.$$set(e),this.$$.skip_bound=!1)}});class xe{$destroy(){X(this,1),this.$destroy=P}$on(t,n){const i=this.$$.callbacks[t]||(this.$$.callbacks[t]=[]);return i.push(n),()=>{const o=i.indexOf(n);o!==-1&&i.splice(o,1)}}$set(t){this.$$set&&!Ke(t)&&(this.$$.skip_bound=!0,this.$$set(t),this.$$.skip_bound=!1)}}function W(e,t){document.dispatchEvent(Ae(e,Object.assign({version:\"3.31.2\"},t)))}function Ui(e,t){W(\"SvelteDOMInsert\",{target:e,node:t}),E(e,t)}function Ji(e,t,n){W(\"SvelteDOMInsert\",{target:e,node:t,anchor:n}),C(e,t,n)}function ze(e){W(\"SvelteDOMRemove\",{node:e}),j(e)}function Xi(e,t){for(;e.nextSibling&&e.nextSibling!==t;)ze(e.nextSibling)}function Gi(e){for(;e.previousSibling;)ze(e.previousSibling)}function Ki(e){for(;e.nextSibling;)ze(e.nextSibling)}function Qi(e,t,n,i,o,l){const s=i===!0?[\"capture\"]:i?Array.from(Object.keys(i)):[];o&&s.push(\"preventDefault\"),l&&s.push(\"stopPropagation\"),W(\"SvelteDOMAddEventListener\",{node:e,event:t,handler:n,modifiers:s});const r=z(e,t,n,i);return()=>{W(\"SvelteDOMRemoveEventListener\",{node:e,event:t,handler:n,modifiers:s}),r()}}function Zi(e,t,n){y(e,t,n),n==null?W(\"SvelteDOMRemoveAttribute\",{node:e,attribute:t}):W(\"SvelteDOMSetAttribute\",{node:e,attribute:t,value:n})}function $i(e,t,n){e[t]=n,W(\"SvelteDOMSetProperty\",{node:e,property:t,value:n})}function eo(e,t,n){e.dataset[t]=n,W(\"SvelteDOMSetDataset\",{node:e,property:t,value:n})}function to(e,t){t=\"\"+t,e.wholeText!==t&&(W(\"SvelteDOMSetData\",{node:e,data:t}),e.data=t)}function no(e){if(typeof e!=\"string\"&&!(e&&typeof e==\"object\"&&\"length\"in e)){let t=\"{#each} only iterates over array-like objects.\";throw typeof Symbol==\"function\"&&e&&Symbol.iterator in e&&(t+=\" You can use a spread to convert this iterable into an array.\"),new Error(t)}}function io(e,t,n){for(const i of Object.keys(t))~n.indexOf(i)||console.warn(`<${e}> received an unexpected slot \"${i}\".`)}class oo extends null{constructor(t){if(!t||!t.target&&!t.$$inline)throw new Error(\"'target' is a required option\");super()}$destroy(){super.$destroy(),this.$destroy=()=>{console.warn(\"Component was already destroyed\")}}$capture_state(){}$inject_state(){}}class lo extends null{constructor(t){super(t)}}function so(e){const t=Date.now();return()=>{if(Date.now()-t>e)throw new Error(\"Infinite loop detected\")}}function ro(e,t){return e.map((n,i)=>n+t[i])}function uo(e,t){return t.map(n=>e*n)}function Gt(e,t,n){return e.map((i,o)=>(1-n)*i+n*t[o])}function st(e,t=2){if(!(\"length\"in e))return Kt(e,t);for(var n=0,i=0;i<e.length;i++)n+=Math.pow(Math.abs(e[i]),t);return Math.pow(n,1/t)}function Kt(e,t=2){for(var n=0,i=0;i<e.shape[0];i++)n+=Math.pow(Math.abs(e.get(i)),t);return Math.pow(n,1/t)}function Ie(e,t=2){var n=st(e,t);return e.map(i=>i/(1e-4+n))}function Qt(e){for(var t=[[1,0,0],[1,1,0],[0,1,0],[0,1,1],[0,0,1],[1,0,1]].map(s=>Ie(s,1));e<0;)e+=360;e=e%360;var n=360/t.length,i=Math.floor(e/n),o=(e-i*n)/n,l=Gt(t[i],t[(i+1)%t.length],o);return l=Ie(l,1),l}const Ve=[];function Zt(e){if(e in Ve)return Ve[e];let t=[];for(let n=0;n<e;n++){const i=360*n/e;t.push(Qt(i))}return Ve[e]=t,t}function rt(e){return`rgb(${255*e[0]}, ${255*e[1]}, ${255*e[2]})`}function ut(e,t=[.98,.98,.98],n=void 0,i=void 0){const o=\"length\"in e?e.length:e.shape[0],l=\"length\"in e?h=>e[h]:h=>e.get(h);if(i==null&&(i=Zt(o)),console.log(\"Hues\",i),n==null){for(var s=[0,0,0],r=0;r<o;r++){const h=l(r);if(h!=0)for(var f=i[r],a=0;a<3;a++)s[a]+=h*f[a]}s=Ie(s,1);for(var c=st(e,2),c=Math.max(0,Math.min(1,c)),a=0;a<3;a++)s[a]=c*s[a]+(1-c)*t[a];return s}else{for(var r=n,d=i[r],s=[0,0,0],a=0;a<3;a++)s[a]=l(r)*d[a]+(1-l(r))*t[a];return s}}function We(e,t=[.98,.98,.98],n=void 0,i=void 0){var o=ut(e,t,n,i);return rt(o)}function $t(e,t=[.98,.98,.98]){if(e>=0)for(var n=[0,.7,0],i=[0,0,0],o=0;o<3;o++)i[o]=e*n[o]+(1-e)*t[o];else for(var n=[1,0,0],i=[0,0,0],o=0;o<3;o++)i[o]=-e*n[o]+(1+e)*t[o];return console.log(\"Neuron color\",e,i),i}function fo(e,t=[.98,.98,.98]){var n=$t(e,t);return rt(n)}function en(){var e=F(\"style\");e.id=\"svelte-1fjpmsy-style\",e.textContent=\".container.svelte-1fjpmsy.svelte-1fjpmsy{position:relative;border:1px solid #aaa}.container.svelte-1fjpmsy>.svelte-1fjpmsy{position:absolute}.container.svelte-1fjpmsy canvas.svelte-1fjpmsy{left:0px;top:0px;width:100%;height:100%;image-rendering:pixelated}.container.svelte-1fjpmsy .focus-top.svelte-1fjpmsy,.container.svelte-1fjpmsy .focus-bottom.svelte-1fjpmsy{left:0px;width:100%;background:#aaa;opacity:0.3}.container.svelte-1fjpmsy .focus-top.svelte-1fjpmsy{top:0px}.container.svelte-1fjpmsy .focus-bottom.svelte-1fjpmsy{bottom:0px}.container.svelte-1fjpmsy .focus-left.svelte-1fjpmsy,.container.svelte-1fjpmsy .focus-right.svelte-1fjpmsy{top:0px;height:100%;background:#aaa;opacity:0.3}.container.svelte-1fjpmsy .focus-left.svelte-1fjpmsy{left:0px}.container.svelte-1fjpmsy .focus-right.svelte-1fjpmsy{right:0px}\",E(document.head,e)}function ft(e){let t,n,i,o=e[3]!=null&&at(e);return{c(){t=F(\"div\"),n=F(\"canvas\"),i=T(),o&&o.c(),S(n,\"width\",e[1]+\"px\"),S(n,\"height\",e[2]+\"px\"),y(n,\"class\",\"svelte-1fjpmsy\"),y(t,\"class\",\"container svelte-1fjpmsy\"),S(t,\"width\",e[1]+\"px\"),S(t,\"height\",e[2]+\"px\")},m(l,s){C(l,t,s),E(t,n),e[9](n),E(t,i),o&&o.m(t,null)},p(l,s){s&2&&S(n,\"width\",l[1]+\"px\"),s&4&&S(n,\"height\",l[2]+\"px\"),l[3]!=null?o?o.p(l,s):(o=at(l),o.c(),o.m(t,null)):o&&(o.d(1),o=null),s&2&&S(t,\"width\",l[1]+\"px\"),s&4&&S(t,\"height\",l[2]+\"px\")},d(l){l&&j(t),e[9](null),o&&o.d()}}}function at(e){let t,n,i;return{c(){t=F(\"div\"),n=T(),i=F(\"div\"),y(t,\"class\",\"focus-top svelte-1fjpmsy\"),S(t,\"height\",e[2]*e[3]/e[0].shape[0]+\"px\"),y(i,\"class\",\"focus-bottom svelte-1fjpmsy\"),S(i,\"height\",e[2]*(1-(e[3]+1)/e[0].shape[0])+\"px\")},m(o,l){C(o,t,l),C(o,n,l),C(o,i,l)},p(o,l){l&13&&S(t,\"height\",o[2]*o[3]/o[0].shape[0]+\"px\"),l&13&&S(i,\"height\",o[2]*(1-(o[3]+1)/o[0].shape[0])+\"px\")},d(o){o&&j(t),o&&j(n),o&&j(i)}}}function ct(e){let t,n,i,o=e[3]!=null&&dt(e);return{c(){t=F(\"div\"),n=F(\"canvas\"),i=T(),o&&o.c(),S(n,\"width\",e[1]+\"px\"),S(n,\"height\",e[2]+\"px\"),y(n,\"class\",\"svelte-1fjpmsy\"),y(t,\"class\",\"container svelte-1fjpmsy\"),S(t,\"width\",e[1]+\"px\"),S(t,\"height\",e[2]+\"px\")},m(l,s){C(l,t,s),E(t,n),e[10](n),E(t,i),o&&o.m(t,null)},p(l,s){s&2&&S(n,\"width\",l[1]+\"px\"),s&4&&S(n,\"height\",l[2]+\"px\"),l[3]!=null?o?o.p(l,s):(o=dt(l),o.c(),o.m(t,null)):o&&(o.d(1),o=null),s&2&&S(t,\"width\",l[1]+\"px\"),s&4&&S(t,\"height\",l[2]+\"px\")},d(l){l&&j(t),e[10](null),o&&o.d()}}}function dt(e){let t,n,i;return{c(){t=F(\"div\"),n=T(),i=F(\"div\"),y(t,\"class\",\"focus-left svelte-1fjpmsy\"),S(t,\"width\",e[1]*e[3]/e[0].shape[1]+\"px\"),y(i,\"class\",\"focus-right svelte-1fjpmsy\"),S(i,\"width\",e[1]*(1-(e[3]+1)/e[0].shape[1])+\"px\")},m(o,l){C(o,t,l),C(o,n,l),C(o,i,l)},p(o,l){l&11&&S(t,\"width\",o[1]*o[3]/o[0].shape[1]+\"px\"),l&11&&S(i,\"width\",o[1]*(1-(o[3]+1)/o[0].shape[1])+\"px\")},d(o){o&&j(t),o&&j(n),o&&j(i)}}}function tn(e){let t,n,i=!e[4]&&ft(e),o=e[4]&&ct(e);return{c(){i&&i.c(),t=T(),o&&o.c(),n=tt()},m(l,s){i&&i.m(l,s),C(l,t,s),o&&o.m(l,s),C(l,n,s)},p(l,[s]){l[4]?i&&(i.d(1),i=null):i?i.p(l,s):(i=ft(l),i.c(),i.m(t.parentNode,t)),l[4]?o?o.p(l,s):(o=ct(l),o.c(),o.m(n.parentNode,n)):o&&(o.d(1),o=null)},i:P,o:P,d(l){i&&i.d(l),l&&j(t),o&&o.d(l),l&&j(n)}}}function nn(e,t,n){let{array:i}=t,{width:o}=t,{height:l}=t,{hues:s}=t,{focus_token:r}=t,{isolate_channel:f=void 0}=t,{hover_token_is_target:a=!1}=t,{color_map:c=ut}=t,d;function h(u,_,k,w=void 0,M=void 0){if(_<k)return[255,255,255];var N=u.pick(_,k,null),b=c(N,void 0,w,M);return b.map(v=>255*v)}function p(u,_,k=void 0,w=void 0){if(!(u==null||_==null)){u.width=_.shape[0],u.height=_.shape[1];for(var M=u.getContext(\"2d\"),N=M.getImageData(0,0,u.width,u.height),b=0;b<u.width;b++)for(var v=0;v<u.height;v++){for(var q=b*u.width+v,D=h(_,b,v,k,w=w),J=0;J<3;J++)N.data[4*q+J]=D[J];N.data[4*q+3]=255}M.putImageData(N,0,0)}}Ht(()=>p(d,i,f));function m(u){ne[u?\"unshift\":\"push\"](()=>{d=u,n(5,d)})}function g(u){ne[u?\"unshift\":\"push\"](()=>{d=u,n(5,d)})}return e.$$set=u=>{\"array\"in u&&n(0,i=u.array),\"width\"in u&&n(1,o=u.width),\"height\"in u&&n(2,l=u.height),\"hues\"in u&&n(6,s=u.hues),\"focus_token\"in u&&n(3,r=u.focus_token),\"isolate_channel\"in u&&n(7,f=u.isolate_channel),\"hover_token_is_target\"in u&&n(4,a=u.hover_token_is_target),\"color_map\"in u&&n(8,c=u.color_map)},e.$$.update=()=>{if(e.$$.dirty&225){e:p(d,i,f,s)}},[i,o,l,r,a,d,s,f,c,m,g]}class on extends xe{constructor(t){super(),document.getElementById(\"svelte-1fjpmsy-style\")||en(),He(this,t,nn,tn,je,{array:0,width:1,height:2,hues:6,focus_token:3,isolate_channel:7,hover_token_is_target:4,color_map:8})}}const qe=on;function _t(e,t){return e.mode==\"soft\"&&(e.value=t),e}function ln(e,t){if(e.mode==\"soft\")e.value=t,e.mode=\"hard\";else if(e.mode==\"hard\"&&e.value!=t)e.value=t;else return sn(e);return e}function sn(e){return e.value=void 0,e.mode=\"soft\",e}function rn(e){let t,n,i,o;const l=e[4].default,s=At(l,e,e[3],null);return{c(){t=F(\"div\"),s&&s.c(),y(t,\"style\",e[2])},m(r,f){C(r,t,f),s&&s.m(t,null),n=!0,i||(o=[z(t,\"mouseover\",e[5]),z(t,\"click\",e[6]),z(t,\"mouseout\",e[7])],i=!0)},p(r,[f]){s&&s.p&&f&8&&Ct(s,l,r,r[3],f,null,null),(!n||f&4)&&y(t,\"style\",r[2])},i(r){n||(O(s,r),n=!0)},o(r){L(s,r),n=!1},d(r){r&&j(t),s&&s.d(r),i=!1,H(o)}}}function un(e,t,n){let{$$slots:i={},$$scope:o}=t,{lock:l}=t,{set_value:s}=t,{style:r=\"\"}=t;const f=()=>{n(0,l=_t(l,s))},a=()=>{n(0,l=ln(l,s))},c=()=>{n(0,l=_t(l,void 0))};return e.$$set=d=>{\"lock\"in d&&n(0,l=d.lock),\"set_value\"in d&&n(1,s=d.set_value),\"style\"in d&&n(2,r=d.style),\"$$scope\"in d&&n(3,o=d.$$scope)},[l,s,r,o,i,f,a,c]}class fn extends xe{constructor(t){super(),He(this,t,un,rn,je,{lock:0,set_value:1,style:2})}}const ht=fn;function an(){var e=F(\"style\");e.id=\"svelte-xqk9oe-style\",e.textContent=\".attn-container.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{display:grid;grid-template-rows:[title] min-content [main] min-content;grid-template-columns:[big-attn] min-content [heads] minmax(min-content, 624px);gap:12px}.figcaption.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{color:#888;grid-row:title;white-space:nowrap}.tokens-container.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{display:grid;grid-template-rows:[title] min-content [main] min-content;grid-template-columns:[left] min-content [right] minmax(min-content, 800px) [end];gap:12px;margin-top:24px;color:white}.tokens.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{grid-row:main;grid-column-start:left;grid-column-end:end;cursor:pointer;height:min-content;line-height:110%}.tokens.svelte-xqk9oe .token.svelte-xqk9oe.svelte-xqk9oe{white-space:pre-wrap}.tokens.svelte-xqk9oe .selected.svelte-xqk9oe.svelte-xqk9oe{border:1px solid #999;z-index:10}.tokens.svelte-xqk9oe .token.svelte-xqk9oe.svelte-xqk9oe:not(.selected){z-index:0;padding:1px}.hover-mode.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe,.hover-mode-text.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe,.info-mode.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe,.info-mode-text.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{color:#888;grid-row:title;grid-column:settings;cursor:pointer}.hover-mode-text.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe,.info-mode-text.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{margin-right:8px}.heads.svelte-xqk9oe.svelte-xqk9oe.svelte-xqk9oe{grid-column:heads;grid-row:main;display:flex;flex-direction:row;flex-wrap:wrap;gap:6px;height:min-content}.heads.svelte-xqk9oe .head-icon.svelte-xqk9oe.svelte-xqk9oe{position:relative;width:62px;height:62px}.heads.svelte-xqk9oe .head-icon.svelte-xqk9oe>.svelte-xqk9oe{position:absolute;right:0px;top:0px}.heads.svelte-xqk9oe .head-icon .head-label.svelte-xqk9oe.svelte-xqk9oe{background:#333;color:#eee;font-size:65%;padding:1px;border-bottom-left-radius:2px;padding-left:4px;padding-right:2px;min-width:14px;opacity:0.75}\",E(document.head,e)}function pt(e,t,n){const i=e.slice();return i[32]=t[n],i[34]=n,i}function mt(e,t,n){const i=e.slice();return i[35]=t[n],i}function gt(e){let t,n=e[15][e[10]]+\"\",i,o;return{c(){t=R(\"(\"),i=R(n),o=R(\")\")},m(l,s){C(l,t,s),C(l,i,s),C(l,o,s)},p(l,s){s[0]&33792&&n!==(n=l[15][l[10]]+\"\")&&ke(i,n)},d(l){l&&j(t),l&&j(i),l&&j(o)}}}function vt(e){let t,n,i,o;return n=new qe({props:{array:e[7],width:\"200\",height:\"200\",focus_token:e[9],hover_token_is_target:e[2],isolate_channel:e[10]}}),{c(){t=F(\"div\"),se(n.$$.fragment),y(t,\"style\",i=\"grid-column: big-attn; grid-row: main; \"+(e[11]?\"\":\"display:none;\"))},m(l,s){C(l,t,s),Z(n,t,null),o=!0},p(l,s){const r={};s[0]&128&&(r.array=l[7]),s[0]&512&&(r.focus_token=l[9]),s[0]&4&&(r.hover_token_is_target=l[2]),s[0]&1024&&(r.isolate_channel=l[10]),n.$set(r),(!o||s[0]&2048&&i!==(i=\"grid-column: big-attn; grid-row: main; \"+(l[11]?\"\":\"display:none;\")))&&y(t,\"style\",i)},i(l){o||(O(n.$$.fragment,l),o=!0)},o(l){L(n.$$.fragment,l),o=!1},d(l){l&&j(t),X(n)}}}function kt(e){let t,n,i,o,l=re(e[12].shape[2]),s=[];for(let f=0;f<l.length;f+=1)s[f]=bt(mt(e,l,f));const r=f=>L(s[f],1,1,()=>{s[f]=null});return{c(){t=F(\"div\"),t.textContent=\"Attention Heads (hover to focus, click to lock)\",n=T(),i=F(\"div\");for(let f=0;f<s.length;f+=1)s[f].c();y(t,\"class\",\"figcaption svelte-xqk9oe\"),S(t,\"grid-column\",\"heads\"),y(i,\"class\",\"heads svelte-xqk9oe\")},m(f,a){C(f,t,a),C(f,n,a),C(f,i,a);for(let c=0;c<s.length;c+=1)s[c].m(i,null);o=!0},p(f,a){if(a[0]&122566){l=re(f[12].shape[2]);let c;for(c=0;c<l.length;c+=1){const d=mt(f,l,c);s[c]?(s[c].p(d,a),O(s[c],1)):(s[c]=bt(d),s[c].c(),O(s[c],1),s[c].m(i,null))}for(oe(),c=l.length;c<s.length;c+=1)r(c);le()}},i(f){if(!o){for(let a=0;a<l.length;a+=1)O(s[a]);o=!0}},o(f){s=s.filter(Boolean);for(let a=0;a<s.length;a+=1)L(s[a]);o=!1},d(f){f&&j(t),f&&j(n),f&&j(i),et(s,f)}}}function cn(e){let t,n,i,o,l=(e[15][e[35]]!=null?e[15][e[35]]:\"&nbsp\")+\"\",s,r,f,a,c,d,h=(e[15][e[35]]!=null?e[15][e[35]]:\"&nbsp\")+\"\",p,m,g;return n=new qe({props:{array:e[7],width:\"60\",height:\"60\",isolate_channel:e[35]}}),a=new qe({props:{array:e[6],width:\"60\",height:\"60\",isolate_channel:e[35]}}),{c(){t=F(\"div\"),se(n.$$.fragment),i=T(),o=F(\"div\"),r=T(),f=F(\"div\"),se(a.$$.fragment),c=T(),d=F(\"div\"),m=T(),y(o,\"class\",\"head-label svelte-xqk9oe\"),S(o,\"background\",e[14][e[35]]),y(t,\"class\",\"head-icon svelte-xqk9oe\"),y(t,\"style\",s=\"opacity: \"+(e[10]!=null&&e[10]!=e[35]?\"0.2\":e[16](e[35],e[9],e[2]))+`;\n",
              "                        `+(e[11]?\"\":\"display:none;\")),y(d,\"class\",\"head-label svelte-xqk9oe\"),S(d,\"background\",e[14][e[35]]),y(f,\"class\",\"head-icon svelte-xqk9oe\"),y(f,\"style\",p=\"opacity: \"+(e[10]!=null&&e[10]!=e[35]?\"0.2\":e[16](e[35],e[9],e[2]))+`;\n",
              "                        `+(e[11]?\"display:none;\":\"\"))},m(u,_){C(u,t,_),Z(n,t,null),E(t,i),E(t,o),o.innerHTML=l,C(u,r,_),C(u,f,_),Z(a,f,null),E(f,c),E(f,d),d.innerHTML=h,C(u,m,_),g=!0},p(u,_){const k={};_[0]&128&&(k.array=u[7]),_[0]&4096&&(k.isolate_channel=u[35]),n.$set(k),(!g||_[0]&36864)&&l!==(l=(u[15][u[35]]!=null?u[15][u[35]]:\"&nbsp\")+\"\")&&(o.innerHTML=l),(!g||_[0]&20480)&&S(o,\"background\",u[14][u[35]]),(!g||_[0]&7684&&s!==(s=\"opacity: \"+(u[10]!=null&&u[10]!=u[35]?\"0.2\":u[16](u[35],u[9],u[2]))+`;\n",
              "                        `+(u[11]?\"\":\"display:none;\")))&&y(t,\"style\",s);const w={};_[0]&64&&(w.array=u[6]),_[0]&4096&&(w.isolate_channel=u[35]),a.$set(w),(!g||_[0]&36864)&&h!==(h=(u[15][u[35]]!=null?u[15][u[35]]:\"&nbsp\")+\"\")&&(d.innerHTML=h),(!g||_[0]&20480)&&S(d,\"background\",u[14][u[35]]),(!g||_[0]&7684&&p!==(p=\"opacity: \"+(u[10]!=null&&u[10]!=u[35]?\"0.2\":u[16](u[35],u[9],u[2]))+`;\n",
              "                        `+(u[11]?\"display:none;\":\"\")))&&y(f,\"style\",p)},i(u){g||(O(n.$$.fragment,u),O(a.$$.fragment,u),g=!0)},o(u){L(n.$$.fragment,u),L(a.$$.fragment,u),g=!1},d(u){u&&j(t),X(n),u&&j(r),u&&j(f),X(a),u&&j(m)}}}function bt(e){let t,n,i;function o(s){e[22].call(null,s)}let l={set_value:e[35],$$slots:{default:[cn]},$$scope:{ctx:e}};return e[1]!==void 0&&(l.lock=e[1]),t=new ht({props:l}),ne.push(()=>lt(t,\"lock\",o)),{c(){se(t.$$.fragment)},m(s,r){Z(t,s,r),i=!0},p(s,r){const f={};r[0]&4096&&(f.set_value=s[35]),r[0]&57028|r[1]&128&&(f.$$scope={dirty:r,ctx:s}),!n&&r[0]&2&&(n=!0,f.lock=s[1],ot(()=>n=!1)),t.$set(f)},i(s){i||(O(t.$$.fragment,s),i=!0)},o(s){L(t.$$.fragment,s),i=!1},d(s){X(t,s)}}}function yt(e){let t,n,i,o,l,s,r,f,a,c,d,h,p=e[2]?\"target\":\"source\",m,g,u,_,k,w=e[5],M=[];for(let v=0;v<w.length;v+=1)M[v]=wt(pt(e,w,v));const N=v=>L(M[v],1,1,()=>{M[v]=null});let b=e[7]!==void 0&&Ft(e);return{c(){t=F(\"div\"),n=F(\"div\"),n.textContent=\"Tokens (hover to focus, click to lock)\",i=T(),o=F(\"div\");for(let v=0;v<M.length;v+=1)M[v].c();l=T(),s=F(\"div\"),r=F(\"nobr\"),f=F(\"input\"),a=T(),c=F(\"span\"),d=R(`Selected is\n",
              "            `),h=F(\"b\"),m=R(p),g=T(),b&&b.c(),y(n,\"class\",\"figcaption svelte-xqk9oe\"),S(n,\"grid-column\",\"left\"),y(o,\"class\",\"tokens svelte-xqk9oe\"),y(f,\"class\",\"hover-mode svelte-xqk9oe\"),y(f,\"type\",\"checkbox\"),y(c,\"class\",\"hover-mode-text svelte-xqk9oe\"),S(c,\"white-space\",\"nowrap\"),y(s,\"class\",\"toggle\"),y(t,\"class\",\"tokens-container svelte-xqk9oe\")},m(v,q){C(v,t,q),E(t,n),E(t,i),E(t,o);for(let D=0;D<M.length;D+=1)M[D].m(o,null);E(t,l),E(t,s),E(s,r),E(r,f),f.checked=e[2],E(r,a),E(r,c),E(c,d),E(c,h),E(h,m),E(r,g),b&&b.m(r,null),u=!0,_||(k=[z(f,\"change\",e[24]),z(c,\"click\",e[25])],_=!0)},p(v,q){if(q[0]&561){w=v[5];let D;for(D=0;D<w.length;D+=1){const J=pt(v,w,D);M[D]?(M[D].p(J,q),O(M[D],1)):(M[D]=wt(J),M[D].c(),O(M[D],1),M[D].m(o,null))}for(oe(),D=w.length;D<M.length;D+=1)N(D);le()}q[0]&4&&(f.checked=v[2]),(!u||q[0]&4)&&p!==(p=v[2]?\"target\":\"source\")&&ke(m,p),v[7]!==void 0?b?b.p(v,q):(b=Ft(v),b.c(),b.m(r,null)):b&&(b.d(1),b=null)},i(v){if(!u){for(let q=0;q<w.length;q+=1)O(M[q]);u=!0}},o(v){M=M.filter(Boolean);for(let q=0;q<M.length;q+=1)L(M[q]);u=!1},d(v){v&&j(t),et(M,v),b&&b.d(),_=!1,H(k)}}}function dn(e){let t,n=e[32]+\"\",i,o;return{c(){t=F(\"span\"),i=R(n),y(t,\"class\",o=\"token \"+(e[34]==e[9]?\"selected\":\"\")+\" svelte-xqk9oe\"),S(t,\"background\",e[4][e[34]])},m(l,s){C(l,t,s),E(t,i)},p(l,s){s[0]&32&&n!==(n=l[32]+\"\")&&ke(i,n),s[0]&512&&o!==(o=\"token \"+(l[34]==l[9]?\"selected\":\"\")+\" svelte-xqk9oe\")&&y(t,\"class\",o),s[0]&16&&S(t,\"background\",l[4][l[34]])},d(l){l&&j(t)}}}function wt(e){let t,n,i;function o(s){e[23].call(null,s)}let l={set_value:e[34],style:\"display: inline\",$$slots:{default:[dn]},$$scope:{ctx:e}};return e[0]!==void 0&&(l.lock=e[0]),t=new ht({props:l}),ne.push(()=>lt(t,\"lock\",o)),{c(){se(t.$$.fragment)},m(s,r){Z(t,s,r),i=!0},p(s,r){const f={};r[0]&560|r[1]&128&&(f.$$scope={dirty:r,ctx:s}),!n&&r[0]&1&&(n=!0,f.lock=s[0],ot(()=>n=!1)),t.$set(f)},i(s){i||(O(t.$$.fragment,s),i=!0)},o(s){L(t.$$.fragment,s),i=!1},d(s){X(t,s)}}}function Ft(e){let t,n,i,o,l,s=e[3]?\"info-weighted\":\"unmodified\",r,f,a;return{c(){t=F(\"input\"),n=T(),i=F(\"span\"),o=R(`Attention is\n",
              "            `),l=F(\"b\"),r=R(s),y(t,\"class\",\"info-mode svelte-xqk9oe\"),y(t,\"type\",\"checkbox\"),y(i,\"class\",\"info-mode-text svelte-xqk9oe\"),S(i,\"white-space\",\"nowrap\")},m(c,d){C(c,t,d),t.checked=e[3],C(c,n,d),C(c,i,d),E(i,o),E(i,l),E(l,r),f||(a=[z(t,\"change\",e[26]),z(i,\"click\",e[27])],f=!0)},p(c,d){d[0]&8&&(t.checked=c[3]),d[0]&8&&s!==(s=c[3]?\"info-weighted\":\"unmodified\")&&ke(r,s)},d(c){c&&j(t),c&&j(n),c&&j(i),f=!1,H(a)}}}function _n(e){let t,n,i,o,l,s,r,f,a,c,d,h,p=e[10]!=null&&gt(e),m=e[7]!==void 0&&vt(e);r=new qe({props:{array:e[6],width:\"200\",height:\"200\",focus_token:e[9],hover_token_is_target:e[2],isolate_channel:e[10]}});let g=e[13]>1&&kt(e),u=e[8]&&yt(e);return{c(){t=F(\"div\"),n=F(\"div\"),i=R(`Attention Pattern\n",
              "        `),p&&p.c(),o=T(),m&&m.c(),l=T(),s=F(\"div\"),se(r.$$.fragment),a=T(),g&&g.c(),c=T(),u&&u.c(),d=tt(),y(n,\"class\",\"figcaption svelte-xqk9oe\"),S(n,\"grid-column\",\"big-attn\"),y(s,\"style\",f=\"grid-column: big-attn; grid-row: main; \"+(e[11]?\"display:none\":\"\")),y(t,\"class\",\"attn-container svelte-xqk9oe\")},m(_,k){C(_,t,k),E(t,n),E(n,i),p&&p.m(n,null),E(t,o),m&&m.m(t,null),E(t,l),E(t,s),Z(r,s,null),E(t,a),g&&g.m(t,null),C(_,c,k),u&&u.m(_,k),C(_,d,k),h=!0},p(_,k){_[10]!=null?p?p.p(_,k):(p=gt(_),p.c(),p.m(n,null)):p&&(p.d(1),p=null),_[7]!==void 0?m?(m.p(_,k),k[0]&128&&O(m,1)):(m=vt(_),m.c(),O(m,1),m.m(t,l)):m&&(oe(),L(m,1,1,()=>{m=null}),le());const w={};k[0]&64&&(w.array=_[6]),k[0]&512&&(w.focus_token=_[9]),k[0]&4&&(w.hover_token_is_target=_[2]),k[0]&1024&&(w.isolate_channel=_[10]),r.$set(w),(!h||k[0]&2048&&f!==(f=\"grid-column: big-attn; grid-row: main; \"+(_[11]?\"display:none\":\"\")))&&y(s,\"style\",f),_[13]>1?g?(g.p(_,k),k[0]&8192&&O(g,1)):(g=kt(_),g.c(),O(g,1),g.m(t,null)):g&&(oe(),L(g,1,1,()=>{g=null}),le()),_[8]?u?(u.p(_,k),k[0]&256&&O(u,1)):(u=yt(_),u.c(),O(u,1),u.m(d.parentNode,d)):u&&(oe(),L(u,1,1,()=>{u=null}),le())},i(_){h||(O(m),O(r.$$.fragment,_),O(g),O(u),h=!0)},o(_){L(m),L(r.$$.fragment,_),L(g),L(u),h=!1},d(_){_&&j(t),p&&p.d(),m&&m.d(),X(r),g&&g.d(),_&&j(c),u&&u.d(_),_&&j(d)}}}function re(e){return[...Array(e).keys()]}function qt(e){if(e!==void 0){for(var t=[],n=0;n<e.shape[0];n++){t.push([]);for(var i=0;i<e.shape[2];i++){for(var o=0,l=0;l<e.shape[1];l++)o=Math.max(o,e.pick(n,l,i));t[n].push(o)}}return t}}function Et(e){if(e!==void 0){for(var t=[],n=0;n<e.shape[0];n++){t.push([]);for(var i=0;i<e.shape[2];i++){for(var o=0,l=0;l<e.shape[1];l++)o=Math.max(o,e.pick(l,n,i));t[n].push(o)}}return t}}function hn(e,t,n){let i,o,l,s,r,f,a,c,d,h,p,m,g,{tokens:u}=t,{attention:_}=t,{info_weighted:k}=t,{head_labels:w}=t,{show_tokens:M=!0}=t,{focus_token_lock:N={value:void 0,mode:\"soft\"}}=t,{focus_head_lock:b={value:void 0,mode:\"soft\"}}=t,{hover_token_is_target:v=!1}=t,{_show_info_weighted:q=!1}=t;function D(A,Y,G,$=void 0){if(Y<G)return\"#FFF\";var ue=A.pick(Y,G,null);return We(ue,void 0,$)}function J(A,Y,G){if(Y==null)var $=1;else var ue=G?h:d,$=Math.max(0,Math.min(1,ue[Y][A]));return\"\"+$}function gn(A,Y,G,$=void 0,ue){if(Y==null){var qn=ue?h:d;return We(qn[G],void 0,$)}let Ue,Je;ue?(Ue=G,Je=Y):(Ue=Y,Je=G);let Xe=D(A,Ue,Je,$);return Xe===\"#FFF\"&&(Xe=\"#DDD\"),Xe}let{all_token_colors:Ye}=t;function vn(A){b=A,n(1,b)}function kn(A){N=A,n(0,N)}function bn(){v=this.checked,n(2,v)}const yn=()=>n(2,v=v^!0);function wn(){q=this.checked,n(3,q)}const Fn=()=>n(3,q=q^!0);return e.$$set=A=>{\"tokens\"in A&&n(5,u=A.tokens),\"attention\"in A&&n(6,_=A.attention),\"info_weighted\"in A&&n(7,k=A.info_weighted),\"head_labels\"in A&&n(17,w=A.head_labels),\"show_tokens\"in A&&n(8,M=A.show_tokens),\"focus_token_lock\"in A&&n(0,N=A.focus_token_lock),\"focus_head_lock\"in A&&n(1,b=A.focus_head_lock),\"hover_token_is_target\"in A&&n(2,v=A.hover_token_is_target),\"_show_info_weighted\"in A&&n(3,q=A._show_info_weighted),\"all_token_colors\"in A&&n(4,Ye=A.all_token_colors)},e.$$.update=()=>{if(e.$$.dirty[0]&1){e:n(9,i=N.value)}if(e.$$.dirty[0]&2){e:n(10,o=b.value)}if(e.$$.dirty[0]&136){e:n(11,l=q&&k!==void 0)}if(e.$$.dirty[0]&2240){e:n(12,s=l?k:_)}if(e.$$.dirty[0]&4096){e:window.attention_show=s}if(e.$$.dirty[0]&64){e:n(18,r=qt(_))}if(e.$$.dirty[0]&64){e:n(19,f=Et(_))}if(e.$$.dirty[0]&128){e:n(20,a=qt(k))}if(e.$$.dirty[0]&128){e:n(21,c=Et(k))}if(e.$$.dirty[0]&1312768){e:d=l?a:r}if(e.$$.dirty[0]&2623488){e:h=l?c:f}if(e.$$.dirty[0]&64){e:n(13,p=_.shape[2])}if(e.$$.dirty[0]&8192){e:n(14,m=re(p).map(A=>We(re(p).map(Y=>1),void 0,A)))}if(e.$$.dirty[0]&139264){e:n(15,g=w!=null?w:re(p))}if(e.$$.dirty[0]&5668){e:n(4,Ye=re(u.length).map(A=>gn(s,i,A,o,v)))}},[N,b,v,q,Ye,u,_,k,M,i,o,l,s,p,m,g,J,w,r,f,a,c,vn,kn,bn,yn,wn,Fn]}class pn extends xe{constructor(t){super(),document.getElementById(\"svelte-xqk9oe-style\")||an(),He(this,t,hn,_n,je,{tokens:5,attention:6,info_weighted:7,head_labels:17,show_tokens:8,focus_token_lock:0,focus_head_lock:1,hover_token_is_target:2,_show_info_weighted:3,all_token_colors:4},[-1,-1])}}const mn=pn}},Ee={};function ee(x){if(Ee[x])return Ee[x].exports;var B=Ee[x]={exports:{}};return St[x](B,B.exports,ee),B.exports}return ee.d=(x,B)=>{for(var te in B)ee.o(B,te)&&!ee.o(x,te)&&Object.defineProperty(x,te,{enumerable:!0,get:B[te]})},ee.o=(x,B)=>Object.prototype.hasOwnProperty.call(x,B),ee(143)})().default;\n",
              "</script>\n",
              "        \n",
              "        <div id=\"AttentionMulti_3ea3db3\"></div>\n",
              "        <script>\n",
              "        ( () => {\n",
              "            var data = {\n",
              "\"tokens\": [\n",
              "\"<|endoftext|>\",\n",
              "\"I\",\n",
              "\" am\",\n",
              "\" an\",\n",
              "\" amazing\",\n",
              "\" aut\",\n",
              "\"ore\",\n",
              "\"gressive\",\n",
              "\",\",\n",
              "\" dec\",\n",
              "\"oder\",\n",
              "\"-\",\n",
              "\"only\",\n",
              "\",\",\n",
              "\" G\",\n",
              "\"PT\",\n",
              "\"-\",\n",
              "\"2\",\n",
              "\" style\",\n",
              "\" transformer\",\n",
              "\".\",\n",
              "\" One\",\n",
              "\" day\",\n",
              "\" I\",\n",
              "\" will\",\n",
              "\" exceed\",\n",
              "\" human\",\n",
              "\" level\",\n",
              "\" intelligence\",\n",
              "\" and\",\n",
              "\" take\",\n",
              "\" over\",\n",
              "\" the\",\n",
              "\" world\",\n",
              "\"!\"\n",
              "],\n",
              "\"attention\": {\n",
              "\"__type__\": \"npy\",\n",
              "\"zdata\": \"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\",\n",
              "\"min\": 0.0,\n",
              "\"max\": 1.0\n",
              "}\n",
              "};\n",
              "            data = loader.unpack_obj(data);\n",
              "            window.AttentionMulti_data = data;\n",
              "            var AttentionMulti_inst = new AttentionMulti({\n",
              "                \"target\": document.getElementById(\"AttentionMulti_3ea3db3\"),\n",
              "                \"props\": data\n",
              "                });\n",
              "        })();\n",
              "        </script>\n",
              "        \n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pysvelte\n",
        "pysvelte.AttentionMulti(tokens=reference_gpt2.to_str_tokens(reference_text), attention=cache['blocks.0.attn.hook_attn'][0].permute(1, 2, 0)).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv3YrnrhBaJD",
        "outputId": "defbe473-588e-4a18-8225-9302d07c9e19"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNNtDQ0zJqFm",
        "outputId": "c6967a45-c11d-43ea-aa5f-4ca83ffc4360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 7.9663e-01,  1.6985e-02,  3.4781e-02,  ...,  3.3120e-02,\n",
              "          -2.3129e-02,  1.8103e-01],\n",
              "         [ 1.3167e-03,  1.5750e-01, -1.4059e-01,  ..., -8.1997e-03,\n",
              "           5.3075e-03,  1.3511e-01],\n",
              "         [ 8.9738e-02, -7.2411e-01, -6.9866e-01,  ...,  5.5321e-02,\n",
              "           2.7958e-03,  9.0785e-02],\n",
              "         ...,\n",
              "         [-3.0286e-01,  4.9638e-02, -6.0990e-01,  ..., -3.7084e-02,\n",
              "          -4.9524e-04, -8.6008e-03],\n",
              "         [-1.0844e+00, -6.1457e-02,  2.2966e-01,  ..., -2.6688e-02,\n",
              "          -1.4368e-02,  3.3245e-02],\n",
              "         [ 3.7947e-01, -4.9886e-01,  2.6434e-01,  ..., -2.7894e-02,\n",
              "          -8.9028e-03,  4.8796e-02]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32, device=\"cpu\", #device= \"cuda\"\n",
        "        ))\n",
        "\n",
        "    def forward(self, normalized_resid_pre):\n",
        "        # normalized_resid_pre: [batch, position, d_model]\n",
        "        # \"YOUR CODE HERE\"\n",
        "\n",
        "        Q = torch.einsum('bnd,hdg->bhng',normalized_resid_pre, self.W_Q) + self.b_Q.unsqueeze(-2).expand(-1,normalized_resid_pre.size(1),-1)\n",
        "        K = torch.einsum('bnd,hdg->bhng',normalized_resid_pre, self.W_K) + self.b_K.unsqueeze(-2).expand(-1,normalized_resid_pre.size(1),-1)\n",
        "        V = torch.einsum('bnd,hdg->bhng',normalized_resid_pre, self.W_V) + self.b_V.unsqueeze(-2).expand(-1,normalized_resid_pre.size(1),-1)\n",
        "\n",
        "        attention = (Q @ torch.transpose(K, -2,-1))/np.sqrt(self.cfg.d_head)\n",
        "        attention_mask = torch.softmax(self.apply_causal_mask(attention),dim = -1)\n",
        "\n",
        "        Z = attention_mask @ V\n",
        "\n",
        "        out = torch.einsum('bhng,hgd->bnd',Z,self.W_O) + self.b_O.unsqueeze(0).expand(Z.size(-2),-1)\n",
        "        return out\n",
        "\n",
        "    def apply_causal_mask(self, attn_scores):\n",
        "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
        "        # \"YOUR CODE HERE\"\n",
        "        # print(torch.triu(torch.ones(attn_scores.size(-1), attn_scores.size(-1))))\n",
        "        attn_scores[:,:,torch.triu(torch.ones(attn_scores.size(-1), attn_scores.size(-1)), diagonal=1).bool(),\n",
        "                    ] = -torch.inf\n",
        "        return attn_scores\n",
        "\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.ln1.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iP2lIPP1Ghz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWWoaqlkD-6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpmZq-icJqFn"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8VX0ysQJqFn",
        "outputId": "bf014e03-7b1d-49d6-a258-3f0bf1594f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4380,  0.3624,  0.5117,  ...,  1.7227,  1.5761,  0.0368],\n",
              "         [-1.0766, -0.0438,  0.3276,  ..., -0.5437,  0.4033,  0.3717],\n",
              "         [-1.2182, -1.5481, -0.9702,  ...,  1.0737,  0.7199,  0.5080],\n",
              "         ...,\n",
              "         [-0.4004,  0.8475,  0.2047,  ...,  0.3789,  0.0455, -0.4744],\n",
              "         [-0.0862,  0.7839,  0.9046,  ..., -0.2174, -0.5953,  0.8555],\n",
              "         [ 0.8448, -0.3743,  1.0397,  ...,  0.0296,  0.3405,  0.3585]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "    def forward(self, normalized_resid_mid):\n",
        "        # normalized_resid_mid: [batch, position, d_model]\n",
        "        # \"YOUR CODE HERE\"\n",
        "        mlp_int = normalized_resid_mid @ self.W_in + self.b_in.unsqueeze(0).expand(normalized_resid_mid.size(1),-1)\n",
        "        mlp_int = gelu_new(mlp_int)\n",
        "        mlp_out = mlp_int @ self.W_out + self.b_out.unsqueeze(0).expand(mlp_int.size(1),-1)\n",
        "        return mlp_out\n",
        "rand_float_test(MLP, [2, 4, 768])\n",
        "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"blocks.0.ln2.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08MRTFElJqFo"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydyWNRoDJqFp",
        "outputId": "f3e5360e-a4e5-4cac-dd64-a757384265b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.3911,  0.1543,  0.6005,  ...,  1.7198,  1.7365,  0.3930],\n",
              "         [-0.9039, -0.0360,  0.2351,  ..., -0.4148,  0.3562,  0.3936],\n",
              "         [-0.9647, -2.4819, -1.4995,  ...,  1.4046,  0.7616,  0.5918],\n",
              "         ...,\n",
              "         [-0.7421,  0.9251, -0.3218,  ...,  0.2921,  0.1097, -0.5344],\n",
              "         [-1.3221,  0.8960,  1.1795,  ..., -0.5544, -0.4071,  0.9255],\n",
              "         [ 1.1209, -0.8919,  1.3737,  ..., -0.1356,  0.3434,  0.4517]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(self, resid_pre):\n",
        "        # resid_pre [batch, position, d_model]\n",
        "        \"YOUR CODE HERE\"\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpyyDjwgJqFq"
      },
      "source": [
        "## Unembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j6s8EZmJqFr",
        "outputId": "f03240d1-27bd-4658-e2db-1affa3332247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_final: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ -43.4317,  -39.8364,  -43.0660,  ...,  -54.0878,  -54.3452,\n",
              "           -42.3645],\n",
              "         [-128.0392, -127.9936, -130.7010,  ..., -136.7121, -129.9261,\n",
              "          -129.3965],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6027,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9815, -112.7749, -117.0633,  ..., -121.2914, -117.6574,\n",
              "          -114.5005],\n",
              "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
              "          -106.3604],\n",
              "         [-126.8285, -128.9596, -128.3941,  ..., -140.1970, -138.5883,\n",
              "          -122.3697]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(self, normalized_resid_final):\n",
        "        # normalized_resid_final [batch, position, d_model]\n",
        "        \"YOUR CODE HERE\"\n",
        "\n",
        "rand_float_test(Unembed, [2, 4, 768])\n",
        "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX6LMwleJqFr"
      },
      "source": [
        "## Full Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqOqZg1tJqFs",
        "outputId": "36491dec-e776-4907-852f-a7f64b9c2dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "Embeddings: torch.Size([2, 4, 768])\n",
            "Tokens: torch.Size([2, 4])\n",
            "pos_embed: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Tokens: torch.Size([1, 35])\n",
            "Embeddings: torch.Size([1, 35, 768])\n",
            "Tokens: torch.Size([1, 35])\n",
            "pos_embed: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_final: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ -43.4317,  -39.8364,  -43.0660,  ...,  -54.0878,  -54.3452,\n",
              "           -42.3645],\n",
              "         [-128.0392, -127.9936, -130.7010,  ..., -136.7121, -129.9261,\n",
              "          -129.3965],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6027,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9815, -112.7749, -117.0633,  ..., -121.2914, -117.6574,\n",
              "          -114.5005],\n",
              "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
              "          -106.3604],\n",
              "         [-126.8285, -128.9596, -128.3941,  ..., -140.1970, -138.5883,\n",
              "          -122.3697]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens [batch, position]\n",
        "        \"YOUR CODE HERE\"\n",
        "\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfFZdx7mJqFv"
      },
      "source": [
        "# Try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Bn4TB15JqFw",
        "outputId": "a3cc483b-3151-412d-c711-d20c4ef92ab3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_gpt2 = DemoTransformer(Config(debug=False))\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "demo_gpt2.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4cn2bDuJqFw"
      },
      "source": [
        "Take a test string - the intro paragraph of today's featured Wikipedia article. Let's calculate the loss!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLKxKW63JqFx"
      },
      "outputs": [],
      "source": [
        "test_string = \"\"\"Mini scule is a species of microhylid frog endemic to Madagascar that was described in 2019. The scientific name of the species refers to its size, being a pun on the word minuscule. It is very small, measuring only 8.4 to 10.8 mm (0.33 to 0.43 in) in snout–vent length. It has bronze underparts with a brown groin and back of the thigh, cream upperparts with brown flecking, a dark brown side of the head, and a red iris. On the hind feet, the first toe is absent and the second and fifth toes are strongly reduced. The frog is known only from the Sainte Luce Reserve, where it inhabits areas with deep leaf litter near semi-permanent water bodies. Specimens of frogs from Mandena, the Vohimena mountains, the southern Anosy Mountains, and Tsitongambarika may also be of this species. Along with Mini mum and Mini ature, the other two species in its genus, it received media attention when first described due to the wordplay in its scientific name. (Full article...)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-UsXJcAJqFy"
      },
      "outputs": [],
      "source": [
        "test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "demo_logits = demo_gpt2(test_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFxklJtYJqFy",
        "outputId": "a27bc4c2-ec24-475a-9636-d34f99dc9f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.7186, device='cuda:0', grad_fn=<NegBackward0>)\n",
            "Loss as average prob tensor(0.0243, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss as 'uniform over this many variables' tensor(41.2079, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Uniform loss over the vocab 10.82490511970208\n"
          ]
        }
      ],
      "source": [
        "def lm_cross_entropy_loss(logits, tokens):\n",
        "    # Measure next token loss\n",
        "    # Logits have shape [batch, position, d_vocab]\n",
        "    # Tokens have shape [batch, position]\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    pred_log_probs = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
        "    return -pred_log_probs.mean()\n",
        "loss = lm_cross_entropy_loss(demo_logits, test_tokens)\n",
        "print(loss)\n",
        "print(\"Loss as average prob\", (-loss).exp())\n",
        "print(\"Loss as 'uniform over this many variables'\", (loss).exp())\n",
        "print(\"Uniform loss over the vocab\", math.log(demo_gpt2.cfg.d_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlNVZlLvJqF0"
      },
      "source": [
        "We can also greedily generate text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "37ac70024b344ea787bd2f70c4f9b69d"
          ]
        },
        "id": "iXcKzojLJqF0",
        "outputId": "2df40fd0-7d6f-4eb5-caba-da2904518030"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ac70024b344ea787bd2f70c4f9b69d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the\n"
          ]
        }
      ],
      "source": [
        "test_string = \"Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on\"\n",
        "for i in tqdm.tqdm(range(100)):\n",
        "    test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "    demo_logits = demo_gpt2(test_tokens)\n",
        "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
        "print(test_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqFtczDOJqF1"
      },
      "source": [
        "# Training a Model!\n",
        "\n",
        "This is a lightweight demonstration of how you can actually train your own GPT-2 with this code! Here we train a tiny model on a tiny dataset, but it's fundamentally the same code for training a larger/more real model (though you'll need beefier GPUs and data parallelism to do it remotely efficiently, and fancier parallelism for much bigger ones).\n",
        "\n",
        "For our purposes, we'll train 2L 4 heads per layer model, with context length 256, for 1000 steps of batch size 8, just to show what it looks like (and so the notebook doesn't melt your colab lol)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZbkSkjIJqF2"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    %pip install datasets\n",
        "    %pip install transformers\n",
        "import datasets\n",
        "import transformers\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJrSqpakJqF2"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PchoWXOSJqF-"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "num_epochs = 1\n",
        "max_steps = 1000\n",
        "log_every = 10\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-2\n",
        "model_cfg = Config(debug=False, d_model=256, n_heads=4, d_head=64, d_mlp=1024, n_layers=2, n_ctx=256, d_vocab=reference_gpt2.cfg.d_vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP-qQ-3qJqF_"
      },
      "source": [
        "\n",
        "## Create Data\n",
        "\n",
        "We load in a tiny dataset I made, with the first 10K entries in the Pile (inspired by Stas' version for OpenWebText!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2cdrmDNJqF_",
        "outputId": "cb21ee7b-2c1c-46f8-f5bf-d56e20d0051c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "Using custom data configuration NeelNanda--pile-10k-30e9c14cdcda6c5c\n",
            "Reusing dataset parquet (/workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'meta'],\n",
            "    num_rows: 10000\n",
            "})\n",
            "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playi\n",
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-5a7efe79fba39fa4.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-5d90b6c801666252.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-63f545415985c072.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e1d3c0b4a6cf8c82.arrow\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\")\n",
        "print(dataset)\n",
        "print(dataset[0]['text'][:100])\n",
        "tokens_dataset = tokenize_and_concatenate(dataset, reference_gpt2.tokenizer, streaming=False, max_length=model_cfg.n_ctx, column_name=\"text\", add_bos_token=True, num_proc=4)\n",
        "data_loader = torch.utils.data.DataLoader(tokens_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1beTsU9MJqGA"
      },
      "source": [
        "## Create Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvbsRjccJqGA",
        "outputId": "0cf07698-cedc-4036-bd90-c55f32cbaafa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = DemoTransformer(model_cfg)\n",
        "model.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO6X31gDJqGA"
      },
      "source": [
        "## Create Optimizer\n",
        "We use AdamW - it's a pretty standard optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0iw1afuJqGB"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dumeWlzZJqGB"
      },
      "source": [
        "## Run Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9bd43306e46843b1abcafea463782a12"
          ]
        },
        "id": "uq6cWezcJqGB",
        "outputId": "734d1d6f-1aa4-4b98-eef4-83af0f75e408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches: 8506\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bd43306e46843b1abcafea463782a12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 0, Loss: 10.8938\n",
            "Step: 10, Loss: 8.6160\n",
            "Step: 20, Loss: 7.4170\n",
            "Step: 30, Loss: 7.4342\n",
            "Step: 40, Loss: 7.1660\n",
            "Step: 50, Loss: 5.9145\n",
            "Step: 60, Loss: 7.3014\n",
            "Step: 70, Loss: 7.7666\n",
            "Step: 80, Loss: 7.5511\n",
            "Step: 90, Loss: 6.2643\n",
            "Step: 100, Loss: 7.1839\n",
            "Step: 110, Loss: 5.3938\n",
            "Step: 120, Loss: 7.3348\n",
            "Step: 130, Loss: 5.9235\n",
            "Step: 140, Loss: 6.0241\n",
            "Step: 150, Loss: 6.5177\n",
            "Step: 160, Loss: 7.0355\n",
            "Step: 170, Loss: 6.0351\n",
            "Step: 180, Loss: 6.7511\n",
            "Step: 190, Loss: 5.9056\n",
            "Step: 200, Loss: 6.2145\n",
            "Step: 210, Loss: 5.7370\n",
            "Step: 220, Loss: 6.9411\n",
            "Step: 230, Loss: 6.4263\n",
            "Step: 240, Loss: 6.4935\n",
            "Step: 250, Loss: 6.3181\n",
            "Step: 260, Loss: 6.4933\n",
            "Step: 270, Loss: 5.8911\n",
            "Step: 280, Loss: 6.8380\n",
            "Step: 290, Loss: 7.1255\n",
            "Step: 300, Loss: 6.5911\n",
            "Step: 310, Loss: 5.8859\n",
            "Step: 320, Loss: 6.9126\n",
            "Step: 330, Loss: 6.5967\n",
            "Step: 340, Loss: 6.7064\n",
            "Step: 350, Loss: 6.1962\n",
            "Step: 360, Loss: 5.7562\n",
            "Step: 370, Loss: 5.9538\n",
            "Step: 380, Loss: 6.9621\n",
            "Step: 390, Loss: 7.1926\n",
            "Step: 400, Loss: 6.2406\n",
            "Step: 410, Loss: 6.8793\n",
            "Step: 420, Loss: 6.7920\n",
            "Step: 430, Loss: 5.6676\n",
            "Step: 440, Loss: 6.4836\n",
            "Step: 450, Loss: 5.8379\n",
            "Step: 460, Loss: 5.0805\n",
            "Step: 470, Loss: 5.3195\n",
            "Step: 480, Loss: 5.8577\n",
            "Step: 490, Loss: 6.0510\n",
            "Step: 500, Loss: 5.3045\n",
            "Step: 510, Loss: 5.6220\n",
            "Step: 520, Loss: 5.6595\n",
            "Step: 530, Loss: 5.1026\n",
            "Step: 540, Loss: 6.2747\n",
            "Step: 550, Loss: 6.5637\n",
            "Step: 560, Loss: 5.9919\n",
            "Step: 570, Loss: 4.4590\n",
            "Step: 580, Loss: 5.7116\n",
            "Step: 590, Loss: 6.4498\n",
            "Step: 600, Loss: 6.2833\n",
            "Step: 610, Loss: 6.0663\n",
            "Step: 620, Loss: 6.1303\n",
            "Step: 630, Loss: 6.0391\n",
            "Step: 640, Loss: 5.9534\n",
            "Step: 650, Loss: 5.8069\n",
            "Step: 660, Loss: 5.7637\n",
            "Step: 670, Loss: 6.2510\n",
            "Step: 680, Loss: 6.7757\n",
            "Step: 690, Loss: 5.8833\n",
            "Step: 700, Loss: 5.6237\n",
            "Step: 710, Loss: 5.9463\n",
            "Step: 720, Loss: 5.9818\n",
            "Step: 730, Loss: 3.7111\n",
            "Step: 740, Loss: 6.2097\n",
            "Step: 750, Loss: 6.3188\n",
            "Step: 760, Loss: 5.4198\n",
            "Step: 770, Loss: 3.9056\n",
            "Step: 780, Loss: 5.8297\n",
            "Step: 790, Loss: 6.2319\n",
            "Step: 800, Loss: 5.4723\n",
            "Step: 810, Loss: 5.5568\n",
            "Step: 820, Loss: 6.2107\n",
            "Step: 830, Loss: 6.5033\n",
            "Step: 840, Loss: 5.5697\n",
            "Step: 850, Loss: 5.6075\n",
            "Step: 860, Loss: 5.4451\n",
            "Step: 870, Loss: 6.1277\n",
            "Step: 880, Loss: 6.1290\n",
            "Step: 890, Loss: 5.2920\n",
            "Step: 900, Loss: 3.9140\n",
            "Step: 910, Loss: 6.3699\n",
            "Step: 920, Loss: 4.8495\n",
            "Step: 930, Loss: 5.8845\n",
            "Step: 940, Loss: 3.8847\n",
            "Step: 950, Loss: 6.1746\n",
            "Step: 960, Loss: 6.6594\n",
            "Step: 970, Loss: 4.5531\n",
            "Step: 980, Loss: 5.2382\n",
            "Step: 990, Loss: 6.6860\n",
            "Step: 1000, Loss: 5.7797\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "print(\"Number of batches:\", len(data_loader))\n",
        "for epoch in range(num_epochs):\n",
        "    for c, batch in tqdm.tqdm(enumerate(data_loader)):\n",
        "        tokens = batch['tokens'].cuda()\n",
        "        logits = model(tokens)\n",
        "        loss = lm_cross_entropy_loss(logits, tokens)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        losses.append(loss.item())\n",
        "        if c % log_every == 0:\n",
        "            print(f\"Step: {c}, Loss: {loss.item():.4f}\")\n",
        "        if c > max_steps:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hIFc7msJqGD"
      },
      "source": [
        "We can now plot a loss curve!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2nqIyzQJqGD",
        "outputId": "e02f0f59-b9fa-4d9b-90a5-c8d42eab246d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "hovertemplate": "Tokens=%{x}<br>Loss=%{y}<extra></extra>",
                  "legendgroup": "",
                  "line": {
                    "color": "#636efa",
                    "dash": "solid"
                  },
                  "marker": {
                    "symbol": "circle"
                  },
                  "mode": "lines",
                  "name": "",
                  "showlegend": false,
                  "type": "scattergl",
                  "x": [
                    0,
                    2048,
                    4096,
                    6144,
                    8192,
                    10240,
                    12288,
                    14336,
                    16384,
                    18432,
                    20480,
                    22528,
                    24576,
                    26624,
                    28672,
                    30720,
                    32768,
                    34816,
                    36864,
                    38912,
                    40960,
                    43008,
                    45056,
                    47104,
                    49152,
                    51200,
                    53248,
                    55296,
                    57344,
                    59392,
                    61440,
                    63488,
                    65536,
                    67584,
                    69632,
                    71680,
                    73728,
                    75776,
                    77824,
                    79872,
                    81920,
                    83968,
                    86016,
                    88064,
                    90112,
                    92160,
                    94208,
                    96256,
                    98304,
                    100352,
                    102400,
                    104448,
                    106496,
                    108544,
                    110592,
                    112640,
                    114688,
                    116736,
                    118784,
                    120832,
                    122880,
                    124928,
                    126976,
                    129024,
                    131072,
                    133120,
                    135168,
                    137216,
                    139264,
                    141312,
                    143360,
                    145408,
                    147456,
                    149504,
                    151552,
                    153600,
                    155648,
                    157696,
                    159744,
                    161792,
                    163840,
                    165888,
                    167936,
                    169984,
                    172032,
                    174080,
                    176128,
                    178176,
                    180224,
                    182272,
                    184320,
                    186368,
                    188416,
                    190464,
                    192512,
                    194560,
                    196608,
                    198656,
                    200704,
                    202752,
                    204800,
                    206848,
                    208896,
                    210944,
                    212992,
                    215040,
                    217088,
                    219136,
                    221184,
                    223232,
                    225280,
                    227328,
                    229376,
                    231424,
                    233472,
                    235520,
                    237568,
                    239616,
                    241664,
                    243712,
                    245760,
                    247808,
                    249856,
                    251904,
                    253952,
                    256000,
                    258048,
                    260096,
                    262144,
                    264192,
                    266240,
                    268288,
                    270336,
                    272384,
                    274432,
                    276480,
                    278528,
                    280576,
                    282624,
                    284672,
                    286720,
                    288768,
                    290816,
                    292864,
                    294912,
                    296960,
                    299008,
                    301056,
                    303104,
                    305152,
                    307200,
                    309248,
                    311296,
                    313344,
                    315392,
                    317440,
                    319488,
                    321536,
                    323584,
                    325632,
                    327680,
                    329728,
                    331776,
                    333824,
                    335872,
                    337920,
                    339968,
                    342016,
                    344064,
                    346112,
                    348160,
                    350208,
                    352256,
                    354304,
                    356352,
                    358400,
                    360448,
                    362496,
                    364544,
                    366592,
                    368640,
                    370688,
                    372736,
                    374784,
                    376832,
                    378880,
                    380928,
                    382976,
                    385024,
                    387072,
                    389120,
                    391168,
                    393216,
                    395264,
                    397312,
                    399360,
                    401408,
                    403456,
                    405504,
                    407552,
                    409600,
                    411648,
                    413696,
                    415744,
                    417792,
                    419840,
                    421888,
                    423936,
                    425984,
                    428032,
                    430080,
                    432128,
                    434176,
                    436224,
                    438272,
                    440320,
                    442368,
                    444416,
                    446464,
                    448512,
                    450560,
                    452608,
                    454656,
                    456704,
                    458752,
                    460800,
                    462848,
                    464896,
                    466944,
                    468992,
                    471040,
                    473088,
                    475136,
                    477184,
                    479232,
                    481280,
                    483328,
                    485376,
                    487424,
                    489472,
                    491520,
                    493568,
                    495616,
                    497664,
                    499712,
                    501760,
                    503808,
                    505856,
                    507904,
                    509952,
                    512000,
                    514048,
                    516096,
                    518144,
                    520192,
                    522240,
                    524288,
                    526336,
                    528384,
                    530432,
                    532480,
                    534528,
                    536576,
                    538624,
                    540672,
                    542720,
                    544768,
                    546816,
                    548864,
                    550912,
                    552960,
                    555008,
                    557056,
                    559104,
                    561152,
                    563200,
                    565248,
                    567296,
                    569344,
                    571392,
                    573440,
                    575488,
                    577536,
                    579584,
                    581632,
                    583680,
                    585728,
                    587776,
                    589824,
                    591872,
                    593920,
                    595968,
                    598016,
                    600064,
                    602112,
                    604160,
                    606208,
                    608256,
                    610304,
                    612352,
                    614400,
                    616448,
                    618496,
                    620544,
                    622592,
                    624640,
                    626688,
                    628736,
                    630784,
                    632832,
                    634880,
                    636928,
                    638976,
                    641024,
                    643072,
                    645120,
                    647168,
                    649216,
                    651264,
                    653312,
                    655360,
                    657408,
                    659456,
                    661504,
                    663552,
                    665600,
                    667648,
                    669696,
                    671744,
                    673792,
                    675840,
                    677888,
                    679936,
                    681984,
                    684032,
                    686080,
                    688128,
                    690176,
                    692224,
                    694272,
                    696320,
                    698368,
                    700416,
                    702464,
                    704512,
                    706560,
                    708608,
                    710656,
                    712704,
                    714752,
                    716800,
                    718848,
                    720896,
                    722944,
                    724992,
                    727040,
                    729088,
                    731136,
                    733184,
                    735232,
                    737280,
                    739328,
                    741376,
                    743424,
                    745472,
                    747520,
                    749568,
                    751616,
                    753664,
                    755712,
                    757760,
                    759808,
                    761856,
                    763904,
                    765952,
                    768000,
                    770048,
                    772096,
                    774144,
                    776192,
                    778240,
                    780288,
                    782336,
                    784384,
                    786432,
                    788480,
                    790528,
                    792576,
                    794624,
                    796672,
                    798720,
                    800768,
                    802816,
                    804864,
                    806912,
                    808960,
                    811008,
                    813056,
                    815104,
                    817152,
                    819200,
                    821248,
                    823296,
                    825344,
                    827392,
                    829440,
                    831488,
                    833536,
                    835584,
                    837632,
                    839680,
                    841728,
                    843776,
                    845824,
                    847872,
                    849920,
                    851968,
                    854016,
                    856064,
                    858112,
                    860160,
                    862208,
                    864256,
                    866304,
                    868352,
                    870400,
                    872448,
                    874496,
                    876544,
                    878592,
                    880640,
                    882688,
                    884736,
                    886784,
                    888832,
                    890880,
                    892928,
                    894976,
                    897024,
                    899072,
                    901120,
                    903168,
                    905216,
                    907264,
                    909312,
                    911360,
                    913408,
                    915456,
                    917504,
                    919552,
                    921600,
                    923648,
                    925696,
                    927744,
                    929792,
                    931840,
                    933888,
                    935936,
                    937984,
                    940032,
                    942080,
                    944128,
                    946176,
                    948224,
                    950272,
                    952320,
                    954368,
                    956416,
                    958464,
                    960512,
                    962560,
                    964608,
                    966656,
                    968704,
                    970752,
                    972800,
                    974848,
                    976896,
                    978944,
                    980992,
                    983040,
                    985088,
                    987136,
                    989184,
                    991232,
                    993280,
                    995328,
                    997376,
                    999424,
                    1001472,
                    1003520,
                    1005568,
                    1007616,
                    1009664,
                    1011712,
                    1013760,
                    1015808,
                    1017856,
                    1019904,
                    1021952,
                    1024000,
                    1026048,
                    1028096,
                    1030144,
                    1032192,
                    1034240,
                    1036288,
                    1038336,
                    1040384,
                    1042432,
                    1044480,
                    1046528,
                    1048576,
                    1050624,
                    1052672,
                    1054720,
                    1056768,
                    1058816,
                    1060864,
                    1062912,
                    1064960,
                    1067008,
                    1069056,
                    1071104,
                    1073152,
                    1075200,
                    1077248,
                    1079296,
                    1081344,
                    1083392,
                    1085440,
                    1087488,
                    1089536,
                    1091584,
                    1093632,
                    1095680,
                    1097728,
                    1099776,
                    1101824,
                    1103872,
                    1105920,
                    1107968,
                    1110016,
                    1112064,
                    1114112,
                    1116160,
                    1118208,
                    1120256,
                    1122304,
                    1124352,
                    1126400,
                    1128448,
                    1130496,
                    1132544,
                    1134592,
                    1136640,
                    1138688,
                    1140736,
                    1142784,
                    1144832,
                    1146880,
                    1148928,
                    1150976,
                    1153024,
                    1155072,
                    1157120,
                    1159168,
                    1161216,
                    1163264,
                    1165312,
                    1167360,
                    1169408,
                    1171456,
                    1173504,
                    1175552,
                    1177600,
                    1179648,
                    1181696,
                    1183744,
                    1185792,
                    1187840,
                    1189888,
                    1191936,
                    1193984,
                    1196032,
                    1198080,
                    1200128,
                    1202176,
                    1204224,
                    1206272,
                    1208320,
                    1210368,
                    1212416,
                    1214464,
                    1216512,
                    1218560,
                    1220608,
                    1222656,
                    1224704,
                    1226752,
                    1228800,
                    1230848,
                    1232896,
                    1234944,
                    1236992,
                    1239040,
                    1241088,
                    1243136,
                    1245184,
                    1247232,
                    1249280,
                    1251328,
                    1253376,
                    1255424,
                    1257472,
                    1259520,
                    1261568,
                    1263616,
                    1265664,
                    1267712,
                    1269760,
                    1271808,
                    1273856,
                    1275904,
                    1277952,
                    1280000,
                    1282048,
                    1284096,
                    1286144,
                    1288192,
                    1290240,
                    1292288,
                    1294336,
                    1296384,
                    1298432,
                    1300480,
                    1302528,
                    1304576,
                    1306624,
                    1308672,
                    1310720,
                    1312768,
                    1314816,
                    1316864,
                    1318912,
                    1320960,
                    1323008,
                    1325056,
                    1327104,
                    1329152,
                    1331200,
                    1333248,
                    1335296,
                    1337344,
                    1339392,
                    1341440,
                    1343488,
                    1345536,
                    1347584,
                    1349632,
                    1351680,
                    1353728,
                    1355776,
                    1357824,
                    1359872,
                    1361920,
                    1363968,
                    1366016,
                    1368064,
                    1370112,
                    1372160,
                    1374208,
                    1376256,
                    1378304,
                    1380352,
                    1382400,
                    1384448,
                    1386496,
                    1388544,
                    1390592,
                    1392640,
                    1394688,
                    1396736,
                    1398784,
                    1400832,
                    1402880,
                    1404928,
                    1406976,
                    1409024,
                    1411072,
                    1413120,
                    1415168,
                    1417216,
                    1419264,
                    1421312,
                    1423360,
                    1425408,
                    1427456,
                    1429504,
                    1431552,
                    1433600,
                    1435648,
                    1437696,
                    1439744,
                    1441792,
                    1443840,
                    1445888,
                    1447936,
                    1449984,
                    1452032,
                    1454080,
                    1456128,
                    1458176,
                    1460224,
                    1462272,
                    1464320,
                    1466368,
                    1468416,
                    1470464,
                    1472512,
                    1474560,
                    1476608,
                    1478656,
                    1480704,
                    1482752,
                    1484800,
                    1486848,
                    1488896,
                    1490944,
                    1492992,
                    1495040,
                    1497088,
                    1499136,
                    1501184,
                    1503232,
                    1505280,
                    1507328,
                    1509376,
                    1511424,
                    1513472,
                    1515520,
                    1517568,
                    1519616,
                    1521664,
                    1523712,
                    1525760,
                    1527808,
                    1529856,
                    1531904,
                    1533952,
                    1536000,
                    1538048,
                    1540096,
                    1542144,
                    1544192,
                    1546240,
                    1548288,
                    1550336,
                    1552384,
                    1554432,
                    1556480,
                    1558528,
                    1560576,
                    1562624,
                    1564672,
                    1566720,
                    1568768,
                    1570816,
                    1572864,
                    1574912,
                    1576960,
                    1579008,
                    1581056,
                    1583104,
                    1585152,
                    1587200,
                    1589248,
                    1591296,
                    1593344,
                    1595392,
                    1597440,
                    1599488,
                    1601536,
                    1603584,
                    1605632,
                    1607680,
                    1609728,
                    1611776,
                    1613824,
                    1615872,
                    1617920,
                    1619968,
                    1622016,
                    1624064,
                    1626112,
                    1628160,
                    1630208,
                    1632256,
                    1634304,
                    1636352,
                    1638400,
                    1640448,
                    1642496,
                    1644544,
                    1646592,
                    1648640,
                    1650688,
                    1652736,
                    1654784,
                    1656832,
                    1658880,
                    1660928,
                    1662976,
                    1665024,
                    1667072,
                    1669120,
                    1671168,
                    1673216,
                    1675264,
                    1677312,
                    1679360,
                    1681408,
                    1683456,
                    1685504,
                    1687552,
                    1689600,
                    1691648,
                    1693696,
                    1695744,
                    1697792,
                    1699840,
                    1701888,
                    1703936,
                    1705984,
                    1708032,
                    1710080,
                    1712128,
                    1714176,
                    1716224,
                    1718272,
                    1720320,
                    1722368,
                    1724416,
                    1726464,
                    1728512,
                    1730560,
                    1732608,
                    1734656,
                    1736704,
                    1738752,
                    1740800,
                    1742848,
                    1744896,
                    1746944,
                    1748992,
                    1751040,
                    1753088,
                    1755136,
                    1757184,
                    1759232,
                    1761280,
                    1763328,
                    1765376,
                    1767424,
                    1769472,
                    1771520,
                    1773568,
                    1775616,
                    1777664,
                    1779712,
                    1781760,
                    1783808,
                    1785856,
                    1787904,
                    1789952,
                    1792000,
                    1794048,
                    1796096,
                    1798144,
                    1800192,
                    1802240,
                    1804288,
                    1806336,
                    1808384,
                    1810432,
                    1812480,
                    1814528,
                    1816576,
                    1818624,
                    1820672,
                    1822720,
                    1824768,
                    1826816,
                    1828864,
                    1830912,
                    1832960,
                    1835008,
                    1837056,
                    1839104,
                    1841152,
                    1843200,
                    1845248,
                    1847296,
                    1849344,
                    1851392,
                    1853440,
                    1855488,
                    1857536,
                    1859584,
                    1861632,
                    1863680,
                    1865728,
                    1867776,
                    1869824,
                    1871872,
                    1873920,
                    1875968,
                    1878016,
                    1880064,
                    1882112,
                    1884160,
                    1886208,
                    1888256,
                    1890304,
                    1892352,
                    1894400,
                    1896448,
                    1898496,
                    1900544,
                    1902592,
                    1904640,
                    1906688,
                    1908736,
                    1910784,
                    1912832,
                    1914880,
                    1916928,
                    1918976,
                    1921024,
                    1923072,
                    1925120,
                    1927168,
                    1929216,
                    1931264,
                    1933312,
                    1935360,
                    1937408,
                    1939456,
                    1941504,
                    1943552,
                    1945600,
                    1947648,
                    1949696,
                    1951744,
                    1953792,
                    1955840,
                    1957888,
                    1959936,
                    1961984,
                    1964032,
                    1966080,
                    1968128,
                    1970176,
                    1972224,
                    1974272,
                    1976320,
                    1978368,
                    1980416,
                    1982464,
                    1984512,
                    1986560,
                    1988608,
                    1990656,
                    1992704,
                    1994752,
                    1996800,
                    1998848,
                    2000896,
                    2002944,
                    2004992,
                    2007040,
                    2009088,
                    2011136,
                    2013184,
                    2015232,
                    2017280,
                    2019328,
                    2021376,
                    2023424,
                    2025472,
                    2027520,
                    2029568,
                    2031616,
                    2033664,
                    2035712,
                    2037760,
                    2039808,
                    2041856,
                    2043904,
                    2045952,
                    2048000,
                    2050048
                  ],
                  "xaxis": "x",
                  "y": [
                    10.893806457519531,
                    10.427045822143555,
                    9.634830474853516,
                    10.264103889465332,
                    9.31908893585205,
                    9.114545822143555,
                    8.989713668823242,
                    9.26657485961914,
                    9.180978775024414,
                    9.055776596069336,
                    8.61603832244873,
                    8.559957504272461,
                    7.807898998260498,
                    7.91976261138916,
                    8.070566177368164,
                    8.144721031188965,
                    6.628560543060303,
                    7.808859348297119,
                    7.625852584838867,
                    8.305569648742676,
                    7.4169535636901855,
                    8.14185905456543,
                    7.313915252685547,
                    7.433940410614014,
                    7.547981262207031,
                    7.983862400054932,
                    7.127997875213623,
                    8.078697204589844,
                    7.674922943115234,
                    7.675109386444092,
                    7.434235095977783,
                    6.662626266479492,
                    7.124334335327148,
                    7.280995845794678,
                    8.049904823303223,
                    7.849207878112793,
                    7.362364292144775,
                    7.178154945373535,
                    7.463449954986572,
                    7.016193866729736,
                    7.165964603424072,
                    7.815927982330322,
                    7.132492542266846,
                    7.43367862701416,
                    6.771230220794678,
                    7.732711315155029,
                    7.033417224884033,
                    7.152134895324707,
                    7.452767848968506,
                    5.829916477203369,
                    5.914529323577881,
                    7.554685115814209,
                    6.6695756912231445,
                    7.587604522705078,
                    6.977630138397217,
                    5.184032440185547,
                    6.905055522918701,
                    6.271007061004639,
                    7.990111827850342,
                    7.912749767303467,
                    7.301448822021484,
                    6.28422212600708,
                    6.436372756958008,
                    7.807494640350342,
                    5.948660850524902,
                    7.79941987991333,
                    6.602100849151611,
                    6.598696231842041,
                    7.384997844696045,
                    5.916327953338623,
                    7.766610622406006,
                    6.166258335113525,
                    6.354918003082275,
                    6.029428482055664,
                    5.2543721199035645,
                    6.982370376586914,
                    6.40958833694458,
                    7.218695640563965,
                    5.283820629119873,
                    7.403279781341553,
                    7.551144599914551,
                    7.717860221862793,
                    7.281604766845703,
                    6.9039106369018555,
                    6.831348896026611,
                    7.377828598022461,
                    7.305034637451172,
                    6.493904113769531,
                    7.502947807312012,
                    7.475921630859375,
                    6.264326095581055,
                    7.900688171386719,
                    6.392958641052246,
                    5.9810099601745605,
                    6.367247104644775,
                    6.246963977813721,
                    5.692319393157959,
                    7.359583377838135,
                    7.038933753967285,
                    7.6092376708984375,
                    7.183945655822754,
                    5.9209113121032715,
                    6.992689609527588,
                    7.349926948547363,
                    6.442592620849609,
                    6.999311923980713,
                    6.716317176818848,
                    7.594215393066406,
                    6.622709274291992,
                    6.699754238128662,
                    5.393760681152344,
                    7.043684482574463,
                    6.514898300170898,
                    6.696376323699951,
                    6.69824743270874,
                    6.460135459899902,
                    7.281935214996338,
                    7.212729454040527,
                    7.594583511352539,
                    7.138926982879639,
                    7.3348188400268555,
                    7.189274311065674,
                    6.738702774047852,
                    6.5225324630737305,
                    6.949594497680664,
                    7.422399520874023,
                    7.410975456237793,
                    6.666720867156982,
                    6.22360372543335,
                    7.085495948791504,
                    5.923482418060303,
                    7.522467136383057,
                    6.361387729644775,
                    5.82284688949585,
                    6.317162036895752,
                    6.981962203979492,
                    7.379582405090332,
                    7.258055686950684,
                    6.434112071990967,
                    7.474478244781494,
                    6.024131774902344,
                    6.669892311096191,
                    6.059913158416748,
                    6.535154342651367,
                    7.081905364990234,
                    6.6076836585998535,
                    7.319371223449707,
                    5.877340316772461,
                    5.5880937576293945,
                    6.722639083862305,
                    6.517719745635986,
                    6.36610221862793,
                    7.354548454284668,
                    6.7593159675598145,
                    6.2848405838012695,
                    7.1035966873168945,
                    6.770442008972168,
                    6.092446327209473,
                    6.611698150634766,
                    7.249154090881348,
                    7.035548210144043,
                    7.410935878753662,
                    6.4828386306762695,
                    7.404731750488281,
                    7.463119983673096,
                    7.264775276184082,
                    7.030026912689209,
                    6.849971771240234,
                    7.444589138031006,
                    5.312416076660156,
                    6.035064220428467,
                    7.059691429138184,
                    6.277189254760742,
                    5.8443074226379395,
                    6.416632652282715,
                    7.28755521774292,
                    6.559230327606201,
                    6.728107929229736,
                    6.1987409591674805,
                    7.212503910064697,
                    6.751069068908691,
                    7.469141960144043,
                    7.459601879119873,
                    7.349392414093018,
                    6.170513153076172,
                    7.395143032073975,
                    7.279488563537598,
                    6.692648410797119,
                    7.316223621368408,
                    6.771309852600098,
                    5.905599594116211,
                    6.544557094573975,
                    5.2595744132995605,
                    6.352523326873779,
                    6.099898815155029,
                    6.16761589050293,
                    7.125868797302246,
                    6.7148237228393555,
                    5.997227668762207,
                    6.733247756958008,
                    6.214476585388184,
                    6.407529830932617,
                    7.264333724975586,
                    6.977560520172119,
                    6.015833854675293,
                    5.969151020050049,
                    7.000478267669678,
                    7.178333759307861,
                    6.263494968414307,
                    7.6479105949401855,
                    5.736992835998535,
                    7.1781744956970215,
                    6.309168338775635,
                    6.672365188598633,
                    5.365495204925537,
                    7.181882381439209,
                    7.348421573638916,
                    6.74544620513916,
                    7.177699565887451,
                    6.935952186584473,
                    6.941099643707275,
                    6.934011936187744,
                    5.753427982330322,
                    6.674023628234863,
                    5.459040641784668,
                    6.063246250152588,
                    6.395949363708496,
                    7.373455047607422,
                    6.879143238067627,
                    7.1031951904296875,
                    6.42634916305542,
                    7.1864447593688965,
                    6.8405632972717285,
                    3.5708701610565186,
                    7.0937581062316895,
                    6.570587635040283,
                    6.882235050201416,
                    7.279861927032471,
                    6.178062915802002,
                    7.118537902832031,
                    6.493494033813477,
                    5.847645282745361,
                    5.426514148712158,
                    7.372856616973877,
                    6.965512275695801,
                    5.870194911956787,
                    6.197558403015137,
                    6.458340644836426,
                    6.9095778465271,
                    6.297845363616943,
                    6.318068504333496,
                    6.843086242675781,
                    6.492095947265625,
                    6.620027542114258,
                    6.984341144561768,
                    6.305624961853027,
                    6.843216896057129,
                    6.46617317199707,
                    6.985827922821045,
                    6.762999057769775,
                    6.4933013916015625,
                    6.540491104125977,
                    6.23700475692749,
                    6.200334072113037,
                    5.087399005889893,
                    6.061723709106445,
                    6.203706741333008,
                    5.4813008308410645,
                    6.1341447830200195,
                    6.042251110076904,
                    5.891076564788818,
                    6.780318260192871,
                    6.889206886291504,
                    7.024605751037598,
                    6.477628707885742,
                    5.8595051765441895,
                    5.17009973526001,
                    6.039463520050049,
                    6.932980060577393,
                    6.82629919052124,
                    6.837954044342041,
                    7.210803985595703,
                    7.130180358886719,
                    7.339724540710449,
                    5.242691516876221,
                    7.033135890960693,
                    6.220620155334473,
                    6.3562774658203125,
                    6.419381618499756,
                    7.239526748657227,
                    7.125497341156006,
                    6.268826961517334,
                    6.306741714477539,
                    6.266530990600586,
                    6.408555030822754,
                    6.608877658843994,
                    7.197091579437256,
                    7.300697326660156,
                    6.535238742828369,
                    6.545780181884766,
                    6.591123104095459,
                    6.527737617492676,
                    5.379087448120117,
                    5.816311836242676,
                    6.979439735412598,
                    6.299715042114258,
                    6.738414764404297,
                    6.83601713180542,
                    6.863978862762451,
                    6.356145858764648,
                    5.8859100341796875,
                    6.475433349609375,
                    7.122377872467041,
                    6.07142448425293,
                    6.694138526916504,
                    5.902716636657715,
                    5.306896686553955,
                    6.100412845611572,
                    6.454117774963379,
                    6.785376071929932,
                    6.912567138671875,
                    5.604643821716309,
                    7.153719425201416,
                    6.470905780792236,
                    6.952639102935791,
                    5.539736270904541,
                    6.790310382843018,
                    6.9054856300354,
                    6.2068681716918945,
                    6.471749782562256,
                    6.596714019775391,
                    6.819143295288086,
                    5.786790370941162,
                    5.1841535568237305,
                    5.967902183532715,
                    6.736931800842285,
                    5.688403129577637,
                    6.72953987121582,
                    6.925650119781494,
                    5.920834541320801,
                    6.706357479095459,
                    6.801548480987549,
                    6.692095756530762,
                    6.381126880645752,
                    5.92860221862793,
                    7.283708095550537,
                    6.068110466003418,
                    6.476272106170654,
                    5.462843894958496,
                    5.8082685470581055,
                    6.196161270141602,
                    5.988715648651123,
                    7.031335830688477,
                    5.655581474304199,
                    6.302164077758789,
                    6.990185260772705,
                    6.657060146331787,
                    5.792215824127197,
                    5.712269306182861,
                    5.634867191314697,
                    5.756242752075195,
                    6.833441734313965,
                    6.653871059417725,
                    6.184776782989502,
                    6.141414642333984,
                    6.0818586349487305,
                    6.62661600112915,
                    6.63861083984375,
                    6.139286994934082,
                    5.828361988067627,
                    5.95382833480835,
                    6.8002848625183105,
                    6.97227668762207,
                    6.524081230163574,
                    6.48838996887207,
                    4.758155822753906,
                    6.398387908935547,
                    6.102293968200684,
                    6.068881511688232,
                    5.9436821937561035,
                    6.9621195793151855,
                    5.715623378753662,
                    7.000760555267334,
                    5.76843786239624,
                    5.78002405166626,
                    5.549404621124268,
                    5.251672267913818,
                    6.037641525268555,
                    5.882079601287842,
                    5.322067737579346,
                    7.192586421966553,
                    5.651959419250488,
                    6.422826290130615,
                    6.721909046173096,
                    6.212947845458984,
                    6.5321269035339355,
                    6.26345157623291,
                    5.321763038635254,
                    6.853144645690918,
                    5.9502129554748535,
                    6.240609169006348,
                    7.064380168914795,
                    7.060173511505127,
                    5.434298515319824,
                    5.713833808898926,
                    5.35958194732666,
                    7.389200687408447,
                    6.6098551750183105,
                    5.971768379211426,
                    6.044561862945557,
                    6.879286766052246,
                    5.353652477264404,
                    7.192244529724121,
                    5.155861854553223,
                    6.459859848022461,
                    6.823322772979736,
                    5.7928643226623535,
                    6.195549964904785,
                    6.129689693450928,
                    5.382623195648193,
                    6.791993618011475,
                    7.066790580749512,
                    6.2079668045043945,
                    5.869408130645752,
                    4.974715709686279,
                    3.9946670532226562,
                    7.120031356811523,
                    6.764587879180908,
                    5.174720764160156,
                    5.589199542999268,
                    5.667579650878906,
                    5.988559246063232,
                    6.569380283355713,
                    6.821842670440674,
                    6.315308094024658,
                    6.189703464508057,
                    6.124805450439453,
                    7.062331199645996,
                    4.86233377456665,
                    6.8343024253845215,
                    6.483643531799316,
                    6.55932092666626,
                    5.6199116706848145,
                    4.8574137687683105,
                    6.9304399490356445,
                    6.953507900238037,
                    6.775815010070801,
                    6.817715167999268,
                    6.5624260902404785,
                    5.681647777557373,
                    5.837902545928955,
                    5.0996479988098145,
                    6.8481268882751465,
                    6.1209235191345215,
                    6.820996284484863,
                    6.056341648101807,
                    6.095166206359863,
                    6.61842679977417,
                    5.438260078430176,
                    5.6815290451049805,
                    5.080475807189941,
                    6.436587333679199,
                    5.884406089782715,
                    5.9520978927612305,
                    5.5276665687561035,
                    6.096118927001953,
                    6.399137020111084,
                    4.965343952178955,
                    6.128511428833008,
                    7.015021324157715,
                    5.319487571716309,
                    6.856664180755615,
                    6.083608150482178,
                    6.367321968078613,
                    5.843657493591309,
                    6.4260478019714355,
                    6.378108978271484,
                    6.459695339202881,
                    6.6272759437561035,
                    6.059246063232422,
                    5.8577470779418945,
                    6.326718807220459,
                    5.700711727142334,
                    6.2530927658081055,
                    6.536418914794922,
                    5.880959987640381,
                    6.49962043762207,
                    6.309074401855469,
                    5.8287248611450195,
                    5.960597991943359,
                    6.050961494445801,
                    5.545186519622803,
                    6.5997138023376465,
                    5.92969274520874,
                    6.413270950317383,
                    6.187255382537842,
                    6.180765151977539,
                    6.33779239654541,
                    6.12028694152832,
                    6.397641181945801,
                    5.3044657707214355,
                    6.83604621887207,
                    6.510043621063232,
                    6.346192836761475,
                    6.65885066986084,
                    6.221997261047363,
                    6.662997245788574,
                    5.459427833557129,
                    6.85530948638916,
                    5.3961591720581055,
                    5.622014045715332,
                    5.986109733581543,
                    6.281040191650391,
                    5.967301845550537,
                    6.529374599456787,
                    6.527423858642578,
                    5.974690914154053,
                    6.404294490814209,
                    5.865479469299316,
                    5.839770317077637,
                    5.659456729888916,
                    6.732898235321045,
                    5.857100009918213,
                    6.750272750854492,
                    6.411985397338867,
                    6.792856216430664,
                    6.249256134033203,
                    6.093013286590576,
                    6.611140727996826,
                    5.683406829833984,
                    5.102623462677002,
                    6.719038963317871,
                    6.895438194274902,
                    6.569279670715332,
                    6.300320148468018,
                    6.2968339920043945,
                    6.411684036254883,
                    6.303232669830322,
                    6.670129299163818,
                    6.057904243469238,
                    6.274672031402588,
                    5.103349208831787,
                    6.7471022605896,
                    6.320355415344238,
                    6.9138264656066895,
                    4.943398952484131,
                    5.276199817657471,
                    6.158751487731934,
                    6.529575824737549,
                    6.511270999908447,
                    6.563686847686768,
                    6.825718402862549,
                    6.0076751708984375,
                    5.515554428100586,
                    6.78159236907959,
                    4.525760650634766,
                    5.7860331535339355,
                    6.884456634521484,
                    4.664862155914307,
                    6.475404262542725,
                    5.991855621337891,
                    5.9356369972229,
                    6.793413162231445,
                    6.159652233123779,
                    6.055816650390625,
                    6.205516815185547,
                    5.20932149887085,
                    6.274753570556641,
                    5.284594535827637,
                    4.9419779777526855,
                    4.458980560302734,
                    6.209834098815918,
                    5.361738681793213,
                    5.023915767669678,
                    5.331613540649414,
                    6.29410982131958,
                    6.466154098510742,
                    5.626280784606934,
                    6.35620641708374,
                    5.478240489959717,
                    5.7116475105285645,
                    5.892956256866455,
                    6.420624256134033,
                    5.794150352478027,
                    5.921229839324951,
                    6.869009017944336,
                    6.1308183670043945,
                    5.915657043457031,
                    6.974363327026367,
                    5.450153350830078,
                    6.449761867523193,
                    6.045516014099121,
                    5.421005725860596,
                    6.253221035003662,
                    5.2270307540893555,
                    6.376247406005859,
                    6.1876349449157715,
                    6.06260871887207,
                    6.720747470855713,
                    5.627060890197754,
                    6.283331394195557,
                    6.351734161376953,
                    5.523952960968018,
                    6.370999336242676,
                    6.451564311981201,
                    6.202211856842041,
                    4.996163845062256,
                    5.659505367279053,
                    5.903824329376221,
                    5.46745491027832,
                    6.066342830657959,
                    6.6164679527282715,
                    4.496311187744141,
                    6.918656349182129,
                    6.374454021453857,
                    6.624735355377197,
                    6.1405181884765625,
                    6.419637680053711,
                    5.368797779083252,
                    5.63762092590332,
                    6.130258083343506,
                    5.883955001831055,
                    5.349919319152832,
                    5.981701850891113,
                    6.619306564331055,
                    5.355196952819824,
                    6.703455924987793,
                    6.215742111206055,
                    6.538422107696533,
                    6.278171539306641,
                    6.039126396179199,
                    5.870230674743652,
                    6.178444862365723,
                    6.194089412689209,
                    6.146444797515869,
                    6.731659889221191,
                    5.233891010284424,
                    5.954592704772949,
                    5.619664669036865,
                    6.739044666290283,
                    5.9534220695495605,
                    6.210587978363037,
                    6.765751361846924,
                    6.739131450653076,
                    5.395712852478027,
                    6.435729503631592,
                    6.559391021728516,
                    6.6493916511535645,
                    5.664209365844727,
                    5.9365363121032715,
                    5.80687952041626,
                    6.157029628753662,
                    6.582067012786865,
                    5.272243976593018,
                    6.387413024902344,
                    6.019307613372803,
                    5.77635383605957,
                    5.32295036315918,
                    5.941738128662109,
                    6.576267242431641,
                    5.763748645782471,
                    5.9041008949279785,
                    5.74242639541626,
                    6.283062934875488,
                    6.257469177246094,
                    6.562018394470215,
                    6.809732437133789,
                    6.094371795654297,
                    6.236048221588135,
                    4.181057929992676,
                    6.251044273376465,
                    6.477835178375244,
                    6.046085357666016,
                    5.837491512298584,
                    6.458290100097656,
                    5.670943260192871,
                    5.2971978187561035,
                    6.108110427856445,
                    5.750730991363525,
                    5.690359115600586,
                    6.7756781578063965,
                    5.08757209777832,
                    6.263877868652344,
                    6.261489391326904,
                    5.932858467102051,
                    6.66238260269165,
                    5.9046430587768555,
                    6.724463939666748,
                    5.962268829345703,
                    6.093897342681885,
                    5.88328742980957,
                    6.031794548034668,
                    5.620194911956787,
                    6.442348957061768,
                    6.230268955230713,
                    5.84187650680542,
                    6.334973335266113,
                    6.030936241149902,
                    6.146600246429443,
                    5.107158660888672,
                    5.6236724853515625,
                    6.439016342163086,
                    6.273532390594482,
                    6.079730033874512,
                    5.274417877197266,
                    5.807642459869385,
                    5.274596214294434,
                    5.956326961517334,
                    6.173469543457031,
                    6.205816745758057,
                    5.946310997009277,
                    5.619250297546387,
                    7.0108642578125,
                    6.019609451293945,
                    6.104399681091309,
                    5.485321998596191,
                    6.42507791519165,
                    6.118117332458496,
                    5.677605628967285,
                    6.27752685546875,
                    5.981806755065918,
                    5.951730251312256,
                    6.593650817871094,
                    5.710947036743164,
                    5.852570056915283,
                    5.670546054840088,
                    6.290445327758789,
                    5.928374290466309,
                    6.097687244415283,
                    6.00021505355835,
                    3.711148977279663,
                    6.25396728515625,
                    5.271996021270752,
                    5.282454967498779,
                    6.487525463104248,
                    6.3335957527160645,
                    5.35158109664917,
                    5.694026470184326,
                    6.299812316894531,
                    6.349177837371826,
                    6.209733486175537,
                    6.428217887878418,
                    5.592421531677246,
                    5.482235431671143,
                    5.584145545959473,
                    5.41577672958374,
                    6.766429424285889,
                    5.789606094360352,
                    5.375753402709961,
                    6.307466506958008,
                    6.318812370300293,
                    6.481020450592041,
                    5.817994594573975,
                    6.273177623748779,
                    6.722898006439209,
                    5.338503837585449,
                    6.670080661773682,
                    5.980781078338623,
                    5.287014007568359,
                    5.842097282409668,
                    5.419844627380371,
                    5.756831645965576,
                    5.9169745445251465,
                    5.530550479888916,
                    6.213921070098877,
                    6.109903812408447,
                    5.853615760803223,
                    6.207830429077148,
                    5.492738246917725,
                    6.175370216369629,
                    3.9055612087249756,
                    6.336564064025879,
                    4.95462703704834,
                    5.901712417602539,
                    5.375865936279297,
                    5.625036716461182,
                    4.983633518218994,
                    6.198032855987549,
                    5.082873344421387,
                    4.950484752655029,
                    5.829664707183838,
                    5.235795497894287,
                    6.1329569816589355,
                    5.456839084625244,
                    5.522766590118408,
                    5.183165073394775,
                    5.625036716461182,
                    5.867244720458984,
                    5.701903820037842,
                    6.661999702453613,
                    6.231913089752197,
                    6.1269636154174805,
                    4.888288974761963,
                    5.385567665100098,
                    5.985903263092041,
                    6.738123893737793,
                    5.537220478057861,
                    5.86268424987793,
                    6.744391441345215,
                    6.640661716461182,
                    5.472293853759766,
                    5.546179294586182,
                    5.534297943115234,
                    6.367386341094971,
                    5.67014741897583,
                    6.480928897857666,
                    5.720998287200928,
                    6.059472560882568,
                    5.823733806610107,
                    4.560082912445068,
                    5.55682373046875,
                    4.636996746063232,
                    5.792925834655762,
                    5.952547550201416,
                    5.223880290985107,
                    6.596568584442139,
                    6.045695781707764,
                    5.875568866729736,
                    6.208745956420898,
                    6.532783508300781,
                    6.210654258728027,
                    6.346561908721924,
                    6.338615894317627,
                    5.9337358474731445,
                    6.433508396148682,
                    6.319293975830078,
                    5.811450004577637,
                    5.49641752243042,
                    5.907059192657471,
                    5.746159553527832,
                    6.503262519836426,
                    5.756721496582031,
                    6.488044738769531,
                    6.117894649505615,
                    5.86445426940918,
                    5.835223197937012,
                    5.549563884735107,
                    5.330730438232422,
                    4.362559795379639,
                    5.012577056884766,
                    5.569671630859375,
                    6.176525592803955,
                    5.664442539215088,
                    6.331360340118408,
                    5.243968486785889,
                    5.100625514984131,
                    6.374338150024414,
                    6.497174263000488,
                    5.70150899887085,
                    5.64119291305542,
                    5.607527732849121,
                    5.71267557144165,
                    6.280437469482422,
                    5.915352821350098,
                    5.677097320556641,
                    6.360349178314209,
                    6.265502452850342,
                    6.178948402404785,
                    5.341156482696533,
                    5.870170593261719,
                    5.4451117515563965,
                    6.241472244262695,
                    5.314521312713623,
                    4.9461517333984375,
                    6.680211544036865,
                    6.917564868927002,
                    6.49563455581665,
                    6.11849308013916,
                    5.478568077087402,
                    6.257815837860107,
                    6.127716064453125,
                    5.675842761993408,
                    6.210302829742432,
                    6.548689842224121,
                    5.86232852935791,
                    5.740886688232422,
                    6.508115768432617,
                    5.909424304962158,
                    6.129854679107666,
                    5.92615270614624,
                    6.129012107849121,
                    5.991880416870117,
                    6.622316837310791,
                    5.540594577789307,
                    6.060328006744385,
                    5.931400775909424,
                    6.792439937591553,
                    5.400372505187988,
                    5.405616283416748,
                    5.465909481048584,
                    5.291983127593994,
                    6.062725067138672,
                    5.695817470550537,
                    6.294777870178223,
                    6.29988431930542,
                    6.702127933502197,
                    5.836272239685059,
                    6.2906880378723145,
                    5.82119083404541,
                    6.386631965637207,
                    3.914015293121338,
                    4.600915431976318,
                    5.786273956298828,
                    5.965373516082764,
                    5.688570022583008,
                    5.874922752380371,
                    5.608105659484863,
                    6.473889350891113,
                    6.068475246429443,
                    5.559708118438721,
                    6.369912147521973,
                    5.660721302032471,
                    6.10959529876709,
                    5.171573162078857,
                    5.885856628417969,
                    6.098738670349121,
                    5.7309136390686035,
                    6.036271095275879,
                    5.380069732666016,
                    6.102173805236816,
                    4.849461078643799,
                    5.115664958953857,
                    6.431756019592285,
                    6.017018795013428,
                    6.432150363922119,
                    5.532230377197266,
                    5.253816604614258,
                    6.474475860595703,
                    3.9770805835723877,
                    6.072547912597656,
                    5.884472370147705,
                    6.253187656402588,
                    5.945555686950684,
                    6.096212863922119,
                    6.4258246421813965,
                    5.689128875732422,
                    6.403471946716309,
                    5.640111446380615,
                    6.316356658935547,
                    5.253259658813477,
                    3.884716033935547,
                    5.994566440582275,
                    6.261377334594727,
                    6.544004917144775,
                    5.812011241912842,
                    5.568344593048096,
                    6.187015056610107,
                    6.731874465942383,
                    4.954038619995117,
                    5.797821044921875,
                    6.174631595611572,
                    4.538426399230957,
                    6.5726213455200195,
                    4.4626264572143555,
                    5.83879280090332,
                    6.313039302825928,
                    5.421074867248535,
                    5.935083389282227,
                    4.370193004608154,
                    6.679178714752197,
                    6.659379959106445,
                    6.706349849700928,
                    5.316075325012207,
                    5.927857875823975,
                    5.195620536804199,
                    5.5007004737854,
                    6.650441646575928,
                    6.306372165679932,
                    6.594603538513184,
                    4.7035698890686035,
                    4.553125381469727,
                    6.798477649688721,
                    5.679795265197754,
                    5.9527788162231445,
                    4.551840305328369,
                    5.673043251037598,
                    6.304561614990234,
                    6.020262241363525,
                    6.0588297843933105,
                    5.522863388061523,
                    5.2381768226623535,
                    6.00363302230835,
                    6.389254570007324,
                    5.4175825119018555,
                    6.422732830047607,
                    5.610039234161377,
                    5.911554336547852,
                    5.2098002433776855,
                    5.918560028076172,
                    5.055022239685059,
                    6.686042308807373,
                    5.942429542541504,
                    5.942678928375244,
                    5.244865894317627,
                    6.026693344116211,
                    6.240598678588867,
                    4.710692405700684,
                    5.621710777282715,
                    5.577942371368408,
                    5.0781660079956055,
                    5.779727458953857,
                    4.423628330230713
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "legend": {
                  "tracegroupgap": 0
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Training curve for my tiny demo model!"
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Tokens"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Loss"
                  }
                }
              }
            },
            "text/html": [
              "<div>                            <div id=\"d657c504-b9c0-4f64-b88a-1888977a57e1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d657c504-b9c0-4f64-b88a-1888977a57e1\")) {                    Plotly.newPlot(                        \"d657c504-b9c0-4f64-b88a-1888977a57e1\",                        [{\"hovertemplate\":\"Tokens=%{x}<br>Loss=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[0,2048,4096,6144,8192,10240,12288,14336,16384,18432,20480,22528,24576,26624,28672,30720,32768,34816,36864,38912,40960,43008,45056,47104,49152,51200,53248,55296,57344,59392,61440,63488,65536,67584,69632,71680,73728,75776,77824,79872,81920,83968,86016,88064,90112,92160,94208,96256,98304,100352,102400,104448,106496,108544,110592,112640,114688,116736,118784,120832,122880,124928,126976,129024,131072,133120,135168,137216,139264,141312,143360,145408,147456,149504,151552,153600,155648,157696,159744,161792,163840,165888,167936,169984,172032,174080,176128,178176,180224,182272,184320,186368,188416,190464,192512,194560,196608,198656,200704,202752,204800,206848,208896,210944,212992,215040,217088,219136,221184,223232,225280,227328,229376,231424,233472,235520,237568,239616,241664,243712,245760,247808,249856,251904,253952,256000,258048,260096,262144,264192,266240,268288,270336,272384,274432,276480,278528,280576,282624,284672,286720,288768,290816,292864,294912,296960,299008,301056,303104,305152,307200,309248,311296,313344,315392,317440,319488,321536,323584,325632,327680,329728,331776,333824,335872,337920,339968,342016,344064,346112,348160,350208,352256,354304,356352,358400,360448,362496,364544,366592,368640,370688,372736,374784,376832,378880,380928,382976,385024,387072,389120,391168,393216,395264,397312,399360,401408,403456,405504,407552,409600,411648,413696,415744,417792,419840,421888,423936,425984,428032,430080,432128,434176,436224,438272,440320,442368,444416,446464,448512,450560,452608,454656,456704,458752,460800,462848,464896,466944,468992,471040,473088,475136,477184,479232,481280,483328,485376,487424,489472,491520,493568,495616,497664,499712,501760,503808,505856,507904,509952,512000,514048,516096,518144,520192,522240,524288,526336,528384,530432,532480,534528,536576,538624,540672,542720,544768,546816,548864,550912,552960,555008,557056,559104,561152,563200,565248,567296,569344,571392,573440,575488,577536,579584,581632,583680,585728,587776,589824,591872,593920,595968,598016,600064,602112,604160,606208,608256,610304,612352,614400,616448,618496,620544,622592,624640,626688,628736,630784,632832,634880,636928,638976,641024,643072,645120,647168,649216,651264,653312,655360,657408,659456,661504,663552,665600,667648,669696,671744,673792,675840,677888,679936,681984,684032,686080,688128,690176,692224,694272,696320,698368,700416,702464,704512,706560,708608,710656,712704,714752,716800,718848,720896,722944,724992,727040,729088,731136,733184,735232,737280,739328,741376,743424,745472,747520,749568,751616,753664,755712,757760,759808,761856,763904,765952,768000,770048,772096,774144,776192,778240,780288,782336,784384,786432,788480,790528,792576,794624,796672,798720,800768,802816,804864,806912,808960,811008,813056,815104,817152,819200,821248,823296,825344,827392,829440,831488,833536,835584,837632,839680,841728,843776,845824,847872,849920,851968,854016,856064,858112,860160,862208,864256,866304,868352,870400,872448,874496,876544,878592,880640,882688,884736,886784,888832,890880,892928,894976,897024,899072,901120,903168,905216,907264,909312,911360,913408,915456,917504,919552,921600,923648,925696,927744,929792,931840,933888,935936,937984,940032,942080,944128,946176,948224,950272,952320,954368,956416,958464,960512,962560,964608,966656,968704,970752,972800,974848,976896,978944,980992,983040,985088,987136,989184,991232,993280,995328,997376,999424,1001472,1003520,1005568,1007616,1009664,1011712,1013760,1015808,1017856,1019904,1021952,1024000,1026048,1028096,1030144,1032192,1034240,1036288,1038336,1040384,1042432,1044480,1046528,1048576,1050624,1052672,1054720,1056768,1058816,1060864,1062912,1064960,1067008,1069056,1071104,1073152,1075200,1077248,1079296,1081344,1083392,1085440,1087488,1089536,1091584,1093632,1095680,1097728,1099776,1101824,1103872,1105920,1107968,1110016,1112064,1114112,1116160,1118208,1120256,1122304,1124352,1126400,1128448,1130496,1132544,1134592,1136640,1138688,1140736,1142784,1144832,1146880,1148928,1150976,1153024,1155072,1157120,1159168,1161216,1163264,1165312,1167360,1169408,1171456,1173504,1175552,1177600,1179648,1181696,1183744,1185792,1187840,1189888,1191936,1193984,1196032,1198080,1200128,1202176,1204224,1206272,1208320,1210368,1212416,1214464,1216512,1218560,1220608,1222656,1224704,1226752,1228800,1230848,1232896,1234944,1236992,1239040,1241088,1243136,1245184,1247232,1249280,1251328,1253376,1255424,1257472,1259520,1261568,1263616,1265664,1267712,1269760,1271808,1273856,1275904,1277952,1280000,1282048,1284096,1286144,1288192,1290240,1292288,1294336,1296384,1298432,1300480,1302528,1304576,1306624,1308672,1310720,1312768,1314816,1316864,1318912,1320960,1323008,1325056,1327104,1329152,1331200,1333248,1335296,1337344,1339392,1341440,1343488,1345536,1347584,1349632,1351680,1353728,1355776,1357824,1359872,1361920,1363968,1366016,1368064,1370112,1372160,1374208,1376256,1378304,1380352,1382400,1384448,1386496,1388544,1390592,1392640,1394688,1396736,1398784,1400832,1402880,1404928,1406976,1409024,1411072,1413120,1415168,1417216,1419264,1421312,1423360,1425408,1427456,1429504,1431552,1433600,1435648,1437696,1439744,1441792,1443840,1445888,1447936,1449984,1452032,1454080,1456128,1458176,1460224,1462272,1464320,1466368,1468416,1470464,1472512,1474560,1476608,1478656,1480704,1482752,1484800,1486848,1488896,1490944,1492992,1495040,1497088,1499136,1501184,1503232,1505280,1507328,1509376,1511424,1513472,1515520,1517568,1519616,1521664,1523712,1525760,1527808,1529856,1531904,1533952,1536000,1538048,1540096,1542144,1544192,1546240,1548288,1550336,1552384,1554432,1556480,1558528,1560576,1562624,1564672,1566720,1568768,1570816,1572864,1574912,1576960,1579008,1581056,1583104,1585152,1587200,1589248,1591296,1593344,1595392,1597440,1599488,1601536,1603584,1605632,1607680,1609728,1611776,1613824,1615872,1617920,1619968,1622016,1624064,1626112,1628160,1630208,1632256,1634304,1636352,1638400,1640448,1642496,1644544,1646592,1648640,1650688,1652736,1654784,1656832,1658880,1660928,1662976,1665024,1667072,1669120,1671168,1673216,1675264,1677312,1679360,1681408,1683456,1685504,1687552,1689600,1691648,1693696,1695744,1697792,1699840,1701888,1703936,1705984,1708032,1710080,1712128,1714176,1716224,1718272,1720320,1722368,1724416,1726464,1728512,1730560,1732608,1734656,1736704,1738752,1740800,1742848,1744896,1746944,1748992,1751040,1753088,1755136,1757184,1759232,1761280,1763328,1765376,1767424,1769472,1771520,1773568,1775616,1777664,1779712,1781760,1783808,1785856,1787904,1789952,1792000,1794048,1796096,1798144,1800192,1802240,1804288,1806336,1808384,1810432,1812480,1814528,1816576,1818624,1820672,1822720,1824768,1826816,1828864,1830912,1832960,1835008,1837056,1839104,1841152,1843200,1845248,1847296,1849344,1851392,1853440,1855488,1857536,1859584,1861632,1863680,1865728,1867776,1869824,1871872,1873920,1875968,1878016,1880064,1882112,1884160,1886208,1888256,1890304,1892352,1894400,1896448,1898496,1900544,1902592,1904640,1906688,1908736,1910784,1912832,1914880,1916928,1918976,1921024,1923072,1925120,1927168,1929216,1931264,1933312,1935360,1937408,1939456,1941504,1943552,1945600,1947648,1949696,1951744,1953792,1955840,1957888,1959936,1961984,1964032,1966080,1968128,1970176,1972224,1974272,1976320,1978368,1980416,1982464,1984512,1986560,1988608,1990656,1992704,1994752,1996800,1998848,2000896,2002944,2004992,2007040,2009088,2011136,2013184,2015232,2017280,2019328,2021376,2023424,2025472,2027520,2029568,2031616,2033664,2035712,2037760,2039808,2041856,2043904,2045952,2048000,2050048],\"xaxis\":\"x\",\"y\":[10.893806457519531,10.427045822143555,9.634830474853516,10.264103889465332,9.31908893585205,9.114545822143555,8.989713668823242,9.26657485961914,9.180978775024414,9.055776596069336,8.61603832244873,8.559957504272461,7.807898998260498,7.91976261138916,8.070566177368164,8.144721031188965,6.628560543060303,7.808859348297119,7.625852584838867,8.305569648742676,7.4169535636901855,8.14185905456543,7.313915252685547,7.433940410614014,7.547981262207031,7.983862400054932,7.127997875213623,8.078697204589844,7.674922943115234,7.675109386444092,7.434235095977783,6.662626266479492,7.124334335327148,7.280995845794678,8.049904823303223,7.849207878112793,7.362364292144775,7.178154945373535,7.463449954986572,7.016193866729736,7.165964603424072,7.815927982330322,7.132492542266846,7.43367862701416,6.771230220794678,7.732711315155029,7.033417224884033,7.152134895324707,7.452767848968506,5.829916477203369,5.914529323577881,7.554685115814209,6.6695756912231445,7.587604522705078,6.977630138397217,5.184032440185547,6.905055522918701,6.271007061004639,7.990111827850342,7.912749767303467,7.301448822021484,6.28422212600708,6.436372756958008,7.807494640350342,5.948660850524902,7.79941987991333,6.602100849151611,6.598696231842041,7.384997844696045,5.916327953338623,7.766610622406006,6.166258335113525,6.354918003082275,6.029428482055664,5.2543721199035645,6.982370376586914,6.40958833694458,7.218695640563965,5.283820629119873,7.403279781341553,7.551144599914551,7.717860221862793,7.281604766845703,6.9039106369018555,6.831348896026611,7.377828598022461,7.305034637451172,6.493904113769531,7.502947807312012,7.475921630859375,6.264326095581055,7.900688171386719,6.392958641052246,5.9810099601745605,6.367247104644775,6.246963977813721,5.692319393157959,7.359583377838135,7.038933753967285,7.6092376708984375,7.183945655822754,5.9209113121032715,6.992689609527588,7.349926948547363,6.442592620849609,6.999311923980713,6.716317176818848,7.594215393066406,6.622709274291992,6.699754238128662,5.393760681152344,7.043684482574463,6.514898300170898,6.696376323699951,6.69824743270874,6.460135459899902,7.281935214996338,7.212729454040527,7.594583511352539,7.138926982879639,7.3348188400268555,7.189274311065674,6.738702774047852,6.5225324630737305,6.949594497680664,7.422399520874023,7.410975456237793,6.666720867156982,6.22360372543335,7.085495948791504,5.923482418060303,7.522467136383057,6.361387729644775,5.82284688949585,6.317162036895752,6.981962203979492,7.379582405090332,7.258055686950684,6.434112071990967,7.474478244781494,6.024131774902344,6.669892311096191,6.059913158416748,6.535154342651367,7.081905364990234,6.6076836585998535,7.319371223449707,5.877340316772461,5.5880937576293945,6.722639083862305,6.517719745635986,6.36610221862793,7.354548454284668,6.7593159675598145,6.2848405838012695,7.1035966873168945,6.770442008972168,6.092446327209473,6.611698150634766,7.249154090881348,7.035548210144043,7.410935878753662,6.4828386306762695,7.404731750488281,7.463119983673096,7.264775276184082,7.030026912689209,6.849971771240234,7.444589138031006,5.312416076660156,6.035064220428467,7.059691429138184,6.277189254760742,5.8443074226379395,6.416632652282715,7.28755521774292,6.559230327606201,6.728107929229736,6.1987409591674805,7.212503910064697,6.751069068908691,7.469141960144043,7.459601879119873,7.349392414093018,6.170513153076172,7.395143032073975,7.279488563537598,6.692648410797119,7.316223621368408,6.771309852600098,5.905599594116211,6.544557094573975,5.2595744132995605,6.352523326873779,6.099898815155029,6.16761589050293,7.125868797302246,6.7148237228393555,5.997227668762207,6.733247756958008,6.214476585388184,6.407529830932617,7.264333724975586,6.977560520172119,6.015833854675293,5.969151020050049,7.000478267669678,7.178333759307861,6.263494968414307,7.6479105949401855,5.736992835998535,7.1781744956970215,6.309168338775635,6.672365188598633,5.365495204925537,7.181882381439209,7.348421573638916,6.74544620513916,7.177699565887451,6.935952186584473,6.941099643707275,6.934011936187744,5.753427982330322,6.674023628234863,5.459040641784668,6.063246250152588,6.395949363708496,7.373455047607422,6.879143238067627,7.1031951904296875,6.42634916305542,7.1864447593688965,6.8405632972717285,3.5708701610565186,7.0937581062316895,6.570587635040283,6.882235050201416,7.279861927032471,6.178062915802002,7.118537902832031,6.493494033813477,5.847645282745361,5.426514148712158,7.372856616973877,6.965512275695801,5.870194911956787,6.197558403015137,6.458340644836426,6.9095778465271,6.297845363616943,6.318068504333496,6.843086242675781,6.492095947265625,6.620027542114258,6.984341144561768,6.305624961853027,6.843216896057129,6.46617317199707,6.985827922821045,6.762999057769775,6.4933013916015625,6.540491104125977,6.23700475692749,6.200334072113037,5.087399005889893,6.061723709106445,6.203706741333008,5.4813008308410645,6.1341447830200195,6.042251110076904,5.891076564788818,6.780318260192871,6.889206886291504,7.024605751037598,6.477628707885742,5.8595051765441895,5.17009973526001,6.039463520050049,6.932980060577393,6.82629919052124,6.837954044342041,7.210803985595703,7.130180358886719,7.339724540710449,5.242691516876221,7.033135890960693,6.220620155334473,6.3562774658203125,6.419381618499756,7.239526748657227,7.125497341156006,6.268826961517334,6.306741714477539,6.266530990600586,6.408555030822754,6.608877658843994,7.197091579437256,7.300697326660156,6.535238742828369,6.545780181884766,6.591123104095459,6.527737617492676,5.379087448120117,5.816311836242676,6.979439735412598,6.299715042114258,6.738414764404297,6.83601713180542,6.863978862762451,6.356145858764648,5.8859100341796875,6.475433349609375,7.122377872467041,6.07142448425293,6.694138526916504,5.902716636657715,5.306896686553955,6.100412845611572,6.454117774963379,6.785376071929932,6.912567138671875,5.604643821716309,7.153719425201416,6.470905780792236,6.952639102935791,5.539736270904541,6.790310382843018,6.9054856300354,6.2068681716918945,6.471749782562256,6.596714019775391,6.819143295288086,5.786790370941162,5.1841535568237305,5.967902183532715,6.736931800842285,5.688403129577637,6.72953987121582,6.925650119781494,5.920834541320801,6.706357479095459,6.801548480987549,6.692095756530762,6.381126880645752,5.92860221862793,7.283708095550537,6.068110466003418,6.476272106170654,5.462843894958496,5.8082685470581055,6.196161270141602,5.988715648651123,7.031335830688477,5.655581474304199,6.302164077758789,6.990185260772705,6.657060146331787,5.792215824127197,5.712269306182861,5.634867191314697,5.756242752075195,6.833441734313965,6.653871059417725,6.184776782989502,6.141414642333984,6.0818586349487305,6.62661600112915,6.63861083984375,6.139286994934082,5.828361988067627,5.95382833480835,6.8002848625183105,6.97227668762207,6.524081230163574,6.48838996887207,4.758155822753906,6.398387908935547,6.102293968200684,6.068881511688232,5.9436821937561035,6.9621195793151855,5.715623378753662,7.000760555267334,5.76843786239624,5.78002405166626,5.549404621124268,5.251672267913818,6.037641525268555,5.882079601287842,5.322067737579346,7.192586421966553,5.651959419250488,6.422826290130615,6.721909046173096,6.212947845458984,6.5321269035339355,6.26345157623291,5.321763038635254,6.853144645690918,5.9502129554748535,6.240609169006348,7.064380168914795,7.060173511505127,5.434298515319824,5.713833808898926,5.35958194732666,7.389200687408447,6.6098551750183105,5.971768379211426,6.044561862945557,6.879286766052246,5.353652477264404,7.192244529724121,5.155861854553223,6.459859848022461,6.823322772979736,5.7928643226623535,6.195549964904785,6.129689693450928,5.382623195648193,6.791993618011475,7.066790580749512,6.2079668045043945,5.869408130645752,4.974715709686279,3.9946670532226562,7.120031356811523,6.764587879180908,5.174720764160156,5.589199542999268,5.667579650878906,5.988559246063232,6.569380283355713,6.821842670440674,6.315308094024658,6.189703464508057,6.124805450439453,7.062331199645996,4.86233377456665,6.8343024253845215,6.483643531799316,6.55932092666626,5.6199116706848145,4.8574137687683105,6.9304399490356445,6.953507900238037,6.775815010070801,6.817715167999268,6.5624260902404785,5.681647777557373,5.837902545928955,5.0996479988098145,6.8481268882751465,6.1209235191345215,6.820996284484863,6.056341648101807,6.095166206359863,6.61842679977417,5.438260078430176,5.6815290451049805,5.080475807189941,6.436587333679199,5.884406089782715,5.9520978927612305,5.5276665687561035,6.096118927001953,6.399137020111084,4.965343952178955,6.128511428833008,7.015021324157715,5.319487571716309,6.856664180755615,6.083608150482178,6.367321968078613,5.843657493591309,6.4260478019714355,6.378108978271484,6.459695339202881,6.6272759437561035,6.059246063232422,5.8577470779418945,6.326718807220459,5.700711727142334,6.2530927658081055,6.536418914794922,5.880959987640381,6.49962043762207,6.309074401855469,5.8287248611450195,5.960597991943359,6.050961494445801,5.545186519622803,6.5997138023376465,5.92969274520874,6.413270950317383,6.187255382537842,6.180765151977539,6.33779239654541,6.12028694152832,6.397641181945801,5.3044657707214355,6.83604621887207,6.510043621063232,6.346192836761475,6.65885066986084,6.221997261047363,6.662997245788574,5.459427833557129,6.85530948638916,5.3961591720581055,5.622014045715332,5.986109733581543,6.281040191650391,5.967301845550537,6.529374599456787,6.527423858642578,5.974690914154053,6.404294490814209,5.865479469299316,5.839770317077637,5.659456729888916,6.732898235321045,5.857100009918213,6.750272750854492,6.411985397338867,6.792856216430664,6.249256134033203,6.093013286590576,6.611140727996826,5.683406829833984,5.102623462677002,6.719038963317871,6.895438194274902,6.569279670715332,6.300320148468018,6.2968339920043945,6.411684036254883,6.303232669830322,6.670129299163818,6.057904243469238,6.274672031402588,5.103349208831787,6.7471022605896,6.320355415344238,6.9138264656066895,4.943398952484131,5.276199817657471,6.158751487731934,6.529575824737549,6.511270999908447,6.563686847686768,6.825718402862549,6.0076751708984375,5.515554428100586,6.78159236907959,4.525760650634766,5.7860331535339355,6.884456634521484,4.664862155914307,6.475404262542725,5.991855621337891,5.9356369972229,6.793413162231445,6.159652233123779,6.055816650390625,6.205516815185547,5.20932149887085,6.274753570556641,5.284594535827637,4.9419779777526855,4.458980560302734,6.209834098815918,5.361738681793213,5.023915767669678,5.331613540649414,6.29410982131958,6.466154098510742,5.626280784606934,6.35620641708374,5.478240489959717,5.7116475105285645,5.892956256866455,6.420624256134033,5.794150352478027,5.921229839324951,6.869009017944336,6.1308183670043945,5.915657043457031,6.974363327026367,5.450153350830078,6.449761867523193,6.045516014099121,5.421005725860596,6.253221035003662,5.2270307540893555,6.376247406005859,6.1876349449157715,6.06260871887207,6.720747470855713,5.627060890197754,6.283331394195557,6.351734161376953,5.523952960968018,6.370999336242676,6.451564311981201,6.202211856842041,4.996163845062256,5.659505367279053,5.903824329376221,5.46745491027832,6.066342830657959,6.6164679527282715,4.496311187744141,6.918656349182129,6.374454021453857,6.624735355377197,6.1405181884765625,6.419637680053711,5.368797779083252,5.63762092590332,6.130258083343506,5.883955001831055,5.349919319152832,5.981701850891113,6.619306564331055,5.355196952819824,6.703455924987793,6.215742111206055,6.538422107696533,6.278171539306641,6.039126396179199,5.870230674743652,6.178444862365723,6.194089412689209,6.146444797515869,6.731659889221191,5.233891010284424,5.954592704772949,5.619664669036865,6.739044666290283,5.9534220695495605,6.210587978363037,6.765751361846924,6.739131450653076,5.395712852478027,6.435729503631592,6.559391021728516,6.6493916511535645,5.664209365844727,5.9365363121032715,5.80687952041626,6.157029628753662,6.582067012786865,5.272243976593018,6.387413024902344,6.019307613372803,5.77635383605957,5.32295036315918,5.941738128662109,6.576267242431641,5.763748645782471,5.9041008949279785,5.74242639541626,6.283062934875488,6.257469177246094,6.562018394470215,6.809732437133789,6.094371795654297,6.236048221588135,4.181057929992676,6.251044273376465,6.477835178375244,6.046085357666016,5.837491512298584,6.458290100097656,5.670943260192871,5.2971978187561035,6.108110427856445,5.750730991363525,5.690359115600586,6.7756781578063965,5.08757209777832,6.263877868652344,6.261489391326904,5.932858467102051,6.66238260269165,5.9046430587768555,6.724463939666748,5.962268829345703,6.093897342681885,5.88328742980957,6.031794548034668,5.620194911956787,6.442348957061768,6.230268955230713,5.84187650680542,6.334973335266113,6.030936241149902,6.146600246429443,5.107158660888672,5.6236724853515625,6.439016342163086,6.273532390594482,6.079730033874512,5.274417877197266,5.807642459869385,5.274596214294434,5.956326961517334,6.173469543457031,6.205816745758057,5.946310997009277,5.619250297546387,7.0108642578125,6.019609451293945,6.104399681091309,5.485321998596191,6.42507791519165,6.118117332458496,5.677605628967285,6.27752685546875,5.981806755065918,5.951730251312256,6.593650817871094,5.710947036743164,5.852570056915283,5.670546054840088,6.290445327758789,5.928374290466309,6.097687244415283,6.00021505355835,3.711148977279663,6.25396728515625,5.271996021270752,5.282454967498779,6.487525463104248,6.3335957527160645,5.35158109664917,5.694026470184326,6.299812316894531,6.349177837371826,6.209733486175537,6.428217887878418,5.592421531677246,5.482235431671143,5.584145545959473,5.41577672958374,6.766429424285889,5.789606094360352,5.375753402709961,6.307466506958008,6.318812370300293,6.481020450592041,5.817994594573975,6.273177623748779,6.722898006439209,5.338503837585449,6.670080661773682,5.980781078338623,5.287014007568359,5.842097282409668,5.419844627380371,5.756831645965576,5.9169745445251465,5.530550479888916,6.213921070098877,6.109903812408447,5.853615760803223,6.207830429077148,5.492738246917725,6.175370216369629,3.9055612087249756,6.336564064025879,4.95462703704834,5.901712417602539,5.375865936279297,5.625036716461182,4.983633518218994,6.198032855987549,5.082873344421387,4.950484752655029,5.829664707183838,5.235795497894287,6.1329569816589355,5.456839084625244,5.522766590118408,5.183165073394775,5.625036716461182,5.867244720458984,5.701903820037842,6.661999702453613,6.231913089752197,6.1269636154174805,4.888288974761963,5.385567665100098,5.985903263092041,6.738123893737793,5.537220478057861,5.86268424987793,6.744391441345215,6.640661716461182,5.472293853759766,5.546179294586182,5.534297943115234,6.367386341094971,5.67014741897583,6.480928897857666,5.720998287200928,6.059472560882568,5.823733806610107,4.560082912445068,5.55682373046875,4.636996746063232,5.792925834655762,5.952547550201416,5.223880290985107,6.596568584442139,6.045695781707764,5.875568866729736,6.208745956420898,6.532783508300781,6.210654258728027,6.346561908721924,6.338615894317627,5.9337358474731445,6.433508396148682,6.319293975830078,5.811450004577637,5.49641752243042,5.907059192657471,5.746159553527832,6.503262519836426,5.756721496582031,6.488044738769531,6.117894649505615,5.86445426940918,5.835223197937012,5.549563884735107,5.330730438232422,4.362559795379639,5.012577056884766,5.569671630859375,6.176525592803955,5.664442539215088,6.331360340118408,5.243968486785889,5.100625514984131,6.374338150024414,6.497174263000488,5.70150899887085,5.64119291305542,5.607527732849121,5.71267557144165,6.280437469482422,5.915352821350098,5.677097320556641,6.360349178314209,6.265502452850342,6.178948402404785,5.341156482696533,5.870170593261719,5.4451117515563965,6.241472244262695,5.314521312713623,4.9461517333984375,6.680211544036865,6.917564868927002,6.49563455581665,6.11849308013916,5.478568077087402,6.257815837860107,6.127716064453125,5.675842761993408,6.210302829742432,6.548689842224121,5.86232852935791,5.740886688232422,6.508115768432617,5.909424304962158,6.129854679107666,5.92615270614624,6.129012107849121,5.991880416870117,6.622316837310791,5.540594577789307,6.060328006744385,5.931400775909424,6.792439937591553,5.400372505187988,5.405616283416748,5.465909481048584,5.291983127593994,6.062725067138672,5.695817470550537,6.294777870178223,6.29988431930542,6.702127933502197,5.836272239685059,6.2906880378723145,5.82119083404541,6.386631965637207,3.914015293121338,4.600915431976318,5.786273956298828,5.965373516082764,5.688570022583008,5.874922752380371,5.608105659484863,6.473889350891113,6.068475246429443,5.559708118438721,6.369912147521973,5.660721302032471,6.10959529876709,5.171573162078857,5.885856628417969,6.098738670349121,5.7309136390686035,6.036271095275879,5.380069732666016,6.102173805236816,4.849461078643799,5.115664958953857,6.431756019592285,6.017018795013428,6.432150363922119,5.532230377197266,5.253816604614258,6.474475860595703,3.9770805835723877,6.072547912597656,5.884472370147705,6.253187656402588,5.945555686950684,6.096212863922119,6.4258246421813965,5.689128875732422,6.403471946716309,5.640111446380615,6.316356658935547,5.253259658813477,3.884716033935547,5.994566440582275,6.261377334594727,6.544004917144775,5.812011241912842,5.568344593048096,6.187015056610107,6.731874465942383,4.954038619995117,5.797821044921875,6.174631595611572,4.538426399230957,6.5726213455200195,4.4626264572143555,5.83879280090332,6.313039302825928,5.421074867248535,5.935083389282227,4.370193004608154,6.679178714752197,6.659379959106445,6.706349849700928,5.316075325012207,5.927857875823975,5.195620536804199,5.5007004737854,6.650441646575928,6.306372165679932,6.594603538513184,4.7035698890686035,4.553125381469727,6.798477649688721,5.679795265197754,5.9527788162231445,4.551840305328369,5.673043251037598,6.304561614990234,6.020262241363525,6.0588297843933105,5.522863388061523,5.2381768226623535,6.00363302230835,6.389254570007324,5.4175825119018555,6.422732830047607,5.610039234161377,5.911554336547852,5.2098002433776855,5.918560028076172,5.055022239685059,6.686042308807373,5.942429542541504,5.942678928375244,5.244865894317627,6.026693344116211,6.240598678588867,4.710692405700684,5.621710777282715,5.577942371368408,5.0781660079956055,5.779727458953857,4.423628330230713],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tokens\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Training curve for my tiny demo model!\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d657c504-b9c0-4f64-b88a-1888977a57e1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "px.line(y=losses, x=np.arange(len(losses))*(model_cfg.n_ctx * batch_size), labels={\"y\":\"Loss\", \"x\":\"Tokens\"}, title=\"Training curve for my tiny demo model!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c8181dd8ff94d11b0ed510e8931aae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8cb632aad3b4eb8ac41c91074f696f7",
              "IPY_MODEL_d04115e9a80040b59a130d03a8bd57d3",
              "IPY_MODEL_c157f651b5ee4f709ae400dd8e92bfd4"
            ],
            "layout": "IPY_MODEL_8abde9b4211643e6910e8ae13406c7ba"
          }
        },
        "c8cb632aad3b4eb8ac41c91074f696f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96dffe98d29840338b5a7d98c571b6a6",
            "placeholder": "​",
            "style": "IPY_MODEL_f1a240fa6b994c12b33b5fbd76251c31",
            "value": "config.json: 100%"
          }
        },
        "d04115e9a80040b59a130d03a8bd57d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc2ef514af354f75a5382186dabb46ce",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d63713089ed04338a9407eef66a0f9b7",
            "value": 665
          }
        },
        "c157f651b5ee4f709ae400dd8e92bfd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3287e3d3e34fdbb8fdf9b65ad5eb30",
            "placeholder": "​",
            "style": "IPY_MODEL_9d79ee77c9f14f6f9caa410fa6693afc",
            "value": " 665/665 [00:00&lt;00:00, 46.9kB/s]"
          }
        },
        "8abde9b4211643e6910e8ae13406c7ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96dffe98d29840338b5a7d98c571b6a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a240fa6b994c12b33b5fbd76251c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc2ef514af354f75a5382186dabb46ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63713089ed04338a9407eef66a0f9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd3287e3d3e34fdbb8fdf9b65ad5eb30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d79ee77c9f14f6f9caa410fa6693afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82af410359ab4ca0a579bf88843c8812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d65ae05918245e59dbcdba5c6479461",
              "IPY_MODEL_99e8dba4d8d2452fa51ef6d670e6c70c",
              "IPY_MODEL_92e5e34dc61b4d7eb642773f43ba4a56"
            ],
            "layout": "IPY_MODEL_7982b8da80dc45a7b8c29268a1cb7625"
          }
        },
        "0d65ae05918245e59dbcdba5c6479461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b928796ac04afaae5bcf51b6319b3e",
            "placeholder": "​",
            "style": "IPY_MODEL_5f7d679b4541423b9684805e3be605ef",
            "value": "model.safetensors: 100%"
          }
        },
        "99e8dba4d8d2452fa51ef6d670e6c70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d1befb1eb341919adc3948981863e3",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a9cd3f50a83406a931c9df1bf98b330",
            "value": 548105171
          }
        },
        "92e5e34dc61b4d7eb642773f43ba4a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ada788302fd4444fb8b437d4b71ef099",
            "placeholder": "​",
            "style": "IPY_MODEL_21c518e0957149a798148f1e889884fe",
            "value": " 548M/548M [00:11&lt;00:00, 82.8MB/s]"
          }
        },
        "7982b8da80dc45a7b8c29268a1cb7625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b928796ac04afaae5bcf51b6319b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f7d679b4541423b9684805e3be605ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38d1befb1eb341919adc3948981863e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9cd3f50a83406a931c9df1bf98b330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ada788302fd4444fb8b437d4b71ef099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21c518e0957149a798148f1e889884fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9037d7e8aaa84b59a626bc40fabef33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4647c5d1f62f4b7da798e077dfd13d75",
              "IPY_MODEL_4043b6e2f54b4292adca53fac33abbd1",
              "IPY_MODEL_8d25a786e0af4af4a24f4fa048015b74"
            ],
            "layout": "IPY_MODEL_15a92c914d5a4c66b5b849463b7576ba"
          }
        },
        "4647c5d1f62f4b7da798e077dfd13d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a44b93d7f5334a6b8f539f21757d6bac",
            "placeholder": "​",
            "style": "IPY_MODEL_e32d34b05d7041a58391e1dde7d3fd0e",
            "value": "generation_config.json: 100%"
          }
        },
        "4043b6e2f54b4292adca53fac33abbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_001d71dad8ad48e686a09e232a13d156",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddeb9f11ba96430891b160a0c9a49e77",
            "value": 124
          }
        },
        "8d25a786e0af4af4a24f4fa048015b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1591ed31c544bdc8afd75135b22095a",
            "placeholder": "​",
            "style": "IPY_MODEL_0d7a943e32fb4fba879d792687fc28d9",
            "value": " 124/124 [00:00&lt;00:00, 3.06kB/s]"
          }
        },
        "15a92c914d5a4c66b5b849463b7576ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a44b93d7f5334a6b8f539f21757d6bac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32d34b05d7041a58391e1dde7d3fd0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "001d71dad8ad48e686a09e232a13d156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddeb9f11ba96430891b160a0c9a49e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1591ed31c544bdc8afd75135b22095a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7a943e32fb4fba879d792687fc28d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8cdea6200674bdd9c90a5aab0b1f1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2168fb05c4f0427099f1ca74cd727ec4",
              "IPY_MODEL_48f6924dfab2446cbaffc78cbe3da60e",
              "IPY_MODEL_d450ca4ebed3473680101453ce26e6c2"
            ],
            "layout": "IPY_MODEL_b4c305614fff46e3ac7151103819e847"
          }
        },
        "2168fb05c4f0427099f1ca74cd727ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3672a6d20c402abede0c01e7ef4267",
            "placeholder": "​",
            "style": "IPY_MODEL_31e06f4a3e674697ab7256d86e6f0bcd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "48f6924dfab2446cbaffc78cbe3da60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e5b1119703b4fd18aa7742b98f35c75",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de54c2a350634e7797d7a11f8f9a1e66",
            "value": 26
          }
        },
        "d450ca4ebed3473680101453ce26e6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af015914107f424b839bee44f3341f66",
            "placeholder": "​",
            "style": "IPY_MODEL_44d8e490340647aa96ff0d9bcae9ec9c",
            "value": " 26.0/26.0 [00:00&lt;00:00, 531B/s]"
          }
        },
        "b4c305614fff46e3ac7151103819e847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3672a6d20c402abede0c01e7ef4267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31e06f4a3e674697ab7256d86e6f0bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e5b1119703b4fd18aa7742b98f35c75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de54c2a350634e7797d7a11f8f9a1e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af015914107f424b839bee44f3341f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d8e490340647aa96ff0d9bcae9ec9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66f3c15dd37d4882938d2e641b49671e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_828841e6cf924be7b68f2901bd2a9ec6",
              "IPY_MODEL_16748686b196440c923a0bf835542567",
              "IPY_MODEL_692e96f67cdb4cedaef4ff264a9632b8"
            ],
            "layout": "IPY_MODEL_f85d9c679da846be8c04bc125e5df1e8"
          }
        },
        "828841e6cf924be7b68f2901bd2a9ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77536c03f4cd409d982e54fc3d3f04e1",
            "placeholder": "​",
            "style": "IPY_MODEL_e26fee4acb524ce1ab32d7421020e84f",
            "value": "vocab.json: 100%"
          }
        },
        "16748686b196440c923a0bf835542567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_545b59cbdbc24102b8d36ece9a999294",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fb4790f80144af897db2a3c7a123187",
            "value": 1042301
          }
        },
        "692e96f67cdb4cedaef4ff264a9632b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a645bfd250324dbaa48ea5cef5258dec",
            "placeholder": "​",
            "style": "IPY_MODEL_0490656a43b545419ce6f52c493c4ac6",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.72MB/s]"
          }
        },
        "f85d9c679da846be8c04bc125e5df1e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77536c03f4cd409d982e54fc3d3f04e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26fee4acb524ce1ab32d7421020e84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "545b59cbdbc24102b8d36ece9a999294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb4790f80144af897db2a3c7a123187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a645bfd250324dbaa48ea5cef5258dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0490656a43b545419ce6f52c493c4ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df7c1dac2f91454e8fcc6299c8e63fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c638959ba994fefa69407027f35742a",
              "IPY_MODEL_bf61f64f641842d893f21da7ff5daae1",
              "IPY_MODEL_b8ac496f62124c7f9f2453431975403d"
            ],
            "layout": "IPY_MODEL_17cc2d67f572411f832e5e4b9d553998"
          }
        },
        "7c638959ba994fefa69407027f35742a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f4f66ef3dd24a3b818b5a5057a34026",
            "placeholder": "​",
            "style": "IPY_MODEL_9ef1d83004834764a7d17cd78b3f3e52",
            "value": "merges.txt: 100%"
          }
        },
        "bf61f64f641842d893f21da7ff5daae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a094e49e62a4025bdf15e6aeceaba2b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60c4f78b529341f1b045ab03750b550b",
            "value": 456318
          }
        },
        "b8ac496f62124c7f9f2453431975403d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dcae6d0e2384ee28bb44dd6a6d78073",
            "placeholder": "​",
            "style": "IPY_MODEL_f176e9c1f7d4490daffaeed9a94e74a7",
            "value": " 456k/456k [00:00&lt;00:00, 7.28MB/s]"
          }
        },
        "17cc2d67f572411f832e5e4b9d553998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f4f66ef3dd24a3b818b5a5057a34026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef1d83004834764a7d17cd78b3f3e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a094e49e62a4025bdf15e6aeceaba2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c4f78b529341f1b045ab03750b550b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0dcae6d0e2384ee28bb44dd6a6d78073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f176e9c1f7d4490daffaeed9a94e74a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58e0eaf64a9c4b098c309f01c724698e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0197409cd3b549a49264b7c23ec69467",
              "IPY_MODEL_60274d0c19a645dbbb4571820d07b129",
              "IPY_MODEL_9771ba5899ec4732b2f09fef379bb41e"
            ],
            "layout": "IPY_MODEL_e182ea65c6ea480ba4f16fd14aee4485"
          }
        },
        "0197409cd3b549a49264b7c23ec69467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa856f617c541198101a5347d6a6202",
            "placeholder": "​",
            "style": "IPY_MODEL_ee6c86eaea0f4e20826d326e94af5a06",
            "value": "tokenizer.json: 100%"
          }
        },
        "60274d0c19a645dbbb4571820d07b129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51084c124c1a4308911c6a0d151d752d",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6709981f786473f8f449419304650cd",
            "value": 1355256
          }
        },
        "9771ba5899ec4732b2f09fef379bb41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa1e1c55f3b4a3fa0cd8b48f7f0c504",
            "placeholder": "​",
            "style": "IPY_MODEL_100f8502551d4656a1c404857f0b8b2f",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 13.5MB/s]"
          }
        },
        "e182ea65c6ea480ba4f16fd14aee4485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aa856f617c541198101a5347d6a6202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6c86eaea0f4e20826d326e94af5a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51084c124c1a4308911c6a0d151d752d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6709981f786473f8f449419304650cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aa1e1c55f3b4a3fa0cd8b48f7f0c504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "100f8502551d4656a1c404857f0b8b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}