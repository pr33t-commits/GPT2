{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3TtRLIuJqEl"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This is a template for a clean, first principles implementation of GPT-2 in PyTorch. This is an accompaniment to [my video tutorial on implementing GPT-2](https://neelnanda.io/transformer-tutorial-2). If you want to properly understand how to implement GPT-2, you'll need to do it yourself! **I recommend filling out this template *as* you watch the video, and seeing how far you can get with each section before watching me do it**. Each section comes with tests, so you can check that you got it right. You can see [a solution notebook here](https://www.neelnanda.io/transformer-solution) - use it if you get stuck, but make an attempt first, and no copying and pasting!\n",
        "\n",
        "There's a [template version of this notebook here](https://neelnanda.io/transformer-template), go and fill in the blanks (no copying and pasting!) and see if you can pass the tests.\n",
        "\n",
        "If you enjoyed this, I expect you'd enjoy learning more about what's actually going on inside these models and how to reverse engineer them! This is a fascinating young research field, with a lot of low-hanging fruit and open problems! **I recommend starting with my post [Concrete Steps for Getting Started in Mechanistic Interpretability](https://www.neelnanda.io/mechanistic-interpretability/getting-started).**\n",
        "\n",
        "This notebook was written to accompany my [TransformerLens library](https://github.com/neelnanda-io/TransformerLens) for doing mechanistic interpretability research on GPT-2 style language models, and is a clean implementation of the underlying transformer architecture in the library. (This notebook is based off of an earlier version called EasyTransformer)\n",
        "\n",
        "Further Resources:\n",
        "* [A Comprehensive Mechanistic Interpretability Explainer & Glossary](https://www.neelnanda.io/glossary)\n",
        "    * Expecially [the transformers section](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=pndoEIqJ6GPvC1yENQkEfZYR)\n",
        "* [200 Concrete Open Problems in Mechanistic Interpretability](https://www.neelnanda.io/concrete-open-problems)\n",
        "* My [TransformerLens library](https://github.com/neelnanda-io/TransformerLens) for doing mechanistic interpretability research on GPT-2 style language models.\n",
        "* My walkthrough of [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html), for a deeper dive into how to think about transformers:.\n",
        "\n",
        "Check out these other intros to transformers for another perspective:\n",
        "* Jay Alammar's [illustrated transformer](https://jalammar.github.io/illustrated-transformer/)\n",
        "* [Andrej Karpathy's MinGPT](https://github.com/karpathy/minGPT)\n",
        "\n",
        "**Sharing Guidelines:** This tutorial is still a bit of a work in progress! I think it's usable, but please don't post it anywhere publicly without checking with me first! Sharing with friends is fine.\n",
        "\n",
        "If you've found this useful, I'd love to hear about it! Positive and negative feedback also very welcome. You can reach me via [email](mailto:neelnanda27@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9bN56U1JqEw"
      },
      "source": [
        "## Instructions\n",
        "* No need to read the Setup Section\n",
        "* Go to runtime > Change Runtime Type and set it to use a GPU\n",
        "* Read and run notebook up until the start of the section \"Actual Code!\". Then go to the template notebook and try coding up the model yourself!\n",
        "    * Bonus points for doing that without reading the solutions, and before I do it in the video!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSWYYF36JqEx"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kksFvS9vJqEz",
        "outputId": "6156ac23-e1d2-4a33-c5e4-5006ea9543f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
            "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git (to revision clean-transformer-demo) to /tmp/pip-req-build-p40f7fvp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /tmp/pip-req-build-p40f7fvp\n",
            "  Running command git checkout -b clean-transformer-demo --track origin/clean-transformer-demo\n",
            "  Switched to a new branch 'clean-transformer-demo'\n",
            "  Branch 'clean-transformer-demo' set up to track remote branch 'clean-transformer-demo' from 'origin'.\n",
            "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 1f25219e631aeb478d17075d47274db32c874e88\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (2.14.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from easy_transformer==0.1.0) (0.19.11)\n",
            "Collecting fancy_einsum (from easy_transformer==0.1.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets->easy_transformer==0.1.0) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->easy_transformer==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->easy_transformer==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->easy_transformer==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->easy_transformer==0.1.0) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->easy_transformer==0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easy_transformer==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easy_transformer==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->easy_transformer==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->easy_transformer==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->easy_transformer==0.1.0) (0.5.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (2.11.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->easy_transformer==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->easy_transformer==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->easy_transformer==0.1.0) (1.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->easy_transformer==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->easy_transformer==0.1.0) (1.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->easy_transformer==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->easy_transformer==0.1.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->easy_transformer==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->easy_transformer==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->easy_transformer==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->easy_transformer==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->easy_transformer==0.1.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easy_transformer==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->easy_transformer==0.1.0) (5.0.2)\n",
            "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: easy_transformer\n",
            "  Building wheel for easy_transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easy_transformer: filename=easy_transformer-0.1.0-py3-none-any.whl size=55601 sha256=162e7de782675ebe1ad06378e1cab4e48ca619863b9733328b3fa8c7c9137c2d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ys8600g0/wheels/bf/56/b1/e601264be47cea8ab7d082bfd13e38f6a652e3790a0a225496\n",
            "Successfully built easy_transformer\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fancy_einsum, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easy_transformer\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easy_transformer-0.1.0 fancy_einsum-0.0.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "  \u001b[1m\u001b[33m                            DEPRECATION WARNING                            \u001b[m\n",
            "\n",
            "    \u001b[1m\u001b[4m Node.js 16.x is no longer actively supported!\u001b[m\n",
            "\n",
            "  \u001b[1mYou will not receive security or critical stability updates\u001b[m for this version.\n",
            "\n",
            "  You should migrate to a supported version of Node.js as soon as possible.\n",
            "  Use the installation script that corresponds to the version of Node.js you\n",
            "  wish to install. e.g.\n",
            "  \n",
            "   * \u001b[31mhttps://deb.nodesource.com/setup_16.x — Node.js 16 \"Gallium\" \u001b[1m(deprecated)\u001b[m\n",
            "   * \u001b[32mhttps://deb.nodesource.com/setup_18.x — Node.js 18 \"Hydrogen\" (Maintenance)\u001b[m\n",
            "   * \u001b[31mhttps://deb.nodesource.com/setup_19.x — Node.js 19 \"Nineteen\" \u001b[1m(deprecated)\u001b[m\n",
            "   * \u001b[1m\u001b[32mhttps://deb.nodesource.com/setup_20.x — Node.js 20 LTS \"Iron\" (recommended)\u001b[m\n",
            "   * \u001b[32mhttps://deb.nodesource.com/setup_21.x — Node.js 21 \"Iron\" (current)\u001b[m\n",
            "   \n",
            "\n",
            "\n",
            "  Please see \u001b[1mhttps://github.com/nodejs/Release\u001b[m for details about which\n",
            "  version may be appropriate for you.\n",
            "\n",
            "  The \u001b[32m\u001b[1mNodeSource\u001b[m Node.js distributions repository contains\n",
            "  information both about supported versions of Node.js and supported Linux\n",
            "  distributions. To learn more about usage, see the repository:\n",
            "   \u001b[4m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "Continuing in 10 seconds ...\n",
            "\n",
            "\u001b[38;5;79m2025-06-16 12:06:33 - Installing pre-requisites\u001b[0m\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,776 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,037 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,986 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,557 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,750 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,250 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,296 kB]\n",
            "Fetched 23.0 MB in 5s (4,236 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.3).\n",
            "gnupg set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  apt-transport-https\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,510 B of archives.\n",
            "After this operation, 170 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 apt-transport-https all 2.4.14 [1,510 B]\n",
            "Fetched 1,510 B in 0s (3,776 B/s)\n",
            "Selecting previously unselected package apt-transport-https.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../apt-transport-https_2.4.14_all.deb ...\n",
            "Unpacking apt-transport-https (2.4.14) ...\n",
            "Setting up apt-transport-https (2.4.14) ...\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:3 https://deb.nodesource.com/node_16.x nodistro InRelease [12.1 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:8 https://deb.nodesource.com/node_16.x nodistro/main amd64 Packages [7,253 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 147 kB in 2s (90.5 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\u001b[1;32m2025-06-16 12:06:52 - Repository configured successfully. To install Node.js, run: apt-get install nodejs -y\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 27.5 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x nodistro/main amd64 nodejs amd64 16.20.2-1nodesource1 [27.5 MB]\n",
            "Fetched 27.5 MB in 1s (32.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 126115 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.2-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.2-1nodesource1) ...\n",
            "Setting up nodejs (16.20.2-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-jgdor2d8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-jgdor2d8\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 582d85ff708947e72b35cfcca05641332b44f5f5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (2.14.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from PySvelte==1.0.0) (2.2.2)\n",
            "Collecting typeguard~=2.0 (from PySvelte==1.0.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets->PySvelte==1.0.0) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->PySvelte==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->PySvelte==1.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->PySvelte==1.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->PySvelte==1.0.0) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->PySvelte==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->PySvelte==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->PySvelte==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->PySvelte==1.0.0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->PySvelte==1.0.0) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->PySvelte==1.0.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->PySvelte==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->PySvelte==1.0.0) (3.0.2)\n",
            "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: PySvelte\n",
            "  Building wheel for PySvelte (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySvelte: filename=PySvelte-1.0.0-py3-none-any.whl size=158316 sha256=e701e90a6cff69c4b4b2133448923ec20c81f7dcc2db0720455a5abf68b6c45c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e0bc_lr4/wheels/40/95/dc/bd1a06dc2ca83b8d30d7b25b683b2e3833dc1f7f1e90a33273\n",
            "Successfully built PySvelte\n",
            "Installing collected packages: typeguard, PySvelte\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PySvelte-1.0.0 typeguard-2.13.3\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.11/dist-packages (0.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  print(\"Running as a Colab notebook\")\n",
        "  %pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
        "  # Install another version of node that makes PySvelte work way faster\n",
        "  !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "  %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "  %pip install fancy_einsum\n",
        "  %pip install einops\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print(\"Running as a Jupyter notebook - intended for development only!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PSb54GoqJqE3"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "from dataclasses import dataclass\n",
        "from easy_transformer import EasyTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
        "import tqdm.auto as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "e350ea361a934380ac41178c2b1a40e0",
            "81f5b33c5b2d451ca5287a8196a560b0",
            "76e78432ed9243a292f1d240f7a9c703",
            "a14ea57bca2846d2b4175d0fcefa942f",
            "e0250213510345439f1cc14fbebe59ab",
            "e3390ff6b7844b24aa8f1a5471be3ffd",
            "27231e1cb0d14ba49941d74c4cd9f83d",
            "d3775ea8db2a4a248b28b103965c9334",
            "b1697750c8154d61954362b2d216e7ca",
            "9fa31950055e491fbf3b9608aad8ebd3",
            "46bf3bf765e849979828f18f6090ebe7",
            "78d5853f3df3417ca3c628dfeb812e49",
            "d16d03a4cf564cfda346f7ec93547805",
            "c05706a97cf240a48cb179f38e72837b",
            "517241dd6a394400b35af1ccbc809a9b",
            "c6e7b280110e420d956ddb71479883bb",
            "9b34c62871f447dd9d940207e05172ce",
            "c15d59735dfe41c48f3140b8b5f2fc53",
            "aefee8a74a9f49479faee58da5f56ba1",
            "cfe978621ee74252ab4cdbef6299afb8",
            "185bbf12618943cbabde24c5efb1d33d",
            "97292055711546728224d1685e54a228",
            "71e85282d8704611b2755d6b5557cd24",
            "9071366ce5df47d7b5e261e811d5a765",
            "6093ffece0e745a9b5d6e5a6ab7d7bce",
            "982d4071738041e78570210f208e5433",
            "84165e13f8c641c4b57b5e679a0a07cf",
            "779c1b4cdfc3487a88213de9c8e0020e",
            "17c4498a4fff4b9eb634e52953de249c",
            "d733d4f1585746f7863298db594c9621",
            "43826b8d8c404adbbbdda96ecc661a1a",
            "7565ee864dcf4405b4fd38cfc45f5561",
            "18ac3aa29ff04bf18290633cacef0943",
            "c4dfbc5d2b72488ea1a7c2f771fa6ae3",
            "a52eb32defb34bc3b5841cbc4c5978cb",
            "6cd51362b79547e28ae344a43e04f71e",
            "e3fdca0d4f4743d4aebedcf705968186",
            "36965bc3e4754d288fcb0845e87c3ce5",
            "96edc89a81384cf69562b705d0b80142",
            "1b953172cb5d4fab8fd7e119042b29de",
            "22842655b2b6441b9d8bb2b3939cb37b",
            "690d3797228d4bedbd70409a1065e08b",
            "2f36f9c4421d4039b62bc4074e9c343b",
            "902efca414644cf18e73f023a3e4266d",
            "331407cd9bb0475590e3938a704e02e4",
            "9b8e5d6cfef945938f3d5b2d45194393",
            "b491f576cc504b3796e35aed1a7624e0",
            "bb2b0ba3aac34ae4b954f61320185ee1",
            "aa53e49920e84e53a8cda4bff64dba45",
            "cc18ddd6414447d5aef1cfffe1e1592a",
            "5c3bdaeca2134f01a6f2445e79dd42fb",
            "24d87cc1346d4afca60285fd2bfaafee",
            "0f73e341b42e417ca66e73fcbe2d0eb8",
            "c2725dbbdf6347fea93a7045d9156f7f",
            "26f1f91dc32f4fbf84405262a80b89a1",
            "673657205482432b9c439a44f4120b1f",
            "b679d30b84914eef84327fc756b262d7",
            "6af0ffe555254c99bc743f27238473be",
            "fa485ba66b3a41a5acdd9431415f3d44",
            "1f1f6be7bbd740da84a8c5a7975edf27",
            "eb46f5dbfd4e4afdb9a95ad44a0ff02a",
            "f7f94e105fa94b008eeff37aa20cbaee",
            "3c1473390d9540e0b662d46f88c4de80",
            "420e0556bd5c4a1ab6a779fa27f0b6ac",
            "cffe27cedc30476b937694b267dda50c",
            "630405df26c942d38f91cf729430ba8a",
            "4452ee3fef694cd9a54e32cbdf6bd975",
            "e98c365a794941cc9709bc4863908fd5",
            "98f4df64bdb443cb8ef1d2595c034aab",
            "023428caccaf4f909dee864e40849786",
            "0021e097667b4a8bb1f1a30be6ef6050",
            "9c017c7859ea4ce592059860c37dc0b4",
            "42735bfcbddb4c1eb7d5f4ea64ee6dc3",
            "e9b75c72de4c451d9287c17092c9193d",
            "1119f18e738c4ff69bc1416d43f73f04",
            "7a645f7fce0e42e7bb1556c966bcdb9c",
            "050257aa8ae8405d8b19bfb8ff5c7e88"
          ]
        },
        "id": "csPoSWeUJqE5",
        "outputId": "3791cf0a-0278-4420-ee3a-6cc126bb1b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e350ea361a934380ac41178c2b1a40e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78d5853f3df3417ca3c628dfeb812e49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71e85282d8704611b2755d6b5557cd24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4dfbc5d2b72488ea1a7c2f771fa6ae3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "331407cd9bb0475590e3938a704e02e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "673657205482432b9c439a44f4120b1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4452ee3fef694cd9a54e32cbdf6bd975"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cpu\n",
            "Finished loading pretrained model gpt2-small into EasyTransformer!\n"
          ]
        }
      ],
      "source": [
        "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noj3I8thJqE7"
      },
      "source": [
        "# Understanding Inputs & Outputs of a Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v41z1o1gJqE9"
      },
      "source": [
        "## What is the point of a transformer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PdzyxW_JqE-"
      },
      "source": [
        "**Transformers exist to model text!**\n",
        "\n",
        "We're going to focus GPT-2 style transformers. Key feature: They generate text! You feed in language, and the model generates a probability distn over tokens. And you can repeatedly sample from this to generate text!\n",
        "\n",
        "### How is the model trained?\n",
        "\n",
        "You give it a bunch of text, and train it to predict the next token.\n",
        "\n",
        "Importantly, if you give a model 100 tokens in a sequence, it predicts the next token for *each* prefix, ie it produces 100 predictions. This is kinda weird but it's much easier to make one that does this. And it also makes training more efficient, because you can 100 bits of feedback rather than just one.\n",
        "\n",
        "#### Objection: Isn't this trivial for the first 99?\n",
        "\n",
        "No! We make the transformer have *causal attention*. The core thing is that it can only move information forwards in the sequence. The prediction of what comes after token 50 is only a function of the first 50 tokens, *not* of token 51. (Jargon: *autoregressive*)\n",
        "\n",
        "### Key takeaway:\n",
        "\n",
        "Transformers are *sequence modelling engines*. It does the same processing in parallel at each sequence position, can move information between positions with attention, and conceptually can take a sequence of arbitrary length (not actually true, see later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x1_8pFqJqFA"
      },
      "source": [
        "## Tokens - Transformer Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNCmi28aJqFA"
      },
      "source": [
        "Core point: Input is language (ie a sequence of characters, strings, etc)\n",
        "\n",
        "### How do we convert language to vectors?\n",
        "\n",
        "ML models take in vectors, not weird shit like language - how do we convert?\n",
        "\n",
        "#### Idea: integers to vectors\n",
        "\n",
        "We basically make a lookup table. Called an embedding.\n",
        "\n",
        "Jargon: **One-hot encoding** We map eg numbers from 1 to 100, to a 100-dim vector, with a 1 in the kth position, 0 everywhere else. Key intuition is that one-hot encodings let you think about each integer independently - useful when integers = labels.\n",
        "\n",
        "Dimensions = things that vary independently. Each input has its own dimension, so each input can be thought of independently, we don't bake in any relation.\n",
        "\n",
        "Lookup tables <=> Multiply a fixed matrix by the one-hot encoded vector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcQT-8yqJqFB"
      },
      "source": [
        "### Tokens: Language to sequence of integers\n",
        "\n",
        "Core idea: We need a model that can deal with arbitrary text. We want to convert this into integers, *and* we want these integers to be in a bounded range.\n",
        "\n",
        "**Idea:** Form a vocabulary!\n",
        "\n",
        "**Idea 1:** Get a dictionary!\n",
        "\n",
        "**Problem:** It can't cope with arbitrary text (eg URLs, punctuation, etc) Can't cope with mispellings.\n",
        "\n",
        "**Idea 2:** Vocab = 256 ASCII characters. Fixed vocab size, can do arbitrary text, etc.\n",
        "\n",
        "**Problem:** Loses structure of language - some sequences of characters are more meaningful than others.\n",
        "\n",
        "Eg \"language\" is a lot more meaningful than \"hjksdfiu\" - we want the first to be a single token, second to not be. It's a more efficient use of our vocab.\n",
        "\n",
        "#### What Actually Happens?\n",
        "\n",
        "This super cursed thing called Byte-Pair Encodings\n",
        "\n",
        "Ġ ~ means begins with a space, tokens with a leading space vs not are different.\n",
        "\n",
        "We begin with the 256 ASCII characters as our tokens, and then find the most common pair of tokens, and merge that into a new token. Eg \" t\" is the most common pair, so it's our next token! Repeat 50000 times..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGt1QBW8JqFC",
        "outputId": "0c1f587a-c691-43d3-e462-135792824bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
            "\n",
            "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
            "\n",
            "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sorted_vocab = sorted(list(reference_gpt2.tokenizer.vocab.items()), key=lambda n:n[1])\n",
        "print(sorted_vocab[:20])\n",
        "print()\n",
        "print(sorted_vocab[250:270])\n",
        "print()\n",
        "print(sorted_vocab[990:1010])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCyA2RLUJqFD"
      },
      "source": [
        "Gets to weird esoteric shit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8dqAEFiJqFD",
        "outputId": "e7452e94-e598-4c1b-bb2e-046ec1dcd4db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Revolution', 50237),\n",
              " ('Ġsnipers', 50238),\n",
              " ('Ġreverted', 50239),\n",
              " ('Ġconglomerate', 50240),\n",
              " ('Terry', 50241),\n",
              " ('794', 50242),\n",
              " ('Ġharsher', 50243),\n",
              " ('Ġdesolate', 50244),\n",
              " ('ĠHitman', 50245),\n",
              " ('Commission', 50246),\n",
              " ('Ġ(/', 50247),\n",
              " ('âĢ¦.\"', 50248),\n",
              " ('Compar', 50249),\n",
              " ('Ġamplification', 50250),\n",
              " ('ominated', 50251),\n",
              " ('Ġregress', 50252),\n",
              " ('ĠCollider', 50253),\n",
              " ('Ġinformants', 50254),\n",
              " ('Ġgazed', 50255),\n",
              " ('<|endoftext|>', 50256)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sorted_vocab[-20:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qps-lcFAJqFD"
      },
      "source": [
        "Use the `to_tokens` method to convert text to numbers\n",
        "\n",
        "Prepends with a special token to give attention a resting position, disable with `prepend_bos=False`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6rwSS5eJqFE",
        "outputId": "c98825e8-72fd-4b02-d677-f220471cf517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256, 15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,\n",
            "          6067,     0]])\n",
            "tensor([[15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,  6067,\n",
            "             0]])\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\"))\n",
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\", prepend_bos=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajKxQEc6JqFE"
      },
      "source": [
        "### Rant: Tokenization is a Headache\n",
        "\n",
        "Whether a word begins with a capital or space matters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv54jv7cJqFE",
        "outputId": "7228372c-717b-44f1-96de-648674f42947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', 'R', 'alph']\n",
            "['<|endoftext|>', ' Ralph']\n",
            "['<|endoftext|>', ' r', 'alph']\n",
            "['<|endoftext|>', 'ral', 'ph']\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_str_tokens(\"Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\"ralph\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAiV60WpJqFF"
      },
      "source": [
        "Arithmetic is a total mess: Length is inconsistent, common numbers bundle together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpSbsZSXJqFF",
        "outputId": "51f2a65e-edca-4887-e9d7-23143384993b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<|endoftext|>',\n",
              " '568',\n",
              " '73',\n",
              " '+',\n",
              " '318',\n",
              " '46',\n",
              " '23',\n",
              " '=',\n",
              " '123',\n",
              " '45',\n",
              " '67',\n",
              " '89',\n",
              " '-',\n",
              " '1',\n",
              " '000000',\n",
              " '000']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "reference_gpt2.to_str_tokens(\"56873+3184623=123456789-1000000000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc-5fvBCJqFF"
      },
      "source": [
        "### Key Takeaway:\n",
        "\n",
        "* We learn a dictionary of vocab of tokens (sub-words).\n",
        "\n",
        "* We (approx) losslessly convert language to integers via tokenizing it.\n",
        "\n",
        "* We convert integers to vectors via a lookup table.\n",
        "\n",
        "* Note: input to the transformer is a sequence of *tokens* (ie integers), not vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRfELnJrJqFG"
      },
      "source": [
        "## Logits - Transformer Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5rwvvM6JqFG"
      },
      "source": [
        "**Goal:** Probability distribution over next tokens. (for every *prefix* of the sequence - given n tokens, we make n next token predictions)\n",
        "\n",
        "**Problem:** How to convert a vector to a probability distribution?\n",
        "\n",
        "**Answer:** Use a softmax ($x_i \\to \\frac{e^{x_i}}{\\sum e^{x_j}}$), exponential makes everything positive, normalization makes it add to one.\n",
        "\n",
        "So the model outputs a tensor of logits, one vector of size $d_{vocab}$ for each input token.\n",
        "\n",
        "We can use this to generate things!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idhuwvQdJqFG"
      },
      "source": [
        "## Generation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MinDfaRsJqFH"
      },
      "source": [
        "**Step 1:** Convert text to tokens\n",
        "\n",
        "Shape = batch x position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20G1EUN3JqFH",
        "outputId": "a5352000-592a-4805-9275-61b5f660876c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0]])\n",
            "torch.Size([1, 35])\n",
            "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
          ]
        }
      ],
      "source": [
        "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
        "tokens = reference_gpt2.to_tokens(reference_text)\n",
        "print(tokens)\n",
        "print(tokens.shape)\n",
        "print(reference_gpt2.to_str_tokens(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwsLYcTMJqFI"
      },
      "source": [
        "**Step 2:** Map tokens to logits\n",
        "\n",
        "(run_with_cache means cache all intermediate activations, not important right now)\n",
        "\n",
        "shape = batch x position x d_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAegxhztJqFJ",
        "outputId": "e7cdf558-3604-49cf-b91f-2d6a2ac53583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "# tokens = tokens.cuda()\n",
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujuBQgukJqFK"
      },
      "source": [
        "**Step 3:** Convert the logits to a distribution with a softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqmwsg9VJqFK",
        "outputId": "0fce066e-7506-45fe-a835-5fc30f856923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n",
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "log_probs = logits.log_softmax(dim=-1)\n",
        "probs = logits.log_softmax(dim=-1)\n",
        "print(log_probs.shape)\n",
        "print(probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT7DlPh4JqFK"
      },
      "source": [
        "**Bonus step:** What is the most likely next token at each position?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HfrSM_gJqFL",
        "outputId": "08699a82-32a1-42e4-ce19-0159b9c2ccf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<|endoftext|>', '\\n'),\n",
              " ('I', \"'m\"),\n",
              " (' am', ' a'),\n",
              " (' an', ' avid'),\n",
              " (' amazing', ' person'),\n",
              " (' aut', 'od'),\n",
              " ('ore', 'sp'),\n",
              " ('gressive', '.'),\n",
              " (',', ' and'),\n",
              " (' dec', 'ently'),\n",
              " ('oder', ','),\n",
              " ('-', 'driven'),\n",
              " ('only', ' programmer'),\n",
              " (',', ' and'),\n",
              " (' G', 'IM'),\n",
              " ('PT', '-'),\n",
              " ('-', 'only'),\n",
              " ('2', '.'),\n",
              " (' style', ','),\n",
              " (' transformer', '.'),\n",
              " ('.', ' I'),\n",
              " (' One', ' of'),\n",
              " (' day', ' I'),\n",
              " (' I', ' will'),\n",
              " (' will', ' be'),\n",
              " (' exceed', ' my'),\n",
              " (' human', 'ly'),\n",
              " (' level', ' of'),\n",
              " (' intelligence', ' and'),\n",
              " (' and', ' I'),\n",
              " (' take', ' over'),\n",
              " (' over', ' the'),\n",
              " (' the', ' world'),\n",
              " (' world', '.'),\n",
              " ('!', ' I')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "list(zip(reference_gpt2.to_str_tokens(reference_text), reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxuAW2xyJqFL"
      },
      "source": [
        "**Step 4:** Map distribution to a token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAygpW8aJqFM",
        "outputId": "e18c2447-7615-4aec-865f-80993e6d4f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(314)\n"
          ]
        }
      ],
      "source": [
        "next_token = logits[0, -1].argmax(dim=-1)\n",
        "print(next_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EekLGJlmJqFM"
      },
      "source": [
        "**Step 5:** Add this to the end of the input, re-run\n",
        "\n",
        "(More efficient ways to do this, but whatever, doesn't matter conceptually)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "-MRyXhhUJqFN",
        "outputId": "3a43a066-77dc-4c2f-dd98-d65aeb0ad3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-411787402>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_tokens = torch.cat([tokens, torch.tensor(next_token, device='cuda', dtype=torch.int64)[None, None]], dim=-1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-411787402>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"New Input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"New Input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_gpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "next_tokens = torch.cat([tokens, torch.tensor(next_token, device='cuda', dtype=torch.int64)[None, None]], dim=-1)\n",
        "new_logits = reference_gpt2(next_tokens)\n",
        "print(\"New Input:\", next_tokens)\n",
        "print(next_tokens.shape)\n",
        "print(\"New Input:\", reference_gpt2.tokenizer.decode(next_tokens[0]))\n",
        "\n",
        "print(new_logits.shape)\n",
        "print(new_logits[-1, -1].argmax(-1))\n",
        "\n",
        "print(reference_gpt2.tokenizer.decode(new_logits[-1, -1].argmax(-1)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q04_DMGuJqFN"
      },
      "source": [
        "## Key takeaways:\n",
        "\n",
        "* Takes in language, predicts next token (for *each* token in a causal way)\n",
        "* We convert language to a sequence of integers with a tokenizer.\n",
        "* We convert integers to vectors with a lookup table.\n",
        "\n",
        "* Output is a vector of logits (one for each input token), we convert to a probability distn with a softmax, and can then convert this to a token (eg taking the largest logit, or sampling).\n",
        "\n",
        "* We append this to the input + run again to generate more text (Jargon: *autoregressive*)\n",
        "\n",
        "* Meta level point: Transformers are sequence operation models, they take in a sequence, do processing in parallel at each position, and use attention to move information between positions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbZVdngHJqFO"
      },
      "source": [
        "# Clean Transformer Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smqh_GrDJqFY"
      },
      "source": [
        "![](https://github.com/neelnanda-io/Easy-Transformer/blob/clean-transformer-demo/transformer_overview.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCYW2lXRJqFY"
      },
      "source": [
        "High-Level architecture:\n",
        "\n",
        "Go watch my [Transformer Circuits walkthrough](https://www.youtube.com/watch?v=KV5gbOmHbjU) if you want more intuitions!\n",
        "\n",
        "(Diagram is bottom to top)\n",
        "\n",
        "* Input tokens, integers\n",
        "* Embedding is a lookup table mapping tokens to vectors\n",
        "    * Lives in the *residual stream*\n",
        "* Residual stream - the sum of all previous outputs of layers of the model, is the input to each new layer.\n",
        "    * *Really* fundamental. It's the central object of the transformer.\n",
        "        * It's how model remembers things, moves information between layers for composition, and it's the medium used to store the information that attention moves between positions.\n",
        "* Then we have a series of $n_{layers}$ transformer blocks\n",
        "    * Confusing jargon - a block contains an attention layer *and* an MLP layer, but we say a transformer has k layers if it has k blocks (ie 2k total layers).\n",
        "* First we have attention. This moves information from prior positions in the sequence to the current token.\n",
        "    * We do this for *every* token in parallel using the same parameters. The only difference is that we look backwards only, so later tokens get more room to look back.\n",
        "        * We look backwards so we can predict the next token without cheating.\n",
        "    * Only bit of a transformer that moves information between positions.\n",
        "    * Made up of $n_heads$ heads - each with their own parameters, own attention pattern, and own information how to copy things from source to destination.\n",
        "        * The heads act independently and additively, we just add their outputs together, and back to the stream\n",
        "    * Each head:\n",
        "        * Produces an attention pattern for each destination token, a probability distribution of prior source tokens (including the current one) weighting how much information to copy.\n",
        "            * Do this for each pair of tokens\n",
        "            * Copy information in the same way from each source token.\n",
        "                * What information we copy *does* depend on the source token's *residual stream*. This does not necessarily mean the info of what text token is at the source token's position\n",
        "                * Copy = apply a linear map.\n",
        "        * Fundamental point: Figuring out *which* source tokens to copy info from is a separate circuit from figuring out *how* to copy that information.\n",
        "        * Internal head dimension of $d_{head} = \\frac{d_{model}}{n_{heads}}\n",
        "* MLP Layers - standard neural network. Single hidden layer, linear map -> GELU activation -> linear map\n",
        "    * Exact activation not conceptually important.\n",
        "    * Middle dimension normally $d_{mlp} = 4 \\times d_{model}$\n",
        "        * Exactly why the ratios are what they are isn't super important - doesn't matter that much, people basically cargo-cult GPT did.\n",
        "    * Intuition - once attention has moved relevant information to a single position in the residual stream, MLPs can actually do computation, reasoning, lookup information, etc.\n",
        "        * Big open problem in transformer mechanistic interpretability is what is going on inside MLPs?! See [Toy Model of Superposition Paper](https://transformer-circuits.pub/2022/toy_model/index.html) for more on why this is hard.\n",
        "        * Underlying intuition - linear map -> non-linearity -> linear map is the most powerful force in the universe and can approximate arbitrary functions. Idk man it just works\n",
        "* Finally, we unembed!\n",
        "    * Apply a linear map, going from final residual stream to a vector of logits - this is the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_SetL0fJqFa"
      },
      "source": [
        "### Bonus things - less conceptually important but key technical details\n",
        "* LayerNorm\n",
        "    * Simple normalization function applied at the start of each layer - MLP, Attn and Unembed\n",
        "    * Converts each input vector (independently in parallel for each batch x position residual stream vector) to have mean zero and variance 1.\n",
        "    * Then applies an elementwise scaling and translation\n",
        "    * Cool maths tangent: The scale & translate is just a linear map. LayerNorm is only applied immediately before another linear map. Linear compose linear = linear, so we can just fold this into a single effective linear layer and ignore it.\n",
        "        * `fold_ln=True` flag in `from_pretrained` does this for you.\n",
        "    * LayerNorm is super fucking annoying, because the scale part is not linear, so you can't think about different bits of the input independently. But it's *almost* linear - if you're changing a small part of the input it's linear, but if you're changing enough to alter the norm substantially it's not linear :(\n",
        "* Positional Information\n",
        "    * This is totally fucked and messy, sorry!\n",
        "    * **Problem:** Attention operates over all pairs of positions. This means it's symmetric with regards to position - the attention calculation from token 5 to token 1 and token 5 to token 2 are the same by default\n",
        "        * This is dumb because nearby tokens are more relevant.\n",
        "    * There's a lot of dumb hacks for this.\n",
        "    * We'll focus on **learned, absolute positional embeddings**. This means we learn a lookup table mapping the index of the position of each token to a residual stream vector, and add this to the embed.\n",
        "        * Note that we *add* rather than concatenate. This is because the residual stream is shared memory, and likely under significant superposition (the model compresses more features in there than the model has dimensions)\n",
        "        * We basically never concatenate inside a transformer, unless doing weird shit like generating text efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fO734HAJqFb"
      },
      "source": [
        "# Actual Code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhawfh2UJqFb"
      },
      "source": [
        "## Print All Activation Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIAzRfBiJqFc"
      },
      "source": [
        "Key:\n",
        "```\n",
        "batch = 1\n",
        "position = 35\n",
        "d_model = 768\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "d_mlp = 3072 (4 * d_model)\n",
        "d_head = 64 (d_model / n_heads)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m3yLICqJqFc",
        "outputId": "b9ffbcc2-38ef-4bf8-b659-31ee99023f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hook_embed torch.Size([1, 35, 768])\n",
            "hook_pos_embed torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 35, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_attn torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_z torch.Size([1, 35, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 35, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 35, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 35, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 35, 768])\n",
            "ln_final.hook_scale torch.Size([1, 35, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 35, 768])\n"
          ]
        }
      ],
      "source": [
        "for activation_name, activation in cache.cache_dict.items():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "        print(activation_name, activation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-_xPMbVJqFc"
      },
      "source": [
        "## Print All Parameters Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j-6lRVWJqFd",
        "outputId": "a71a6db4-df25-43df-866b-01cd8dc003b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.W_E torch.Size([50257, 768])\n",
            "pos_embed.W_pos torch.Size([1024, 768])\n",
            "blocks.0.ln1.w torch.Size([768])\n",
            "blocks.0.ln1.b torch.Size([768])\n",
            "blocks.0.ln2.w torch.Size([768])\n",
            "blocks.0.ln2.b torch.Size([768])\n",
            "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
            "blocks.0.attn.b_Q torch.Size([12, 64])\n",
            "blocks.0.attn.b_K torch.Size([12, 64])\n",
            "blocks.0.attn.b_V torch.Size([12, 64])\n",
            "blocks.0.attn.b_O torch.Size([768])\n",
            "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
            "blocks.0.mlp.b_in torch.Size([3072])\n",
            "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
            "blocks.0.mlp.b_out torch.Size([768])\n",
            "ln_final.w torch.Size([768])\n",
            "ln_final.b torch.Size([768])\n",
            "unembed.W_U torch.Size([768, 50257])\n",
            "unembed.b_U torch.Size([50257])\n"
          ]
        }
      ],
      "source": [
        "for name, param in reference_gpt2.named_parameters():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in name or \"blocks\" not in name:\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv9fuqH3JqFd"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfPqJoywJqFd",
        "outputId": "1c3b4904-3a4b-4f67-8b6f-e18cfbf7e092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EasyTransformerConfig(n_layers=12, d_model=768, n_ctx=1024, d_head=64, model_name='gpt2-small', n_heads=12, d_mlp=3072, act_fn='gelu_new', d_vocab=50257, eps=1e-05, use_attn_result=False, use_attn_scale=True, use_local_attn=False, model_family='gpt2', checkpoint=None, tokenizer_name='gpt2', window_size=None, attn_types=None, init_mode='gpt2', normalization_type='LN', device='cpu', attention_dir='causal', attn_only=False, seed=42, initializer_range=np.float64(0.02886751345948129), init_weights=False, scale_attn_by_inverse_layer_idx=False, positional_embedding_type='standard', final_rms=False, d_vocab_out=50257, parallel_attn_mlp=False, rotary_dim=64, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# As a reference - note there's a lot of stuff we don't care about in here, to do with library internals or other architectures\n",
        "print(reference_gpt2.cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuxyLLpqJqFe"
      },
      "source": [
        "We define a stripped down config for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyLw-FBZJqFe",
        "outputId": "7568c706-4cb5-40e4-922c-145e09f23204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024\n",
        "    d_head: int = 64\n",
        "    d_mlp: int = 3072\n",
        "    n_heads: int = 12\n",
        "    n_layers: int = 12\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKP6xpGeJqFf"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urmdiec9JqFg"
      },
      "source": [
        "Tests are great, write lightweight ones to use as you go!\n",
        "\n",
        "**Naive test:** Generate random inputs of the right shape, input to your model, check whether there's an error and print the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nqikkbT1JqFg"
      },
      "outputs": [],
      "source": [
        "def rand_float_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)#.cuda()\n",
        "    random_input = torch.randn(shape)#.cuda()\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    print()\n",
        "    return output\n",
        "\n",
        "def rand_int_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)#.cuda()\n",
        "    random_input = torch.randint(100, 1000, shape)#.cuda()\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    return output\n",
        "\n",
        "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)#.cuda()\n",
        "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
        "    # Allow inputs of strings or tensors\n",
        "    if isinstance(input_name, str):\n",
        "        reference_input = cache_dict[input_name]\n",
        "    else:\n",
        "        reference_input = input_name\n",
        "    print(\"Input shape:\", reference_input.shape)\n",
        "\n",
        "    output = layer(reference_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    reference_output = gpt2_layer(reference_input)\n",
        "    print(\"Reference output shape:\", reference_output.shape)\n",
        "\n",
        "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
        "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpPo1JtiJqFh"
      },
      "source": [
        "## LayerNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zugiugLWJqFh"
      },
      "source": [
        "Make mean 0\n",
        "Normalize to have variance 1\n",
        "Scale with learned weights\n",
        "Translate with learned bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "i2tuLxnsJqFi"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "\n",
        "    self.cfg = cfg\n",
        "    self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
        "    self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
        "    self.normalized = None\n",
        "    self.mean_zeroed = None\n",
        "    self.std = None\n",
        "\n",
        "  def forward(self, residual):\n",
        "\n",
        "    res_mean = torch.mean(residual, dim = -1).unsqueeze(-1)\n",
        "    res_std = torch.sqrt(torch.mean((residual - res_mean).pow(2), dim = -1).unsqueeze(-1)) + cfg.layer_norm_eps\n",
        "    residual_ln = (residual - res_mean)/res_std\n",
        "    residual_ln_lin = torch.einsum('bnd,d->bnd', residual_ln, self.w) + self.b\n",
        "    self.normalized = residual_ln\n",
        "    self.mean_zeroed = residual - res_mean\n",
        "    self.std = res_std\n",
        "    return residual_ln_lin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L0_O-I9JqFj",
        "outputId": "625d4113-767e-48bd-b924-2bc695c1320e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        }
      ],
      "source": [
        "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
        "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLkVXvQpJqFj"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISEXL3XYJqFj"
      },
      "source": [
        "Basically a lookup table from tokens to residual stream vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7414IWovJqFk",
        "outputId": "b7de81e4-88c0-4a62-c7d5-c6b81adb76d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "Input shape: torch.Size([1, 35])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
              "         [ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
              "         [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
              "         ...,\n",
              "         [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
              "         [-0.1488,  0.1519,  0.0056,  ..., -0.3107,  0.2073,  0.0377],\n",
              "         [-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453]]],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        # \"YOUR CODE HERE\"\n",
        "\n",
        "        embedding = self.W_E[tokens, :]\n",
        "\n",
        "        return embedding\n",
        "rand_int_test(Embed, [2, 4])\n",
        "load_gpt2_test(Embed, reference_gpt2.embed, tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3jXfMoVbLNV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-YufpZGJqFk"
      },
      "source": [
        "## Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8iSyWTYnKvlS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hTJdvnQJqFk",
        "outputId": "f76a961c-fc13-4058-b9e3-96db6f110cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "Input shape: torch.Size([1, 35])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
              "           2.8267e-02,  5.4490e-02],\n",
              "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
              "           1.0172e-02, -1.5573e-04],\n",
              "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
              "           1.9325e-02, -2.1424e-02],\n",
              "         ...,\n",
              "         [ 4.6277e-04,  2.3037e-02,  4.1227e-02,  ..., -1.9287e-03,\n",
              "          -2.3037e-03, -4.3189e-03],\n",
              "         [-2.7136e-03,  2.1724e-02,  3.9675e-02,  ...,  4.2048e-04,\n",
              "          -4.8160e-03, -9.2252e-04],\n",
              "         [ 6.6815e-03,  2.0595e-02,  3.6596e-02,  ..., -9.5090e-04,\n",
              "          -3.2512e-03, -9.6509e-04]]], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # \"YOUR CODE HERE\"\n",
        "\n",
        "        pos_emb_inp = torch.arange(tokens.shape[-1]).unsqueeze(0).expand(tokens.shape[0],-1)\n",
        "\n",
        "        embedding = self.W_pos[pos_emb_inp,:]\n",
        "\n",
        "        return embedding\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLSVNBUFJqFl"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLMT58uLJqFl"
      },
      "source": [
        "* **Step 1:** Produce an attention pattern - for each destination token, probability distribution over previous tokens (incl current token)\n",
        "    * Linear map from input -> query, key shape [batch, position, head_index, d_head]\n",
        "    * Dot product every *pair* of queries and keys to get attn_scores [batch, head_index, query_pos, key_pos] (query = dest, key = source)\n",
        "    * Scale and mask attn_scores to make it lower triangular, ie causal\n",
        "    * softmax row-wise, to get a probability distribution along each the key_pos dimension - this is our attention pattern!\n",
        "* **Step 2:** Move information from source tokens to destination token using attention pattern (move = apply linear map)\n",
        "    * Linear map from input -> value [batch, key_pos, head_index, d_head]\n",
        "    * Mix along the key_pos with attn pattern to get z, a mixed value [batch, query_pos, head_index, d_head]\n",
        "    * Map to output, [batch, position, d_model] (position = query_pos, we've summed over all heads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "330QTc2gJqFl"
      },
      "source": [
        "First, it's useful to visualize and play around with attention patterns - what exactly are we looking at here? (Click on a head to lock onto just showing that head's pattern, it'll make it easier to interpret)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysvelte"
      ],
      "metadata": {
        "id": "MBB5B4XJsIBX",
        "outputId": "402561ef-1831-409e-9aca-a3776aee900c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pysvelte in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from pysvelte) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.14.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from pysvelte) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pysvelte) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.2.2)\n",
            "Requirement already satisfied: typeguard~=2.0 in /usr/local/lib/python3.11/dist-packages (from pysvelte) (2.13.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets->pysvelte) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->pysvelte) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pysvelte) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pysvelte) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pysvelte) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pysvelte) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pysvelte) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->pysvelte) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->pysvelte) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->pysvelte) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->pysvelte) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets->pysvelte) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pysvelte) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->pysvelte) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->pysvelte) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->pysvelte) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets->pysvelte) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pysvelte) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDWAHc2EJqFl",
        "outputId": "b50c5025-e17a-47cc-dcba-98298ec2c353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pysvelte components appear to be unbuilt or stale\n",
            "Running npm install...\n"
          ]
        }
      ],
      "source": [
        "import pysvelte\n",
        "pysvelte.AttentionMulti(tokens=reference_gpt2.to_str_tokens(reference_text), attention=cache['blocks.0.attn.hook_attn'][0].permute(1, 2, 0)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNNtDQ0zJqFm"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32, device=\"cuda\"))\n",
        "\n",
        "    def forward(self, normalized_resid_pre):\n",
        "        # normalized_resid_pre: [batch, position, d_model]\n",
        "        # \"YOUR CODE HERE\"\n",
        "\n",
        "        Q = torch.einsum('bnd,hdg->bhng',normalized_resid_pre, self.W_Q) + self.b_Q.unsqueeze(-2).expand(-1,normalized_resid_pre.size(1),-1)\n",
        "        K = torch.einsum('bnd,hdg->bhng',normalized_resid_pre, self.W_K) + self.b_K.unsqueeze(-2).expand(-1,normalized_resid_pre.size(1),-1)\n",
        "        V = torch.einsum('bnd,hdg->bhng',normalized_resid_pre, self.W_V) + self.b_V.unsqueeze(-2).expand(-1,normalized_resid_pre.size(1),-1)\n",
        "\n",
        "        attention = torch.softmax((Q @ torch.flip(K, dims=[-2,-1]))/torch.sqrt(self.cfg.d_head), dim = -1)\n",
        "        attention_mask = self.apply_causal_mask(attention)\n",
        "\n",
        "        Z = attention_mask @ V\n",
        "        out = torch.einsum('bhng,hgd->bhnd',Z,self.W_O) + self.b_O.unsqueeze(0).expand(Z.size(0),-1)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def apply_causal_mask(self, attn_scores):\n",
        "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
        "        # \"YOUR CODE HERE\"\n",
        "        attn_scores[:,:,torch.triu(torch.ones(attn_scores.size(-1), attn_scores.size(-1)), diagonal=1).bool(),\n",
        "                    torch.triu(torch.ones(attn_scores.size(-1), attn_scores.size(-1)), diagonal=1).bool()] = -torch.inf\n",
        "        return attn_scores\n",
        "\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.ln1.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpmZq-icJqFn"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8VX0ysQJqFn",
        "outputId": "a1858d02-1b42-4281-8f53-7632cb297ccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.4380,  0.3624,  0.5117,  ...,  1.7227,  1.5761,  0.0368],\n",
              "         [-1.0766, -0.0438,  0.3276,  ..., -0.5437,  0.4033,  0.3717],\n",
              "         [-1.2182, -1.5481, -0.9702,  ...,  1.0737,  0.7199,  0.5080],\n",
              "         ...,\n",
              "         [-0.4004,  0.8475,  0.2047,  ...,  0.3789,  0.0455, -0.4744],\n",
              "         [-0.0862,  0.7839,  0.9046,  ..., -0.2175, -0.5953,  0.8555],\n",
              "         [ 0.8448, -0.3743,  1.0397,  ...,  0.0296,  0.3405,  0.3585]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "    def forward(self, normalized_resid_mid):\n",
        "        # normalized_resid_mid: [batch, position, d_model]\n",
        "        \"YOUR CODE HERE\"\n",
        "\n",
        "rand_float_test(MLP, [2, 4, 768])\n",
        "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"blocks.0.ln2.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08MRTFElJqFo"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydyWNRoDJqFp",
        "outputId": "f3e5360e-a4e5-4cac-dd64-a757384265b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.3911,  0.1543,  0.6005,  ...,  1.7198,  1.7365,  0.3930],\n",
              "         [-0.9039, -0.0360,  0.2351,  ..., -0.4148,  0.3562,  0.3936],\n",
              "         [-0.9647, -2.4819, -1.4995,  ...,  1.4046,  0.7616,  0.5918],\n",
              "         ...,\n",
              "         [-0.7421,  0.9251, -0.3218,  ...,  0.2921,  0.1097, -0.5344],\n",
              "         [-1.3221,  0.8960,  1.1795,  ..., -0.5544, -0.4071,  0.9255],\n",
              "         [ 1.1209, -0.8919,  1.3737,  ..., -0.1356,  0.3434,  0.4517]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(self, resid_pre):\n",
        "        # resid_pre [batch, position, d_model]\n",
        "        \"YOUR CODE HERE\"\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpyyDjwgJqFq"
      },
      "source": [
        "## Unembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j6s8EZmJqFr",
        "outputId": "f03240d1-27bd-4658-e2db-1affa3332247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_final: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ -43.4317,  -39.8364,  -43.0660,  ...,  -54.0878,  -54.3452,\n",
              "           -42.3645],\n",
              "         [-128.0392, -127.9936, -130.7010,  ..., -136.7121, -129.9261,\n",
              "          -129.3965],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6027,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9815, -112.7749, -117.0633,  ..., -121.2914, -117.6574,\n",
              "          -114.5005],\n",
              "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
              "          -106.3604],\n",
              "         [-126.8285, -128.9596, -128.3941,  ..., -140.1970, -138.5883,\n",
              "          -122.3697]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(self, normalized_resid_final):\n",
        "        # normalized_resid_final [batch, position, d_model]\n",
        "        \"YOUR CODE HERE\"\n",
        "\n",
        "rand_float_test(Unembed, [2, 4, 768])\n",
        "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX6LMwleJqFr"
      },
      "source": [
        "## Full Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqOqZg1tJqFs",
        "outputId": "36491dec-e776-4907-852f-a7f64b9c2dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "Embeddings: torch.Size([2, 4, 768])\n",
            "Tokens: torch.Size([2, 4])\n",
            "pos_embed: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Tokens: torch.Size([1, 35])\n",
            "Embeddings: torch.Size([1, 35, 768])\n",
            "Tokens: torch.Size([1, 35])\n",
            "pos_embed: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_final: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ -43.4317,  -39.8364,  -43.0660,  ...,  -54.0878,  -54.3452,\n",
              "           -42.3645],\n",
              "         [-128.0392, -127.9936, -130.7010,  ..., -136.7121, -129.9261,\n",
              "          -129.3965],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6027,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9815, -112.7749, -117.0633,  ..., -121.2914, -117.6574,\n",
              "          -114.5005],\n",
              "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
              "          -106.3604],\n",
              "         [-126.8285, -128.9596, -128.3941,  ..., -140.1970, -138.5883,\n",
              "          -122.3697]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens [batch, position]\n",
        "        \"YOUR CODE HERE\"\n",
        "\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfFZdx7mJqFv"
      },
      "source": [
        "# Try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Bn4TB15JqFw",
        "outputId": "a3cc483b-3151-412d-c711-d20c4ef92ab3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_gpt2 = DemoTransformer(Config(debug=False))\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "demo_gpt2.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4cn2bDuJqFw"
      },
      "source": [
        "Take a test string - the intro paragraph of today's featured Wikipedia article. Let's calculate the loss!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLKxKW63JqFx"
      },
      "outputs": [],
      "source": [
        "test_string = \"\"\"Mini scule is a species of microhylid frog endemic to Madagascar that was described in 2019. The scientific name of the species refers to its size, being a pun on the word minuscule. It is very small, measuring only 8.4 to 10.8 mm (0.33 to 0.43 in) in snout–vent length. It has bronze underparts with a brown groin and back of the thigh, cream upperparts with brown flecking, a dark brown side of the head, and a red iris. On the hind feet, the first toe is absent and the second and fifth toes are strongly reduced. The frog is known only from the Sainte Luce Reserve, where it inhabits areas with deep leaf litter near semi-permanent water bodies. Specimens of frogs from Mandena, the Vohimena mountains, the southern Anosy Mountains, and Tsitongambarika may also be of this species. Along with Mini mum and Mini ature, the other two species in its genus, it received media attention when first described due to the wordplay in its scientific name. (Full article...)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-UsXJcAJqFy"
      },
      "outputs": [],
      "source": [
        "test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "demo_logits = demo_gpt2(test_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFxklJtYJqFy",
        "outputId": "a27bc4c2-ec24-475a-9636-d34f99dc9f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.7186, device='cuda:0', grad_fn=<NegBackward0>)\n",
            "Loss as average prob tensor(0.0243, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss as 'uniform over this many variables' tensor(41.2079, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Uniform loss over the vocab 10.82490511970208\n"
          ]
        }
      ],
      "source": [
        "def lm_cross_entropy_loss(logits, tokens):\n",
        "    # Measure next token loss\n",
        "    # Logits have shape [batch, position, d_vocab]\n",
        "    # Tokens have shape [batch, position]\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    pred_log_probs = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
        "    return -pred_log_probs.mean()\n",
        "loss = lm_cross_entropy_loss(demo_logits, test_tokens)\n",
        "print(loss)\n",
        "print(\"Loss as average prob\", (-loss).exp())\n",
        "print(\"Loss as 'uniform over this many variables'\", (loss).exp())\n",
        "print(\"Uniform loss over the vocab\", math.log(demo_gpt2.cfg.d_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlNVZlLvJqF0"
      },
      "source": [
        "We can also greedily generate text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "37ac70024b344ea787bd2f70c4f9b69d"
          ]
        },
        "id": "iXcKzojLJqF0",
        "outputId": "2df40fd0-7d6f-4eb5-caba-da2904518030"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ac70024b344ea787bd2f70c4f9b69d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the impeachment of President Trump on Tuesday.\n",
            "\n",
            "\n",
            "The Senate is expected to begin the trial on Monday.\n",
            "\n",
            "\n",
            "The House of Representatives is expected to vote on the\n"
          ]
        }
      ],
      "source": [
        "test_string = \"Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on\"\n",
        "for i in tqdm.tqdm(range(100)):\n",
        "    test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "    demo_logits = demo_gpt2(test_tokens)\n",
        "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
        "print(test_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqFtczDOJqF1"
      },
      "source": [
        "# Training a Model!\n",
        "\n",
        "This is a lightweight demonstration of how you can actually train your own GPT-2 with this code! Here we train a tiny model on a tiny dataset, but it's fundamentally the same code for training a larger/more real model (though you'll need beefier GPUs and data parallelism to do it remotely efficiently, and fancier parallelism for much bigger ones).\n",
        "\n",
        "For our purposes, we'll train 2L 4 heads per layer model, with context length 256, for 1000 steps of batch size 8, just to show what it looks like (and so the notebook doesn't melt your colab lol)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZbkSkjIJqF2"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    %pip install datasets\n",
        "    %pip install transformers\n",
        "import datasets\n",
        "import transformers\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJrSqpakJqF2"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PchoWXOSJqF-"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "num_epochs = 1\n",
        "max_steps = 1000\n",
        "log_every = 10\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-2\n",
        "model_cfg = Config(debug=False, d_model=256, n_heads=4, d_head=64, d_mlp=1024, n_layers=2, n_ctx=256, d_vocab=reference_gpt2.cfg.d_vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP-qQ-3qJqF_"
      },
      "source": [
        "\n",
        "## Create Data\n",
        "\n",
        "We load in a tiny dataset I made, with the first 10K entries in the Pile (inspired by Stas' version for OpenWebText!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2cdrmDNJqF_",
        "outputId": "cb21ee7b-2c1c-46f8-f5bf-d56e20d0051c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "Using custom data configuration NeelNanda--pile-10k-30e9c14cdcda6c5c\n",
            "Reusing dataset parquet (/workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'meta'],\n",
            "    num_rows: 10000\n",
            "})\n",
            "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playi\n",
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-5a7efe79fba39fa4.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-5d90b6c801666252.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-63f545415985c072.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /workspace/cache/NeelNanda___parquet/NeelNanda--pile-10k-30e9c14cdcda6c5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e1d3c0b4a6cf8c82.arrow\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\")\n",
        "print(dataset)\n",
        "print(dataset[0]['text'][:100])\n",
        "tokens_dataset = tokenize_and_concatenate(dataset, reference_gpt2.tokenizer, streaming=False, max_length=model_cfg.n_ctx, column_name=\"text\", add_bos_token=True, num_proc=4)\n",
        "data_loader = torch.utils.data.DataLoader(tokens_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1beTsU9MJqGA"
      },
      "source": [
        "## Create Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvbsRjccJqGA",
        "outputId": "0cf07698-cedc-4036-bd90-c55f32cbaafa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = DemoTransformer(model_cfg)\n",
        "model.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO6X31gDJqGA"
      },
      "source": [
        "## Create Optimizer\n",
        "We use AdamW - it's a pretty standard optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0iw1afuJqGB"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dumeWlzZJqGB"
      },
      "source": [
        "## Run Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9bd43306e46843b1abcafea463782a12"
          ]
        },
        "id": "uq6cWezcJqGB",
        "outputId": "734d1d6f-1aa4-4b98-eef4-83af0f75e408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches: 8506\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bd43306e46843b1abcafea463782a12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 0, Loss: 10.8938\n",
            "Step: 10, Loss: 8.6160\n",
            "Step: 20, Loss: 7.4170\n",
            "Step: 30, Loss: 7.4342\n",
            "Step: 40, Loss: 7.1660\n",
            "Step: 50, Loss: 5.9145\n",
            "Step: 60, Loss: 7.3014\n",
            "Step: 70, Loss: 7.7666\n",
            "Step: 80, Loss: 7.5511\n",
            "Step: 90, Loss: 6.2643\n",
            "Step: 100, Loss: 7.1839\n",
            "Step: 110, Loss: 5.3938\n",
            "Step: 120, Loss: 7.3348\n",
            "Step: 130, Loss: 5.9235\n",
            "Step: 140, Loss: 6.0241\n",
            "Step: 150, Loss: 6.5177\n",
            "Step: 160, Loss: 7.0355\n",
            "Step: 170, Loss: 6.0351\n",
            "Step: 180, Loss: 6.7511\n",
            "Step: 190, Loss: 5.9056\n",
            "Step: 200, Loss: 6.2145\n",
            "Step: 210, Loss: 5.7370\n",
            "Step: 220, Loss: 6.9411\n",
            "Step: 230, Loss: 6.4263\n",
            "Step: 240, Loss: 6.4935\n",
            "Step: 250, Loss: 6.3181\n",
            "Step: 260, Loss: 6.4933\n",
            "Step: 270, Loss: 5.8911\n",
            "Step: 280, Loss: 6.8380\n",
            "Step: 290, Loss: 7.1255\n",
            "Step: 300, Loss: 6.5911\n",
            "Step: 310, Loss: 5.8859\n",
            "Step: 320, Loss: 6.9126\n",
            "Step: 330, Loss: 6.5967\n",
            "Step: 340, Loss: 6.7064\n",
            "Step: 350, Loss: 6.1962\n",
            "Step: 360, Loss: 5.7562\n",
            "Step: 370, Loss: 5.9538\n",
            "Step: 380, Loss: 6.9621\n",
            "Step: 390, Loss: 7.1926\n",
            "Step: 400, Loss: 6.2406\n",
            "Step: 410, Loss: 6.8793\n",
            "Step: 420, Loss: 6.7920\n",
            "Step: 430, Loss: 5.6676\n",
            "Step: 440, Loss: 6.4836\n",
            "Step: 450, Loss: 5.8379\n",
            "Step: 460, Loss: 5.0805\n",
            "Step: 470, Loss: 5.3195\n",
            "Step: 480, Loss: 5.8577\n",
            "Step: 490, Loss: 6.0510\n",
            "Step: 500, Loss: 5.3045\n",
            "Step: 510, Loss: 5.6220\n",
            "Step: 520, Loss: 5.6595\n",
            "Step: 530, Loss: 5.1026\n",
            "Step: 540, Loss: 6.2747\n",
            "Step: 550, Loss: 6.5637\n",
            "Step: 560, Loss: 5.9919\n",
            "Step: 570, Loss: 4.4590\n",
            "Step: 580, Loss: 5.7116\n",
            "Step: 590, Loss: 6.4498\n",
            "Step: 600, Loss: 6.2833\n",
            "Step: 610, Loss: 6.0663\n",
            "Step: 620, Loss: 6.1303\n",
            "Step: 630, Loss: 6.0391\n",
            "Step: 640, Loss: 5.9534\n",
            "Step: 650, Loss: 5.8069\n",
            "Step: 660, Loss: 5.7637\n",
            "Step: 670, Loss: 6.2510\n",
            "Step: 680, Loss: 6.7757\n",
            "Step: 690, Loss: 5.8833\n",
            "Step: 700, Loss: 5.6237\n",
            "Step: 710, Loss: 5.9463\n",
            "Step: 720, Loss: 5.9818\n",
            "Step: 730, Loss: 3.7111\n",
            "Step: 740, Loss: 6.2097\n",
            "Step: 750, Loss: 6.3188\n",
            "Step: 760, Loss: 5.4198\n",
            "Step: 770, Loss: 3.9056\n",
            "Step: 780, Loss: 5.8297\n",
            "Step: 790, Loss: 6.2319\n",
            "Step: 800, Loss: 5.4723\n",
            "Step: 810, Loss: 5.5568\n",
            "Step: 820, Loss: 6.2107\n",
            "Step: 830, Loss: 6.5033\n",
            "Step: 840, Loss: 5.5697\n",
            "Step: 850, Loss: 5.6075\n",
            "Step: 860, Loss: 5.4451\n",
            "Step: 870, Loss: 6.1277\n",
            "Step: 880, Loss: 6.1290\n",
            "Step: 890, Loss: 5.2920\n",
            "Step: 900, Loss: 3.9140\n",
            "Step: 910, Loss: 6.3699\n",
            "Step: 920, Loss: 4.8495\n",
            "Step: 930, Loss: 5.8845\n",
            "Step: 940, Loss: 3.8847\n",
            "Step: 950, Loss: 6.1746\n",
            "Step: 960, Loss: 6.6594\n",
            "Step: 970, Loss: 4.5531\n",
            "Step: 980, Loss: 5.2382\n",
            "Step: 990, Loss: 6.6860\n",
            "Step: 1000, Loss: 5.7797\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "print(\"Number of batches:\", len(data_loader))\n",
        "for epoch in range(num_epochs):\n",
        "    for c, batch in tqdm.tqdm(enumerate(data_loader)):\n",
        "        tokens = batch['tokens'].cuda()\n",
        "        logits = model(tokens)\n",
        "        loss = lm_cross_entropy_loss(logits, tokens)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        losses.append(loss.item())\n",
        "        if c % log_every == 0:\n",
        "            print(f\"Step: {c}, Loss: {loss.item():.4f}\")\n",
        "        if c > max_steps:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hIFc7msJqGD"
      },
      "source": [
        "We can now plot a loss curve!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2nqIyzQJqGD",
        "outputId": "e02f0f59-b9fa-4d9b-90a5-c8d42eab246d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "hovertemplate": "Tokens=%{x}<br>Loss=%{y}<extra></extra>",
                  "legendgroup": "",
                  "line": {
                    "color": "#636efa",
                    "dash": "solid"
                  },
                  "marker": {
                    "symbol": "circle"
                  },
                  "mode": "lines",
                  "name": "",
                  "showlegend": false,
                  "type": "scattergl",
                  "x": [
                    0,
                    2048,
                    4096,
                    6144,
                    8192,
                    10240,
                    12288,
                    14336,
                    16384,
                    18432,
                    20480,
                    22528,
                    24576,
                    26624,
                    28672,
                    30720,
                    32768,
                    34816,
                    36864,
                    38912,
                    40960,
                    43008,
                    45056,
                    47104,
                    49152,
                    51200,
                    53248,
                    55296,
                    57344,
                    59392,
                    61440,
                    63488,
                    65536,
                    67584,
                    69632,
                    71680,
                    73728,
                    75776,
                    77824,
                    79872,
                    81920,
                    83968,
                    86016,
                    88064,
                    90112,
                    92160,
                    94208,
                    96256,
                    98304,
                    100352,
                    102400,
                    104448,
                    106496,
                    108544,
                    110592,
                    112640,
                    114688,
                    116736,
                    118784,
                    120832,
                    122880,
                    124928,
                    126976,
                    129024,
                    131072,
                    133120,
                    135168,
                    137216,
                    139264,
                    141312,
                    143360,
                    145408,
                    147456,
                    149504,
                    151552,
                    153600,
                    155648,
                    157696,
                    159744,
                    161792,
                    163840,
                    165888,
                    167936,
                    169984,
                    172032,
                    174080,
                    176128,
                    178176,
                    180224,
                    182272,
                    184320,
                    186368,
                    188416,
                    190464,
                    192512,
                    194560,
                    196608,
                    198656,
                    200704,
                    202752,
                    204800,
                    206848,
                    208896,
                    210944,
                    212992,
                    215040,
                    217088,
                    219136,
                    221184,
                    223232,
                    225280,
                    227328,
                    229376,
                    231424,
                    233472,
                    235520,
                    237568,
                    239616,
                    241664,
                    243712,
                    245760,
                    247808,
                    249856,
                    251904,
                    253952,
                    256000,
                    258048,
                    260096,
                    262144,
                    264192,
                    266240,
                    268288,
                    270336,
                    272384,
                    274432,
                    276480,
                    278528,
                    280576,
                    282624,
                    284672,
                    286720,
                    288768,
                    290816,
                    292864,
                    294912,
                    296960,
                    299008,
                    301056,
                    303104,
                    305152,
                    307200,
                    309248,
                    311296,
                    313344,
                    315392,
                    317440,
                    319488,
                    321536,
                    323584,
                    325632,
                    327680,
                    329728,
                    331776,
                    333824,
                    335872,
                    337920,
                    339968,
                    342016,
                    344064,
                    346112,
                    348160,
                    350208,
                    352256,
                    354304,
                    356352,
                    358400,
                    360448,
                    362496,
                    364544,
                    366592,
                    368640,
                    370688,
                    372736,
                    374784,
                    376832,
                    378880,
                    380928,
                    382976,
                    385024,
                    387072,
                    389120,
                    391168,
                    393216,
                    395264,
                    397312,
                    399360,
                    401408,
                    403456,
                    405504,
                    407552,
                    409600,
                    411648,
                    413696,
                    415744,
                    417792,
                    419840,
                    421888,
                    423936,
                    425984,
                    428032,
                    430080,
                    432128,
                    434176,
                    436224,
                    438272,
                    440320,
                    442368,
                    444416,
                    446464,
                    448512,
                    450560,
                    452608,
                    454656,
                    456704,
                    458752,
                    460800,
                    462848,
                    464896,
                    466944,
                    468992,
                    471040,
                    473088,
                    475136,
                    477184,
                    479232,
                    481280,
                    483328,
                    485376,
                    487424,
                    489472,
                    491520,
                    493568,
                    495616,
                    497664,
                    499712,
                    501760,
                    503808,
                    505856,
                    507904,
                    509952,
                    512000,
                    514048,
                    516096,
                    518144,
                    520192,
                    522240,
                    524288,
                    526336,
                    528384,
                    530432,
                    532480,
                    534528,
                    536576,
                    538624,
                    540672,
                    542720,
                    544768,
                    546816,
                    548864,
                    550912,
                    552960,
                    555008,
                    557056,
                    559104,
                    561152,
                    563200,
                    565248,
                    567296,
                    569344,
                    571392,
                    573440,
                    575488,
                    577536,
                    579584,
                    581632,
                    583680,
                    585728,
                    587776,
                    589824,
                    591872,
                    593920,
                    595968,
                    598016,
                    600064,
                    602112,
                    604160,
                    606208,
                    608256,
                    610304,
                    612352,
                    614400,
                    616448,
                    618496,
                    620544,
                    622592,
                    624640,
                    626688,
                    628736,
                    630784,
                    632832,
                    634880,
                    636928,
                    638976,
                    641024,
                    643072,
                    645120,
                    647168,
                    649216,
                    651264,
                    653312,
                    655360,
                    657408,
                    659456,
                    661504,
                    663552,
                    665600,
                    667648,
                    669696,
                    671744,
                    673792,
                    675840,
                    677888,
                    679936,
                    681984,
                    684032,
                    686080,
                    688128,
                    690176,
                    692224,
                    694272,
                    696320,
                    698368,
                    700416,
                    702464,
                    704512,
                    706560,
                    708608,
                    710656,
                    712704,
                    714752,
                    716800,
                    718848,
                    720896,
                    722944,
                    724992,
                    727040,
                    729088,
                    731136,
                    733184,
                    735232,
                    737280,
                    739328,
                    741376,
                    743424,
                    745472,
                    747520,
                    749568,
                    751616,
                    753664,
                    755712,
                    757760,
                    759808,
                    761856,
                    763904,
                    765952,
                    768000,
                    770048,
                    772096,
                    774144,
                    776192,
                    778240,
                    780288,
                    782336,
                    784384,
                    786432,
                    788480,
                    790528,
                    792576,
                    794624,
                    796672,
                    798720,
                    800768,
                    802816,
                    804864,
                    806912,
                    808960,
                    811008,
                    813056,
                    815104,
                    817152,
                    819200,
                    821248,
                    823296,
                    825344,
                    827392,
                    829440,
                    831488,
                    833536,
                    835584,
                    837632,
                    839680,
                    841728,
                    843776,
                    845824,
                    847872,
                    849920,
                    851968,
                    854016,
                    856064,
                    858112,
                    860160,
                    862208,
                    864256,
                    866304,
                    868352,
                    870400,
                    872448,
                    874496,
                    876544,
                    878592,
                    880640,
                    882688,
                    884736,
                    886784,
                    888832,
                    890880,
                    892928,
                    894976,
                    897024,
                    899072,
                    901120,
                    903168,
                    905216,
                    907264,
                    909312,
                    911360,
                    913408,
                    915456,
                    917504,
                    919552,
                    921600,
                    923648,
                    925696,
                    927744,
                    929792,
                    931840,
                    933888,
                    935936,
                    937984,
                    940032,
                    942080,
                    944128,
                    946176,
                    948224,
                    950272,
                    952320,
                    954368,
                    956416,
                    958464,
                    960512,
                    962560,
                    964608,
                    966656,
                    968704,
                    970752,
                    972800,
                    974848,
                    976896,
                    978944,
                    980992,
                    983040,
                    985088,
                    987136,
                    989184,
                    991232,
                    993280,
                    995328,
                    997376,
                    999424,
                    1001472,
                    1003520,
                    1005568,
                    1007616,
                    1009664,
                    1011712,
                    1013760,
                    1015808,
                    1017856,
                    1019904,
                    1021952,
                    1024000,
                    1026048,
                    1028096,
                    1030144,
                    1032192,
                    1034240,
                    1036288,
                    1038336,
                    1040384,
                    1042432,
                    1044480,
                    1046528,
                    1048576,
                    1050624,
                    1052672,
                    1054720,
                    1056768,
                    1058816,
                    1060864,
                    1062912,
                    1064960,
                    1067008,
                    1069056,
                    1071104,
                    1073152,
                    1075200,
                    1077248,
                    1079296,
                    1081344,
                    1083392,
                    1085440,
                    1087488,
                    1089536,
                    1091584,
                    1093632,
                    1095680,
                    1097728,
                    1099776,
                    1101824,
                    1103872,
                    1105920,
                    1107968,
                    1110016,
                    1112064,
                    1114112,
                    1116160,
                    1118208,
                    1120256,
                    1122304,
                    1124352,
                    1126400,
                    1128448,
                    1130496,
                    1132544,
                    1134592,
                    1136640,
                    1138688,
                    1140736,
                    1142784,
                    1144832,
                    1146880,
                    1148928,
                    1150976,
                    1153024,
                    1155072,
                    1157120,
                    1159168,
                    1161216,
                    1163264,
                    1165312,
                    1167360,
                    1169408,
                    1171456,
                    1173504,
                    1175552,
                    1177600,
                    1179648,
                    1181696,
                    1183744,
                    1185792,
                    1187840,
                    1189888,
                    1191936,
                    1193984,
                    1196032,
                    1198080,
                    1200128,
                    1202176,
                    1204224,
                    1206272,
                    1208320,
                    1210368,
                    1212416,
                    1214464,
                    1216512,
                    1218560,
                    1220608,
                    1222656,
                    1224704,
                    1226752,
                    1228800,
                    1230848,
                    1232896,
                    1234944,
                    1236992,
                    1239040,
                    1241088,
                    1243136,
                    1245184,
                    1247232,
                    1249280,
                    1251328,
                    1253376,
                    1255424,
                    1257472,
                    1259520,
                    1261568,
                    1263616,
                    1265664,
                    1267712,
                    1269760,
                    1271808,
                    1273856,
                    1275904,
                    1277952,
                    1280000,
                    1282048,
                    1284096,
                    1286144,
                    1288192,
                    1290240,
                    1292288,
                    1294336,
                    1296384,
                    1298432,
                    1300480,
                    1302528,
                    1304576,
                    1306624,
                    1308672,
                    1310720,
                    1312768,
                    1314816,
                    1316864,
                    1318912,
                    1320960,
                    1323008,
                    1325056,
                    1327104,
                    1329152,
                    1331200,
                    1333248,
                    1335296,
                    1337344,
                    1339392,
                    1341440,
                    1343488,
                    1345536,
                    1347584,
                    1349632,
                    1351680,
                    1353728,
                    1355776,
                    1357824,
                    1359872,
                    1361920,
                    1363968,
                    1366016,
                    1368064,
                    1370112,
                    1372160,
                    1374208,
                    1376256,
                    1378304,
                    1380352,
                    1382400,
                    1384448,
                    1386496,
                    1388544,
                    1390592,
                    1392640,
                    1394688,
                    1396736,
                    1398784,
                    1400832,
                    1402880,
                    1404928,
                    1406976,
                    1409024,
                    1411072,
                    1413120,
                    1415168,
                    1417216,
                    1419264,
                    1421312,
                    1423360,
                    1425408,
                    1427456,
                    1429504,
                    1431552,
                    1433600,
                    1435648,
                    1437696,
                    1439744,
                    1441792,
                    1443840,
                    1445888,
                    1447936,
                    1449984,
                    1452032,
                    1454080,
                    1456128,
                    1458176,
                    1460224,
                    1462272,
                    1464320,
                    1466368,
                    1468416,
                    1470464,
                    1472512,
                    1474560,
                    1476608,
                    1478656,
                    1480704,
                    1482752,
                    1484800,
                    1486848,
                    1488896,
                    1490944,
                    1492992,
                    1495040,
                    1497088,
                    1499136,
                    1501184,
                    1503232,
                    1505280,
                    1507328,
                    1509376,
                    1511424,
                    1513472,
                    1515520,
                    1517568,
                    1519616,
                    1521664,
                    1523712,
                    1525760,
                    1527808,
                    1529856,
                    1531904,
                    1533952,
                    1536000,
                    1538048,
                    1540096,
                    1542144,
                    1544192,
                    1546240,
                    1548288,
                    1550336,
                    1552384,
                    1554432,
                    1556480,
                    1558528,
                    1560576,
                    1562624,
                    1564672,
                    1566720,
                    1568768,
                    1570816,
                    1572864,
                    1574912,
                    1576960,
                    1579008,
                    1581056,
                    1583104,
                    1585152,
                    1587200,
                    1589248,
                    1591296,
                    1593344,
                    1595392,
                    1597440,
                    1599488,
                    1601536,
                    1603584,
                    1605632,
                    1607680,
                    1609728,
                    1611776,
                    1613824,
                    1615872,
                    1617920,
                    1619968,
                    1622016,
                    1624064,
                    1626112,
                    1628160,
                    1630208,
                    1632256,
                    1634304,
                    1636352,
                    1638400,
                    1640448,
                    1642496,
                    1644544,
                    1646592,
                    1648640,
                    1650688,
                    1652736,
                    1654784,
                    1656832,
                    1658880,
                    1660928,
                    1662976,
                    1665024,
                    1667072,
                    1669120,
                    1671168,
                    1673216,
                    1675264,
                    1677312,
                    1679360,
                    1681408,
                    1683456,
                    1685504,
                    1687552,
                    1689600,
                    1691648,
                    1693696,
                    1695744,
                    1697792,
                    1699840,
                    1701888,
                    1703936,
                    1705984,
                    1708032,
                    1710080,
                    1712128,
                    1714176,
                    1716224,
                    1718272,
                    1720320,
                    1722368,
                    1724416,
                    1726464,
                    1728512,
                    1730560,
                    1732608,
                    1734656,
                    1736704,
                    1738752,
                    1740800,
                    1742848,
                    1744896,
                    1746944,
                    1748992,
                    1751040,
                    1753088,
                    1755136,
                    1757184,
                    1759232,
                    1761280,
                    1763328,
                    1765376,
                    1767424,
                    1769472,
                    1771520,
                    1773568,
                    1775616,
                    1777664,
                    1779712,
                    1781760,
                    1783808,
                    1785856,
                    1787904,
                    1789952,
                    1792000,
                    1794048,
                    1796096,
                    1798144,
                    1800192,
                    1802240,
                    1804288,
                    1806336,
                    1808384,
                    1810432,
                    1812480,
                    1814528,
                    1816576,
                    1818624,
                    1820672,
                    1822720,
                    1824768,
                    1826816,
                    1828864,
                    1830912,
                    1832960,
                    1835008,
                    1837056,
                    1839104,
                    1841152,
                    1843200,
                    1845248,
                    1847296,
                    1849344,
                    1851392,
                    1853440,
                    1855488,
                    1857536,
                    1859584,
                    1861632,
                    1863680,
                    1865728,
                    1867776,
                    1869824,
                    1871872,
                    1873920,
                    1875968,
                    1878016,
                    1880064,
                    1882112,
                    1884160,
                    1886208,
                    1888256,
                    1890304,
                    1892352,
                    1894400,
                    1896448,
                    1898496,
                    1900544,
                    1902592,
                    1904640,
                    1906688,
                    1908736,
                    1910784,
                    1912832,
                    1914880,
                    1916928,
                    1918976,
                    1921024,
                    1923072,
                    1925120,
                    1927168,
                    1929216,
                    1931264,
                    1933312,
                    1935360,
                    1937408,
                    1939456,
                    1941504,
                    1943552,
                    1945600,
                    1947648,
                    1949696,
                    1951744,
                    1953792,
                    1955840,
                    1957888,
                    1959936,
                    1961984,
                    1964032,
                    1966080,
                    1968128,
                    1970176,
                    1972224,
                    1974272,
                    1976320,
                    1978368,
                    1980416,
                    1982464,
                    1984512,
                    1986560,
                    1988608,
                    1990656,
                    1992704,
                    1994752,
                    1996800,
                    1998848,
                    2000896,
                    2002944,
                    2004992,
                    2007040,
                    2009088,
                    2011136,
                    2013184,
                    2015232,
                    2017280,
                    2019328,
                    2021376,
                    2023424,
                    2025472,
                    2027520,
                    2029568,
                    2031616,
                    2033664,
                    2035712,
                    2037760,
                    2039808,
                    2041856,
                    2043904,
                    2045952,
                    2048000,
                    2050048
                  ],
                  "xaxis": "x",
                  "y": [
                    10.893806457519531,
                    10.427045822143555,
                    9.634830474853516,
                    10.264103889465332,
                    9.31908893585205,
                    9.114545822143555,
                    8.989713668823242,
                    9.26657485961914,
                    9.180978775024414,
                    9.055776596069336,
                    8.61603832244873,
                    8.559957504272461,
                    7.807898998260498,
                    7.91976261138916,
                    8.070566177368164,
                    8.144721031188965,
                    6.628560543060303,
                    7.808859348297119,
                    7.625852584838867,
                    8.305569648742676,
                    7.4169535636901855,
                    8.14185905456543,
                    7.313915252685547,
                    7.433940410614014,
                    7.547981262207031,
                    7.983862400054932,
                    7.127997875213623,
                    8.078697204589844,
                    7.674922943115234,
                    7.675109386444092,
                    7.434235095977783,
                    6.662626266479492,
                    7.124334335327148,
                    7.280995845794678,
                    8.049904823303223,
                    7.849207878112793,
                    7.362364292144775,
                    7.178154945373535,
                    7.463449954986572,
                    7.016193866729736,
                    7.165964603424072,
                    7.815927982330322,
                    7.132492542266846,
                    7.43367862701416,
                    6.771230220794678,
                    7.732711315155029,
                    7.033417224884033,
                    7.152134895324707,
                    7.452767848968506,
                    5.829916477203369,
                    5.914529323577881,
                    7.554685115814209,
                    6.6695756912231445,
                    7.587604522705078,
                    6.977630138397217,
                    5.184032440185547,
                    6.905055522918701,
                    6.271007061004639,
                    7.990111827850342,
                    7.912749767303467,
                    7.301448822021484,
                    6.28422212600708,
                    6.436372756958008,
                    7.807494640350342,
                    5.948660850524902,
                    7.79941987991333,
                    6.602100849151611,
                    6.598696231842041,
                    7.384997844696045,
                    5.916327953338623,
                    7.766610622406006,
                    6.166258335113525,
                    6.354918003082275,
                    6.029428482055664,
                    5.2543721199035645,
                    6.982370376586914,
                    6.40958833694458,
                    7.218695640563965,
                    5.283820629119873,
                    7.403279781341553,
                    7.551144599914551,
                    7.717860221862793,
                    7.281604766845703,
                    6.9039106369018555,
                    6.831348896026611,
                    7.377828598022461,
                    7.305034637451172,
                    6.493904113769531,
                    7.502947807312012,
                    7.475921630859375,
                    6.264326095581055,
                    7.900688171386719,
                    6.392958641052246,
                    5.9810099601745605,
                    6.367247104644775,
                    6.246963977813721,
                    5.692319393157959,
                    7.359583377838135,
                    7.038933753967285,
                    7.6092376708984375,
                    7.183945655822754,
                    5.9209113121032715,
                    6.992689609527588,
                    7.349926948547363,
                    6.442592620849609,
                    6.999311923980713,
                    6.716317176818848,
                    7.594215393066406,
                    6.622709274291992,
                    6.699754238128662,
                    5.393760681152344,
                    7.043684482574463,
                    6.514898300170898,
                    6.696376323699951,
                    6.69824743270874,
                    6.460135459899902,
                    7.281935214996338,
                    7.212729454040527,
                    7.594583511352539,
                    7.138926982879639,
                    7.3348188400268555,
                    7.189274311065674,
                    6.738702774047852,
                    6.5225324630737305,
                    6.949594497680664,
                    7.422399520874023,
                    7.410975456237793,
                    6.666720867156982,
                    6.22360372543335,
                    7.085495948791504,
                    5.923482418060303,
                    7.522467136383057,
                    6.361387729644775,
                    5.82284688949585,
                    6.317162036895752,
                    6.981962203979492,
                    7.379582405090332,
                    7.258055686950684,
                    6.434112071990967,
                    7.474478244781494,
                    6.024131774902344,
                    6.669892311096191,
                    6.059913158416748,
                    6.535154342651367,
                    7.081905364990234,
                    6.6076836585998535,
                    7.319371223449707,
                    5.877340316772461,
                    5.5880937576293945,
                    6.722639083862305,
                    6.517719745635986,
                    6.36610221862793,
                    7.354548454284668,
                    6.7593159675598145,
                    6.2848405838012695,
                    7.1035966873168945,
                    6.770442008972168,
                    6.092446327209473,
                    6.611698150634766,
                    7.249154090881348,
                    7.035548210144043,
                    7.410935878753662,
                    6.4828386306762695,
                    7.404731750488281,
                    7.463119983673096,
                    7.264775276184082,
                    7.030026912689209,
                    6.849971771240234,
                    7.444589138031006,
                    5.312416076660156,
                    6.035064220428467,
                    7.059691429138184,
                    6.277189254760742,
                    5.8443074226379395,
                    6.416632652282715,
                    7.28755521774292,
                    6.559230327606201,
                    6.728107929229736,
                    6.1987409591674805,
                    7.212503910064697,
                    6.751069068908691,
                    7.469141960144043,
                    7.459601879119873,
                    7.349392414093018,
                    6.170513153076172,
                    7.395143032073975,
                    7.279488563537598,
                    6.692648410797119,
                    7.316223621368408,
                    6.771309852600098,
                    5.905599594116211,
                    6.544557094573975,
                    5.2595744132995605,
                    6.352523326873779,
                    6.099898815155029,
                    6.16761589050293,
                    7.125868797302246,
                    6.7148237228393555,
                    5.997227668762207,
                    6.733247756958008,
                    6.214476585388184,
                    6.407529830932617,
                    7.264333724975586,
                    6.977560520172119,
                    6.015833854675293,
                    5.969151020050049,
                    7.000478267669678,
                    7.178333759307861,
                    6.263494968414307,
                    7.6479105949401855,
                    5.736992835998535,
                    7.1781744956970215,
                    6.309168338775635,
                    6.672365188598633,
                    5.365495204925537,
                    7.181882381439209,
                    7.348421573638916,
                    6.74544620513916,
                    7.177699565887451,
                    6.935952186584473,
                    6.941099643707275,
                    6.934011936187744,
                    5.753427982330322,
                    6.674023628234863,
                    5.459040641784668,
                    6.063246250152588,
                    6.395949363708496,
                    7.373455047607422,
                    6.879143238067627,
                    7.1031951904296875,
                    6.42634916305542,
                    7.1864447593688965,
                    6.8405632972717285,
                    3.5708701610565186,
                    7.0937581062316895,
                    6.570587635040283,
                    6.882235050201416,
                    7.279861927032471,
                    6.178062915802002,
                    7.118537902832031,
                    6.493494033813477,
                    5.847645282745361,
                    5.426514148712158,
                    7.372856616973877,
                    6.965512275695801,
                    5.870194911956787,
                    6.197558403015137,
                    6.458340644836426,
                    6.9095778465271,
                    6.297845363616943,
                    6.318068504333496,
                    6.843086242675781,
                    6.492095947265625,
                    6.620027542114258,
                    6.984341144561768,
                    6.305624961853027,
                    6.843216896057129,
                    6.46617317199707,
                    6.985827922821045,
                    6.762999057769775,
                    6.4933013916015625,
                    6.540491104125977,
                    6.23700475692749,
                    6.200334072113037,
                    5.087399005889893,
                    6.061723709106445,
                    6.203706741333008,
                    5.4813008308410645,
                    6.1341447830200195,
                    6.042251110076904,
                    5.891076564788818,
                    6.780318260192871,
                    6.889206886291504,
                    7.024605751037598,
                    6.477628707885742,
                    5.8595051765441895,
                    5.17009973526001,
                    6.039463520050049,
                    6.932980060577393,
                    6.82629919052124,
                    6.837954044342041,
                    7.210803985595703,
                    7.130180358886719,
                    7.339724540710449,
                    5.242691516876221,
                    7.033135890960693,
                    6.220620155334473,
                    6.3562774658203125,
                    6.419381618499756,
                    7.239526748657227,
                    7.125497341156006,
                    6.268826961517334,
                    6.306741714477539,
                    6.266530990600586,
                    6.408555030822754,
                    6.608877658843994,
                    7.197091579437256,
                    7.300697326660156,
                    6.535238742828369,
                    6.545780181884766,
                    6.591123104095459,
                    6.527737617492676,
                    5.379087448120117,
                    5.816311836242676,
                    6.979439735412598,
                    6.299715042114258,
                    6.738414764404297,
                    6.83601713180542,
                    6.863978862762451,
                    6.356145858764648,
                    5.8859100341796875,
                    6.475433349609375,
                    7.122377872467041,
                    6.07142448425293,
                    6.694138526916504,
                    5.902716636657715,
                    5.306896686553955,
                    6.100412845611572,
                    6.454117774963379,
                    6.785376071929932,
                    6.912567138671875,
                    5.604643821716309,
                    7.153719425201416,
                    6.470905780792236,
                    6.952639102935791,
                    5.539736270904541,
                    6.790310382843018,
                    6.9054856300354,
                    6.2068681716918945,
                    6.471749782562256,
                    6.596714019775391,
                    6.819143295288086,
                    5.786790370941162,
                    5.1841535568237305,
                    5.967902183532715,
                    6.736931800842285,
                    5.688403129577637,
                    6.72953987121582,
                    6.925650119781494,
                    5.920834541320801,
                    6.706357479095459,
                    6.801548480987549,
                    6.692095756530762,
                    6.381126880645752,
                    5.92860221862793,
                    7.283708095550537,
                    6.068110466003418,
                    6.476272106170654,
                    5.462843894958496,
                    5.8082685470581055,
                    6.196161270141602,
                    5.988715648651123,
                    7.031335830688477,
                    5.655581474304199,
                    6.302164077758789,
                    6.990185260772705,
                    6.657060146331787,
                    5.792215824127197,
                    5.712269306182861,
                    5.634867191314697,
                    5.756242752075195,
                    6.833441734313965,
                    6.653871059417725,
                    6.184776782989502,
                    6.141414642333984,
                    6.0818586349487305,
                    6.62661600112915,
                    6.63861083984375,
                    6.139286994934082,
                    5.828361988067627,
                    5.95382833480835,
                    6.8002848625183105,
                    6.97227668762207,
                    6.524081230163574,
                    6.48838996887207,
                    4.758155822753906,
                    6.398387908935547,
                    6.102293968200684,
                    6.068881511688232,
                    5.9436821937561035,
                    6.9621195793151855,
                    5.715623378753662,
                    7.000760555267334,
                    5.76843786239624,
                    5.78002405166626,
                    5.549404621124268,
                    5.251672267913818,
                    6.037641525268555,
                    5.882079601287842,
                    5.322067737579346,
                    7.192586421966553,
                    5.651959419250488,
                    6.422826290130615,
                    6.721909046173096,
                    6.212947845458984,
                    6.5321269035339355,
                    6.26345157623291,
                    5.321763038635254,
                    6.853144645690918,
                    5.9502129554748535,
                    6.240609169006348,
                    7.064380168914795,
                    7.060173511505127,
                    5.434298515319824,
                    5.713833808898926,
                    5.35958194732666,
                    7.389200687408447,
                    6.6098551750183105,
                    5.971768379211426,
                    6.044561862945557,
                    6.879286766052246,
                    5.353652477264404,
                    7.192244529724121,
                    5.155861854553223,
                    6.459859848022461,
                    6.823322772979736,
                    5.7928643226623535,
                    6.195549964904785,
                    6.129689693450928,
                    5.382623195648193,
                    6.791993618011475,
                    7.066790580749512,
                    6.2079668045043945,
                    5.869408130645752,
                    4.974715709686279,
                    3.9946670532226562,
                    7.120031356811523,
                    6.764587879180908,
                    5.174720764160156,
                    5.589199542999268,
                    5.667579650878906,
                    5.988559246063232,
                    6.569380283355713,
                    6.821842670440674,
                    6.315308094024658,
                    6.189703464508057,
                    6.124805450439453,
                    7.062331199645996,
                    4.86233377456665,
                    6.8343024253845215,
                    6.483643531799316,
                    6.55932092666626,
                    5.6199116706848145,
                    4.8574137687683105,
                    6.9304399490356445,
                    6.953507900238037,
                    6.775815010070801,
                    6.817715167999268,
                    6.5624260902404785,
                    5.681647777557373,
                    5.837902545928955,
                    5.0996479988098145,
                    6.8481268882751465,
                    6.1209235191345215,
                    6.820996284484863,
                    6.056341648101807,
                    6.095166206359863,
                    6.61842679977417,
                    5.438260078430176,
                    5.6815290451049805,
                    5.080475807189941,
                    6.436587333679199,
                    5.884406089782715,
                    5.9520978927612305,
                    5.5276665687561035,
                    6.096118927001953,
                    6.399137020111084,
                    4.965343952178955,
                    6.128511428833008,
                    7.015021324157715,
                    5.319487571716309,
                    6.856664180755615,
                    6.083608150482178,
                    6.367321968078613,
                    5.843657493591309,
                    6.4260478019714355,
                    6.378108978271484,
                    6.459695339202881,
                    6.6272759437561035,
                    6.059246063232422,
                    5.8577470779418945,
                    6.326718807220459,
                    5.700711727142334,
                    6.2530927658081055,
                    6.536418914794922,
                    5.880959987640381,
                    6.49962043762207,
                    6.309074401855469,
                    5.8287248611450195,
                    5.960597991943359,
                    6.050961494445801,
                    5.545186519622803,
                    6.5997138023376465,
                    5.92969274520874,
                    6.413270950317383,
                    6.187255382537842,
                    6.180765151977539,
                    6.33779239654541,
                    6.12028694152832,
                    6.397641181945801,
                    5.3044657707214355,
                    6.83604621887207,
                    6.510043621063232,
                    6.346192836761475,
                    6.65885066986084,
                    6.221997261047363,
                    6.662997245788574,
                    5.459427833557129,
                    6.85530948638916,
                    5.3961591720581055,
                    5.622014045715332,
                    5.986109733581543,
                    6.281040191650391,
                    5.967301845550537,
                    6.529374599456787,
                    6.527423858642578,
                    5.974690914154053,
                    6.404294490814209,
                    5.865479469299316,
                    5.839770317077637,
                    5.659456729888916,
                    6.732898235321045,
                    5.857100009918213,
                    6.750272750854492,
                    6.411985397338867,
                    6.792856216430664,
                    6.249256134033203,
                    6.093013286590576,
                    6.611140727996826,
                    5.683406829833984,
                    5.102623462677002,
                    6.719038963317871,
                    6.895438194274902,
                    6.569279670715332,
                    6.300320148468018,
                    6.2968339920043945,
                    6.411684036254883,
                    6.303232669830322,
                    6.670129299163818,
                    6.057904243469238,
                    6.274672031402588,
                    5.103349208831787,
                    6.7471022605896,
                    6.320355415344238,
                    6.9138264656066895,
                    4.943398952484131,
                    5.276199817657471,
                    6.158751487731934,
                    6.529575824737549,
                    6.511270999908447,
                    6.563686847686768,
                    6.825718402862549,
                    6.0076751708984375,
                    5.515554428100586,
                    6.78159236907959,
                    4.525760650634766,
                    5.7860331535339355,
                    6.884456634521484,
                    4.664862155914307,
                    6.475404262542725,
                    5.991855621337891,
                    5.9356369972229,
                    6.793413162231445,
                    6.159652233123779,
                    6.055816650390625,
                    6.205516815185547,
                    5.20932149887085,
                    6.274753570556641,
                    5.284594535827637,
                    4.9419779777526855,
                    4.458980560302734,
                    6.209834098815918,
                    5.361738681793213,
                    5.023915767669678,
                    5.331613540649414,
                    6.29410982131958,
                    6.466154098510742,
                    5.626280784606934,
                    6.35620641708374,
                    5.478240489959717,
                    5.7116475105285645,
                    5.892956256866455,
                    6.420624256134033,
                    5.794150352478027,
                    5.921229839324951,
                    6.869009017944336,
                    6.1308183670043945,
                    5.915657043457031,
                    6.974363327026367,
                    5.450153350830078,
                    6.449761867523193,
                    6.045516014099121,
                    5.421005725860596,
                    6.253221035003662,
                    5.2270307540893555,
                    6.376247406005859,
                    6.1876349449157715,
                    6.06260871887207,
                    6.720747470855713,
                    5.627060890197754,
                    6.283331394195557,
                    6.351734161376953,
                    5.523952960968018,
                    6.370999336242676,
                    6.451564311981201,
                    6.202211856842041,
                    4.996163845062256,
                    5.659505367279053,
                    5.903824329376221,
                    5.46745491027832,
                    6.066342830657959,
                    6.6164679527282715,
                    4.496311187744141,
                    6.918656349182129,
                    6.374454021453857,
                    6.624735355377197,
                    6.1405181884765625,
                    6.419637680053711,
                    5.368797779083252,
                    5.63762092590332,
                    6.130258083343506,
                    5.883955001831055,
                    5.349919319152832,
                    5.981701850891113,
                    6.619306564331055,
                    5.355196952819824,
                    6.703455924987793,
                    6.215742111206055,
                    6.538422107696533,
                    6.278171539306641,
                    6.039126396179199,
                    5.870230674743652,
                    6.178444862365723,
                    6.194089412689209,
                    6.146444797515869,
                    6.731659889221191,
                    5.233891010284424,
                    5.954592704772949,
                    5.619664669036865,
                    6.739044666290283,
                    5.9534220695495605,
                    6.210587978363037,
                    6.765751361846924,
                    6.739131450653076,
                    5.395712852478027,
                    6.435729503631592,
                    6.559391021728516,
                    6.6493916511535645,
                    5.664209365844727,
                    5.9365363121032715,
                    5.80687952041626,
                    6.157029628753662,
                    6.582067012786865,
                    5.272243976593018,
                    6.387413024902344,
                    6.019307613372803,
                    5.77635383605957,
                    5.32295036315918,
                    5.941738128662109,
                    6.576267242431641,
                    5.763748645782471,
                    5.9041008949279785,
                    5.74242639541626,
                    6.283062934875488,
                    6.257469177246094,
                    6.562018394470215,
                    6.809732437133789,
                    6.094371795654297,
                    6.236048221588135,
                    4.181057929992676,
                    6.251044273376465,
                    6.477835178375244,
                    6.046085357666016,
                    5.837491512298584,
                    6.458290100097656,
                    5.670943260192871,
                    5.2971978187561035,
                    6.108110427856445,
                    5.750730991363525,
                    5.690359115600586,
                    6.7756781578063965,
                    5.08757209777832,
                    6.263877868652344,
                    6.261489391326904,
                    5.932858467102051,
                    6.66238260269165,
                    5.9046430587768555,
                    6.724463939666748,
                    5.962268829345703,
                    6.093897342681885,
                    5.88328742980957,
                    6.031794548034668,
                    5.620194911956787,
                    6.442348957061768,
                    6.230268955230713,
                    5.84187650680542,
                    6.334973335266113,
                    6.030936241149902,
                    6.146600246429443,
                    5.107158660888672,
                    5.6236724853515625,
                    6.439016342163086,
                    6.273532390594482,
                    6.079730033874512,
                    5.274417877197266,
                    5.807642459869385,
                    5.274596214294434,
                    5.956326961517334,
                    6.173469543457031,
                    6.205816745758057,
                    5.946310997009277,
                    5.619250297546387,
                    7.0108642578125,
                    6.019609451293945,
                    6.104399681091309,
                    5.485321998596191,
                    6.42507791519165,
                    6.118117332458496,
                    5.677605628967285,
                    6.27752685546875,
                    5.981806755065918,
                    5.951730251312256,
                    6.593650817871094,
                    5.710947036743164,
                    5.852570056915283,
                    5.670546054840088,
                    6.290445327758789,
                    5.928374290466309,
                    6.097687244415283,
                    6.00021505355835,
                    3.711148977279663,
                    6.25396728515625,
                    5.271996021270752,
                    5.282454967498779,
                    6.487525463104248,
                    6.3335957527160645,
                    5.35158109664917,
                    5.694026470184326,
                    6.299812316894531,
                    6.349177837371826,
                    6.209733486175537,
                    6.428217887878418,
                    5.592421531677246,
                    5.482235431671143,
                    5.584145545959473,
                    5.41577672958374,
                    6.766429424285889,
                    5.789606094360352,
                    5.375753402709961,
                    6.307466506958008,
                    6.318812370300293,
                    6.481020450592041,
                    5.817994594573975,
                    6.273177623748779,
                    6.722898006439209,
                    5.338503837585449,
                    6.670080661773682,
                    5.980781078338623,
                    5.287014007568359,
                    5.842097282409668,
                    5.419844627380371,
                    5.756831645965576,
                    5.9169745445251465,
                    5.530550479888916,
                    6.213921070098877,
                    6.109903812408447,
                    5.853615760803223,
                    6.207830429077148,
                    5.492738246917725,
                    6.175370216369629,
                    3.9055612087249756,
                    6.336564064025879,
                    4.95462703704834,
                    5.901712417602539,
                    5.375865936279297,
                    5.625036716461182,
                    4.983633518218994,
                    6.198032855987549,
                    5.082873344421387,
                    4.950484752655029,
                    5.829664707183838,
                    5.235795497894287,
                    6.1329569816589355,
                    5.456839084625244,
                    5.522766590118408,
                    5.183165073394775,
                    5.625036716461182,
                    5.867244720458984,
                    5.701903820037842,
                    6.661999702453613,
                    6.231913089752197,
                    6.1269636154174805,
                    4.888288974761963,
                    5.385567665100098,
                    5.985903263092041,
                    6.738123893737793,
                    5.537220478057861,
                    5.86268424987793,
                    6.744391441345215,
                    6.640661716461182,
                    5.472293853759766,
                    5.546179294586182,
                    5.534297943115234,
                    6.367386341094971,
                    5.67014741897583,
                    6.480928897857666,
                    5.720998287200928,
                    6.059472560882568,
                    5.823733806610107,
                    4.560082912445068,
                    5.55682373046875,
                    4.636996746063232,
                    5.792925834655762,
                    5.952547550201416,
                    5.223880290985107,
                    6.596568584442139,
                    6.045695781707764,
                    5.875568866729736,
                    6.208745956420898,
                    6.532783508300781,
                    6.210654258728027,
                    6.346561908721924,
                    6.338615894317627,
                    5.9337358474731445,
                    6.433508396148682,
                    6.319293975830078,
                    5.811450004577637,
                    5.49641752243042,
                    5.907059192657471,
                    5.746159553527832,
                    6.503262519836426,
                    5.756721496582031,
                    6.488044738769531,
                    6.117894649505615,
                    5.86445426940918,
                    5.835223197937012,
                    5.549563884735107,
                    5.330730438232422,
                    4.362559795379639,
                    5.012577056884766,
                    5.569671630859375,
                    6.176525592803955,
                    5.664442539215088,
                    6.331360340118408,
                    5.243968486785889,
                    5.100625514984131,
                    6.374338150024414,
                    6.497174263000488,
                    5.70150899887085,
                    5.64119291305542,
                    5.607527732849121,
                    5.71267557144165,
                    6.280437469482422,
                    5.915352821350098,
                    5.677097320556641,
                    6.360349178314209,
                    6.265502452850342,
                    6.178948402404785,
                    5.341156482696533,
                    5.870170593261719,
                    5.4451117515563965,
                    6.241472244262695,
                    5.314521312713623,
                    4.9461517333984375,
                    6.680211544036865,
                    6.917564868927002,
                    6.49563455581665,
                    6.11849308013916,
                    5.478568077087402,
                    6.257815837860107,
                    6.127716064453125,
                    5.675842761993408,
                    6.210302829742432,
                    6.548689842224121,
                    5.86232852935791,
                    5.740886688232422,
                    6.508115768432617,
                    5.909424304962158,
                    6.129854679107666,
                    5.92615270614624,
                    6.129012107849121,
                    5.991880416870117,
                    6.622316837310791,
                    5.540594577789307,
                    6.060328006744385,
                    5.931400775909424,
                    6.792439937591553,
                    5.400372505187988,
                    5.405616283416748,
                    5.465909481048584,
                    5.291983127593994,
                    6.062725067138672,
                    5.695817470550537,
                    6.294777870178223,
                    6.29988431930542,
                    6.702127933502197,
                    5.836272239685059,
                    6.2906880378723145,
                    5.82119083404541,
                    6.386631965637207,
                    3.914015293121338,
                    4.600915431976318,
                    5.786273956298828,
                    5.965373516082764,
                    5.688570022583008,
                    5.874922752380371,
                    5.608105659484863,
                    6.473889350891113,
                    6.068475246429443,
                    5.559708118438721,
                    6.369912147521973,
                    5.660721302032471,
                    6.10959529876709,
                    5.171573162078857,
                    5.885856628417969,
                    6.098738670349121,
                    5.7309136390686035,
                    6.036271095275879,
                    5.380069732666016,
                    6.102173805236816,
                    4.849461078643799,
                    5.115664958953857,
                    6.431756019592285,
                    6.017018795013428,
                    6.432150363922119,
                    5.532230377197266,
                    5.253816604614258,
                    6.474475860595703,
                    3.9770805835723877,
                    6.072547912597656,
                    5.884472370147705,
                    6.253187656402588,
                    5.945555686950684,
                    6.096212863922119,
                    6.4258246421813965,
                    5.689128875732422,
                    6.403471946716309,
                    5.640111446380615,
                    6.316356658935547,
                    5.253259658813477,
                    3.884716033935547,
                    5.994566440582275,
                    6.261377334594727,
                    6.544004917144775,
                    5.812011241912842,
                    5.568344593048096,
                    6.187015056610107,
                    6.731874465942383,
                    4.954038619995117,
                    5.797821044921875,
                    6.174631595611572,
                    4.538426399230957,
                    6.5726213455200195,
                    4.4626264572143555,
                    5.83879280090332,
                    6.313039302825928,
                    5.421074867248535,
                    5.935083389282227,
                    4.370193004608154,
                    6.679178714752197,
                    6.659379959106445,
                    6.706349849700928,
                    5.316075325012207,
                    5.927857875823975,
                    5.195620536804199,
                    5.5007004737854,
                    6.650441646575928,
                    6.306372165679932,
                    6.594603538513184,
                    4.7035698890686035,
                    4.553125381469727,
                    6.798477649688721,
                    5.679795265197754,
                    5.9527788162231445,
                    4.551840305328369,
                    5.673043251037598,
                    6.304561614990234,
                    6.020262241363525,
                    6.0588297843933105,
                    5.522863388061523,
                    5.2381768226623535,
                    6.00363302230835,
                    6.389254570007324,
                    5.4175825119018555,
                    6.422732830047607,
                    5.610039234161377,
                    5.911554336547852,
                    5.2098002433776855,
                    5.918560028076172,
                    5.055022239685059,
                    6.686042308807373,
                    5.942429542541504,
                    5.942678928375244,
                    5.244865894317627,
                    6.026693344116211,
                    6.240598678588867,
                    4.710692405700684,
                    5.621710777282715,
                    5.577942371368408,
                    5.0781660079956055,
                    5.779727458953857,
                    4.423628330230713
                  ],
                  "yaxis": "y"
                }
              ],
              "layout": {
                "legend": {
                  "tracegroupgap": 0
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Training curve for my tiny demo model!"
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Tokens"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Loss"
                  }
                }
              }
            },
            "text/html": [
              "<div>                            <div id=\"d657c504-b9c0-4f64-b88a-1888977a57e1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d657c504-b9c0-4f64-b88a-1888977a57e1\")) {                    Plotly.newPlot(                        \"d657c504-b9c0-4f64-b88a-1888977a57e1\",                        [{\"hovertemplate\":\"Tokens=%{x}<br>Loss=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[0,2048,4096,6144,8192,10240,12288,14336,16384,18432,20480,22528,24576,26624,28672,30720,32768,34816,36864,38912,40960,43008,45056,47104,49152,51200,53248,55296,57344,59392,61440,63488,65536,67584,69632,71680,73728,75776,77824,79872,81920,83968,86016,88064,90112,92160,94208,96256,98304,100352,102400,104448,106496,108544,110592,112640,114688,116736,118784,120832,122880,124928,126976,129024,131072,133120,135168,137216,139264,141312,143360,145408,147456,149504,151552,153600,155648,157696,159744,161792,163840,165888,167936,169984,172032,174080,176128,178176,180224,182272,184320,186368,188416,190464,192512,194560,196608,198656,200704,202752,204800,206848,208896,210944,212992,215040,217088,219136,221184,223232,225280,227328,229376,231424,233472,235520,237568,239616,241664,243712,245760,247808,249856,251904,253952,256000,258048,260096,262144,264192,266240,268288,270336,272384,274432,276480,278528,280576,282624,284672,286720,288768,290816,292864,294912,296960,299008,301056,303104,305152,307200,309248,311296,313344,315392,317440,319488,321536,323584,325632,327680,329728,331776,333824,335872,337920,339968,342016,344064,346112,348160,350208,352256,354304,356352,358400,360448,362496,364544,366592,368640,370688,372736,374784,376832,378880,380928,382976,385024,387072,389120,391168,393216,395264,397312,399360,401408,403456,405504,407552,409600,411648,413696,415744,417792,419840,421888,423936,425984,428032,430080,432128,434176,436224,438272,440320,442368,444416,446464,448512,450560,452608,454656,456704,458752,460800,462848,464896,466944,468992,471040,473088,475136,477184,479232,481280,483328,485376,487424,489472,491520,493568,495616,497664,499712,501760,503808,505856,507904,509952,512000,514048,516096,518144,520192,522240,524288,526336,528384,530432,532480,534528,536576,538624,540672,542720,544768,546816,548864,550912,552960,555008,557056,559104,561152,563200,565248,567296,569344,571392,573440,575488,577536,579584,581632,583680,585728,587776,589824,591872,593920,595968,598016,600064,602112,604160,606208,608256,610304,612352,614400,616448,618496,620544,622592,624640,626688,628736,630784,632832,634880,636928,638976,641024,643072,645120,647168,649216,651264,653312,655360,657408,659456,661504,663552,665600,667648,669696,671744,673792,675840,677888,679936,681984,684032,686080,688128,690176,692224,694272,696320,698368,700416,702464,704512,706560,708608,710656,712704,714752,716800,718848,720896,722944,724992,727040,729088,731136,733184,735232,737280,739328,741376,743424,745472,747520,749568,751616,753664,755712,757760,759808,761856,763904,765952,768000,770048,772096,774144,776192,778240,780288,782336,784384,786432,788480,790528,792576,794624,796672,798720,800768,802816,804864,806912,808960,811008,813056,815104,817152,819200,821248,823296,825344,827392,829440,831488,833536,835584,837632,839680,841728,843776,845824,847872,849920,851968,854016,856064,858112,860160,862208,864256,866304,868352,870400,872448,874496,876544,878592,880640,882688,884736,886784,888832,890880,892928,894976,897024,899072,901120,903168,905216,907264,909312,911360,913408,915456,917504,919552,921600,923648,925696,927744,929792,931840,933888,935936,937984,940032,942080,944128,946176,948224,950272,952320,954368,956416,958464,960512,962560,964608,966656,968704,970752,972800,974848,976896,978944,980992,983040,985088,987136,989184,991232,993280,995328,997376,999424,1001472,1003520,1005568,1007616,1009664,1011712,1013760,1015808,1017856,1019904,1021952,1024000,1026048,1028096,1030144,1032192,1034240,1036288,1038336,1040384,1042432,1044480,1046528,1048576,1050624,1052672,1054720,1056768,1058816,1060864,1062912,1064960,1067008,1069056,1071104,1073152,1075200,1077248,1079296,1081344,1083392,1085440,1087488,1089536,1091584,1093632,1095680,1097728,1099776,1101824,1103872,1105920,1107968,1110016,1112064,1114112,1116160,1118208,1120256,1122304,1124352,1126400,1128448,1130496,1132544,1134592,1136640,1138688,1140736,1142784,1144832,1146880,1148928,1150976,1153024,1155072,1157120,1159168,1161216,1163264,1165312,1167360,1169408,1171456,1173504,1175552,1177600,1179648,1181696,1183744,1185792,1187840,1189888,1191936,1193984,1196032,1198080,1200128,1202176,1204224,1206272,1208320,1210368,1212416,1214464,1216512,1218560,1220608,1222656,1224704,1226752,1228800,1230848,1232896,1234944,1236992,1239040,1241088,1243136,1245184,1247232,1249280,1251328,1253376,1255424,1257472,1259520,1261568,1263616,1265664,1267712,1269760,1271808,1273856,1275904,1277952,1280000,1282048,1284096,1286144,1288192,1290240,1292288,1294336,1296384,1298432,1300480,1302528,1304576,1306624,1308672,1310720,1312768,1314816,1316864,1318912,1320960,1323008,1325056,1327104,1329152,1331200,1333248,1335296,1337344,1339392,1341440,1343488,1345536,1347584,1349632,1351680,1353728,1355776,1357824,1359872,1361920,1363968,1366016,1368064,1370112,1372160,1374208,1376256,1378304,1380352,1382400,1384448,1386496,1388544,1390592,1392640,1394688,1396736,1398784,1400832,1402880,1404928,1406976,1409024,1411072,1413120,1415168,1417216,1419264,1421312,1423360,1425408,1427456,1429504,1431552,1433600,1435648,1437696,1439744,1441792,1443840,1445888,1447936,1449984,1452032,1454080,1456128,1458176,1460224,1462272,1464320,1466368,1468416,1470464,1472512,1474560,1476608,1478656,1480704,1482752,1484800,1486848,1488896,1490944,1492992,1495040,1497088,1499136,1501184,1503232,1505280,1507328,1509376,1511424,1513472,1515520,1517568,1519616,1521664,1523712,1525760,1527808,1529856,1531904,1533952,1536000,1538048,1540096,1542144,1544192,1546240,1548288,1550336,1552384,1554432,1556480,1558528,1560576,1562624,1564672,1566720,1568768,1570816,1572864,1574912,1576960,1579008,1581056,1583104,1585152,1587200,1589248,1591296,1593344,1595392,1597440,1599488,1601536,1603584,1605632,1607680,1609728,1611776,1613824,1615872,1617920,1619968,1622016,1624064,1626112,1628160,1630208,1632256,1634304,1636352,1638400,1640448,1642496,1644544,1646592,1648640,1650688,1652736,1654784,1656832,1658880,1660928,1662976,1665024,1667072,1669120,1671168,1673216,1675264,1677312,1679360,1681408,1683456,1685504,1687552,1689600,1691648,1693696,1695744,1697792,1699840,1701888,1703936,1705984,1708032,1710080,1712128,1714176,1716224,1718272,1720320,1722368,1724416,1726464,1728512,1730560,1732608,1734656,1736704,1738752,1740800,1742848,1744896,1746944,1748992,1751040,1753088,1755136,1757184,1759232,1761280,1763328,1765376,1767424,1769472,1771520,1773568,1775616,1777664,1779712,1781760,1783808,1785856,1787904,1789952,1792000,1794048,1796096,1798144,1800192,1802240,1804288,1806336,1808384,1810432,1812480,1814528,1816576,1818624,1820672,1822720,1824768,1826816,1828864,1830912,1832960,1835008,1837056,1839104,1841152,1843200,1845248,1847296,1849344,1851392,1853440,1855488,1857536,1859584,1861632,1863680,1865728,1867776,1869824,1871872,1873920,1875968,1878016,1880064,1882112,1884160,1886208,1888256,1890304,1892352,1894400,1896448,1898496,1900544,1902592,1904640,1906688,1908736,1910784,1912832,1914880,1916928,1918976,1921024,1923072,1925120,1927168,1929216,1931264,1933312,1935360,1937408,1939456,1941504,1943552,1945600,1947648,1949696,1951744,1953792,1955840,1957888,1959936,1961984,1964032,1966080,1968128,1970176,1972224,1974272,1976320,1978368,1980416,1982464,1984512,1986560,1988608,1990656,1992704,1994752,1996800,1998848,2000896,2002944,2004992,2007040,2009088,2011136,2013184,2015232,2017280,2019328,2021376,2023424,2025472,2027520,2029568,2031616,2033664,2035712,2037760,2039808,2041856,2043904,2045952,2048000,2050048],\"xaxis\":\"x\",\"y\":[10.893806457519531,10.427045822143555,9.634830474853516,10.264103889465332,9.31908893585205,9.114545822143555,8.989713668823242,9.26657485961914,9.180978775024414,9.055776596069336,8.61603832244873,8.559957504272461,7.807898998260498,7.91976261138916,8.070566177368164,8.144721031188965,6.628560543060303,7.808859348297119,7.625852584838867,8.305569648742676,7.4169535636901855,8.14185905456543,7.313915252685547,7.433940410614014,7.547981262207031,7.983862400054932,7.127997875213623,8.078697204589844,7.674922943115234,7.675109386444092,7.434235095977783,6.662626266479492,7.124334335327148,7.280995845794678,8.049904823303223,7.849207878112793,7.362364292144775,7.178154945373535,7.463449954986572,7.016193866729736,7.165964603424072,7.815927982330322,7.132492542266846,7.43367862701416,6.771230220794678,7.732711315155029,7.033417224884033,7.152134895324707,7.452767848968506,5.829916477203369,5.914529323577881,7.554685115814209,6.6695756912231445,7.587604522705078,6.977630138397217,5.184032440185547,6.905055522918701,6.271007061004639,7.990111827850342,7.912749767303467,7.301448822021484,6.28422212600708,6.436372756958008,7.807494640350342,5.948660850524902,7.79941987991333,6.602100849151611,6.598696231842041,7.384997844696045,5.916327953338623,7.766610622406006,6.166258335113525,6.354918003082275,6.029428482055664,5.2543721199035645,6.982370376586914,6.40958833694458,7.218695640563965,5.283820629119873,7.403279781341553,7.551144599914551,7.717860221862793,7.281604766845703,6.9039106369018555,6.831348896026611,7.377828598022461,7.305034637451172,6.493904113769531,7.502947807312012,7.475921630859375,6.264326095581055,7.900688171386719,6.392958641052246,5.9810099601745605,6.367247104644775,6.246963977813721,5.692319393157959,7.359583377838135,7.038933753967285,7.6092376708984375,7.183945655822754,5.9209113121032715,6.992689609527588,7.349926948547363,6.442592620849609,6.999311923980713,6.716317176818848,7.594215393066406,6.622709274291992,6.699754238128662,5.393760681152344,7.043684482574463,6.514898300170898,6.696376323699951,6.69824743270874,6.460135459899902,7.281935214996338,7.212729454040527,7.594583511352539,7.138926982879639,7.3348188400268555,7.189274311065674,6.738702774047852,6.5225324630737305,6.949594497680664,7.422399520874023,7.410975456237793,6.666720867156982,6.22360372543335,7.085495948791504,5.923482418060303,7.522467136383057,6.361387729644775,5.82284688949585,6.317162036895752,6.981962203979492,7.379582405090332,7.258055686950684,6.434112071990967,7.474478244781494,6.024131774902344,6.669892311096191,6.059913158416748,6.535154342651367,7.081905364990234,6.6076836585998535,7.319371223449707,5.877340316772461,5.5880937576293945,6.722639083862305,6.517719745635986,6.36610221862793,7.354548454284668,6.7593159675598145,6.2848405838012695,7.1035966873168945,6.770442008972168,6.092446327209473,6.611698150634766,7.249154090881348,7.035548210144043,7.410935878753662,6.4828386306762695,7.404731750488281,7.463119983673096,7.264775276184082,7.030026912689209,6.849971771240234,7.444589138031006,5.312416076660156,6.035064220428467,7.059691429138184,6.277189254760742,5.8443074226379395,6.416632652282715,7.28755521774292,6.559230327606201,6.728107929229736,6.1987409591674805,7.212503910064697,6.751069068908691,7.469141960144043,7.459601879119873,7.349392414093018,6.170513153076172,7.395143032073975,7.279488563537598,6.692648410797119,7.316223621368408,6.771309852600098,5.905599594116211,6.544557094573975,5.2595744132995605,6.352523326873779,6.099898815155029,6.16761589050293,7.125868797302246,6.7148237228393555,5.997227668762207,6.733247756958008,6.214476585388184,6.407529830932617,7.264333724975586,6.977560520172119,6.015833854675293,5.969151020050049,7.000478267669678,7.178333759307861,6.263494968414307,7.6479105949401855,5.736992835998535,7.1781744956970215,6.309168338775635,6.672365188598633,5.365495204925537,7.181882381439209,7.348421573638916,6.74544620513916,7.177699565887451,6.935952186584473,6.941099643707275,6.934011936187744,5.753427982330322,6.674023628234863,5.459040641784668,6.063246250152588,6.395949363708496,7.373455047607422,6.879143238067627,7.1031951904296875,6.42634916305542,7.1864447593688965,6.8405632972717285,3.5708701610565186,7.0937581062316895,6.570587635040283,6.882235050201416,7.279861927032471,6.178062915802002,7.118537902832031,6.493494033813477,5.847645282745361,5.426514148712158,7.372856616973877,6.965512275695801,5.870194911956787,6.197558403015137,6.458340644836426,6.9095778465271,6.297845363616943,6.318068504333496,6.843086242675781,6.492095947265625,6.620027542114258,6.984341144561768,6.305624961853027,6.843216896057129,6.46617317199707,6.985827922821045,6.762999057769775,6.4933013916015625,6.540491104125977,6.23700475692749,6.200334072113037,5.087399005889893,6.061723709106445,6.203706741333008,5.4813008308410645,6.1341447830200195,6.042251110076904,5.891076564788818,6.780318260192871,6.889206886291504,7.024605751037598,6.477628707885742,5.8595051765441895,5.17009973526001,6.039463520050049,6.932980060577393,6.82629919052124,6.837954044342041,7.210803985595703,7.130180358886719,7.339724540710449,5.242691516876221,7.033135890960693,6.220620155334473,6.3562774658203125,6.419381618499756,7.239526748657227,7.125497341156006,6.268826961517334,6.306741714477539,6.266530990600586,6.408555030822754,6.608877658843994,7.197091579437256,7.300697326660156,6.535238742828369,6.545780181884766,6.591123104095459,6.527737617492676,5.379087448120117,5.816311836242676,6.979439735412598,6.299715042114258,6.738414764404297,6.83601713180542,6.863978862762451,6.356145858764648,5.8859100341796875,6.475433349609375,7.122377872467041,6.07142448425293,6.694138526916504,5.902716636657715,5.306896686553955,6.100412845611572,6.454117774963379,6.785376071929932,6.912567138671875,5.604643821716309,7.153719425201416,6.470905780792236,6.952639102935791,5.539736270904541,6.790310382843018,6.9054856300354,6.2068681716918945,6.471749782562256,6.596714019775391,6.819143295288086,5.786790370941162,5.1841535568237305,5.967902183532715,6.736931800842285,5.688403129577637,6.72953987121582,6.925650119781494,5.920834541320801,6.706357479095459,6.801548480987549,6.692095756530762,6.381126880645752,5.92860221862793,7.283708095550537,6.068110466003418,6.476272106170654,5.462843894958496,5.8082685470581055,6.196161270141602,5.988715648651123,7.031335830688477,5.655581474304199,6.302164077758789,6.990185260772705,6.657060146331787,5.792215824127197,5.712269306182861,5.634867191314697,5.756242752075195,6.833441734313965,6.653871059417725,6.184776782989502,6.141414642333984,6.0818586349487305,6.62661600112915,6.63861083984375,6.139286994934082,5.828361988067627,5.95382833480835,6.8002848625183105,6.97227668762207,6.524081230163574,6.48838996887207,4.758155822753906,6.398387908935547,6.102293968200684,6.068881511688232,5.9436821937561035,6.9621195793151855,5.715623378753662,7.000760555267334,5.76843786239624,5.78002405166626,5.549404621124268,5.251672267913818,6.037641525268555,5.882079601287842,5.322067737579346,7.192586421966553,5.651959419250488,6.422826290130615,6.721909046173096,6.212947845458984,6.5321269035339355,6.26345157623291,5.321763038635254,6.853144645690918,5.9502129554748535,6.240609169006348,7.064380168914795,7.060173511505127,5.434298515319824,5.713833808898926,5.35958194732666,7.389200687408447,6.6098551750183105,5.971768379211426,6.044561862945557,6.879286766052246,5.353652477264404,7.192244529724121,5.155861854553223,6.459859848022461,6.823322772979736,5.7928643226623535,6.195549964904785,6.129689693450928,5.382623195648193,6.791993618011475,7.066790580749512,6.2079668045043945,5.869408130645752,4.974715709686279,3.9946670532226562,7.120031356811523,6.764587879180908,5.174720764160156,5.589199542999268,5.667579650878906,5.988559246063232,6.569380283355713,6.821842670440674,6.315308094024658,6.189703464508057,6.124805450439453,7.062331199645996,4.86233377456665,6.8343024253845215,6.483643531799316,6.55932092666626,5.6199116706848145,4.8574137687683105,6.9304399490356445,6.953507900238037,6.775815010070801,6.817715167999268,6.5624260902404785,5.681647777557373,5.837902545928955,5.0996479988098145,6.8481268882751465,6.1209235191345215,6.820996284484863,6.056341648101807,6.095166206359863,6.61842679977417,5.438260078430176,5.6815290451049805,5.080475807189941,6.436587333679199,5.884406089782715,5.9520978927612305,5.5276665687561035,6.096118927001953,6.399137020111084,4.965343952178955,6.128511428833008,7.015021324157715,5.319487571716309,6.856664180755615,6.083608150482178,6.367321968078613,5.843657493591309,6.4260478019714355,6.378108978271484,6.459695339202881,6.6272759437561035,6.059246063232422,5.8577470779418945,6.326718807220459,5.700711727142334,6.2530927658081055,6.536418914794922,5.880959987640381,6.49962043762207,6.309074401855469,5.8287248611450195,5.960597991943359,6.050961494445801,5.545186519622803,6.5997138023376465,5.92969274520874,6.413270950317383,6.187255382537842,6.180765151977539,6.33779239654541,6.12028694152832,6.397641181945801,5.3044657707214355,6.83604621887207,6.510043621063232,6.346192836761475,6.65885066986084,6.221997261047363,6.662997245788574,5.459427833557129,6.85530948638916,5.3961591720581055,5.622014045715332,5.986109733581543,6.281040191650391,5.967301845550537,6.529374599456787,6.527423858642578,5.974690914154053,6.404294490814209,5.865479469299316,5.839770317077637,5.659456729888916,6.732898235321045,5.857100009918213,6.750272750854492,6.411985397338867,6.792856216430664,6.249256134033203,6.093013286590576,6.611140727996826,5.683406829833984,5.102623462677002,6.719038963317871,6.895438194274902,6.569279670715332,6.300320148468018,6.2968339920043945,6.411684036254883,6.303232669830322,6.670129299163818,6.057904243469238,6.274672031402588,5.103349208831787,6.7471022605896,6.320355415344238,6.9138264656066895,4.943398952484131,5.276199817657471,6.158751487731934,6.529575824737549,6.511270999908447,6.563686847686768,6.825718402862549,6.0076751708984375,5.515554428100586,6.78159236907959,4.525760650634766,5.7860331535339355,6.884456634521484,4.664862155914307,6.475404262542725,5.991855621337891,5.9356369972229,6.793413162231445,6.159652233123779,6.055816650390625,6.205516815185547,5.20932149887085,6.274753570556641,5.284594535827637,4.9419779777526855,4.458980560302734,6.209834098815918,5.361738681793213,5.023915767669678,5.331613540649414,6.29410982131958,6.466154098510742,5.626280784606934,6.35620641708374,5.478240489959717,5.7116475105285645,5.892956256866455,6.420624256134033,5.794150352478027,5.921229839324951,6.869009017944336,6.1308183670043945,5.915657043457031,6.974363327026367,5.450153350830078,6.449761867523193,6.045516014099121,5.421005725860596,6.253221035003662,5.2270307540893555,6.376247406005859,6.1876349449157715,6.06260871887207,6.720747470855713,5.627060890197754,6.283331394195557,6.351734161376953,5.523952960968018,6.370999336242676,6.451564311981201,6.202211856842041,4.996163845062256,5.659505367279053,5.903824329376221,5.46745491027832,6.066342830657959,6.6164679527282715,4.496311187744141,6.918656349182129,6.374454021453857,6.624735355377197,6.1405181884765625,6.419637680053711,5.368797779083252,5.63762092590332,6.130258083343506,5.883955001831055,5.349919319152832,5.981701850891113,6.619306564331055,5.355196952819824,6.703455924987793,6.215742111206055,6.538422107696533,6.278171539306641,6.039126396179199,5.870230674743652,6.178444862365723,6.194089412689209,6.146444797515869,6.731659889221191,5.233891010284424,5.954592704772949,5.619664669036865,6.739044666290283,5.9534220695495605,6.210587978363037,6.765751361846924,6.739131450653076,5.395712852478027,6.435729503631592,6.559391021728516,6.6493916511535645,5.664209365844727,5.9365363121032715,5.80687952041626,6.157029628753662,6.582067012786865,5.272243976593018,6.387413024902344,6.019307613372803,5.77635383605957,5.32295036315918,5.941738128662109,6.576267242431641,5.763748645782471,5.9041008949279785,5.74242639541626,6.283062934875488,6.257469177246094,6.562018394470215,6.809732437133789,6.094371795654297,6.236048221588135,4.181057929992676,6.251044273376465,6.477835178375244,6.046085357666016,5.837491512298584,6.458290100097656,5.670943260192871,5.2971978187561035,6.108110427856445,5.750730991363525,5.690359115600586,6.7756781578063965,5.08757209777832,6.263877868652344,6.261489391326904,5.932858467102051,6.66238260269165,5.9046430587768555,6.724463939666748,5.962268829345703,6.093897342681885,5.88328742980957,6.031794548034668,5.620194911956787,6.442348957061768,6.230268955230713,5.84187650680542,6.334973335266113,6.030936241149902,6.146600246429443,5.107158660888672,5.6236724853515625,6.439016342163086,6.273532390594482,6.079730033874512,5.274417877197266,5.807642459869385,5.274596214294434,5.956326961517334,6.173469543457031,6.205816745758057,5.946310997009277,5.619250297546387,7.0108642578125,6.019609451293945,6.104399681091309,5.485321998596191,6.42507791519165,6.118117332458496,5.677605628967285,6.27752685546875,5.981806755065918,5.951730251312256,6.593650817871094,5.710947036743164,5.852570056915283,5.670546054840088,6.290445327758789,5.928374290466309,6.097687244415283,6.00021505355835,3.711148977279663,6.25396728515625,5.271996021270752,5.282454967498779,6.487525463104248,6.3335957527160645,5.35158109664917,5.694026470184326,6.299812316894531,6.349177837371826,6.209733486175537,6.428217887878418,5.592421531677246,5.482235431671143,5.584145545959473,5.41577672958374,6.766429424285889,5.789606094360352,5.375753402709961,6.307466506958008,6.318812370300293,6.481020450592041,5.817994594573975,6.273177623748779,6.722898006439209,5.338503837585449,6.670080661773682,5.980781078338623,5.287014007568359,5.842097282409668,5.419844627380371,5.756831645965576,5.9169745445251465,5.530550479888916,6.213921070098877,6.109903812408447,5.853615760803223,6.207830429077148,5.492738246917725,6.175370216369629,3.9055612087249756,6.336564064025879,4.95462703704834,5.901712417602539,5.375865936279297,5.625036716461182,4.983633518218994,6.198032855987549,5.082873344421387,4.950484752655029,5.829664707183838,5.235795497894287,6.1329569816589355,5.456839084625244,5.522766590118408,5.183165073394775,5.625036716461182,5.867244720458984,5.701903820037842,6.661999702453613,6.231913089752197,6.1269636154174805,4.888288974761963,5.385567665100098,5.985903263092041,6.738123893737793,5.537220478057861,5.86268424987793,6.744391441345215,6.640661716461182,5.472293853759766,5.546179294586182,5.534297943115234,6.367386341094971,5.67014741897583,6.480928897857666,5.720998287200928,6.059472560882568,5.823733806610107,4.560082912445068,5.55682373046875,4.636996746063232,5.792925834655762,5.952547550201416,5.223880290985107,6.596568584442139,6.045695781707764,5.875568866729736,6.208745956420898,6.532783508300781,6.210654258728027,6.346561908721924,6.338615894317627,5.9337358474731445,6.433508396148682,6.319293975830078,5.811450004577637,5.49641752243042,5.907059192657471,5.746159553527832,6.503262519836426,5.756721496582031,6.488044738769531,6.117894649505615,5.86445426940918,5.835223197937012,5.549563884735107,5.330730438232422,4.362559795379639,5.012577056884766,5.569671630859375,6.176525592803955,5.664442539215088,6.331360340118408,5.243968486785889,5.100625514984131,6.374338150024414,6.497174263000488,5.70150899887085,5.64119291305542,5.607527732849121,5.71267557144165,6.280437469482422,5.915352821350098,5.677097320556641,6.360349178314209,6.265502452850342,6.178948402404785,5.341156482696533,5.870170593261719,5.4451117515563965,6.241472244262695,5.314521312713623,4.9461517333984375,6.680211544036865,6.917564868927002,6.49563455581665,6.11849308013916,5.478568077087402,6.257815837860107,6.127716064453125,5.675842761993408,6.210302829742432,6.548689842224121,5.86232852935791,5.740886688232422,6.508115768432617,5.909424304962158,6.129854679107666,5.92615270614624,6.129012107849121,5.991880416870117,6.622316837310791,5.540594577789307,6.060328006744385,5.931400775909424,6.792439937591553,5.400372505187988,5.405616283416748,5.465909481048584,5.291983127593994,6.062725067138672,5.695817470550537,6.294777870178223,6.29988431930542,6.702127933502197,5.836272239685059,6.2906880378723145,5.82119083404541,6.386631965637207,3.914015293121338,4.600915431976318,5.786273956298828,5.965373516082764,5.688570022583008,5.874922752380371,5.608105659484863,6.473889350891113,6.068475246429443,5.559708118438721,6.369912147521973,5.660721302032471,6.10959529876709,5.171573162078857,5.885856628417969,6.098738670349121,5.7309136390686035,6.036271095275879,5.380069732666016,6.102173805236816,4.849461078643799,5.115664958953857,6.431756019592285,6.017018795013428,6.432150363922119,5.532230377197266,5.253816604614258,6.474475860595703,3.9770805835723877,6.072547912597656,5.884472370147705,6.253187656402588,5.945555686950684,6.096212863922119,6.4258246421813965,5.689128875732422,6.403471946716309,5.640111446380615,6.316356658935547,5.253259658813477,3.884716033935547,5.994566440582275,6.261377334594727,6.544004917144775,5.812011241912842,5.568344593048096,6.187015056610107,6.731874465942383,4.954038619995117,5.797821044921875,6.174631595611572,4.538426399230957,6.5726213455200195,4.4626264572143555,5.83879280090332,6.313039302825928,5.421074867248535,5.935083389282227,4.370193004608154,6.679178714752197,6.659379959106445,6.706349849700928,5.316075325012207,5.927857875823975,5.195620536804199,5.5007004737854,6.650441646575928,6.306372165679932,6.594603538513184,4.7035698890686035,4.553125381469727,6.798477649688721,5.679795265197754,5.9527788162231445,4.551840305328369,5.673043251037598,6.304561614990234,6.020262241363525,6.0588297843933105,5.522863388061523,5.2381768226623535,6.00363302230835,6.389254570007324,5.4175825119018555,6.422732830047607,5.610039234161377,5.911554336547852,5.2098002433776855,5.918560028076172,5.055022239685059,6.686042308807373,5.942429542541504,5.942678928375244,5.244865894317627,6.026693344116211,6.240598678588867,4.710692405700684,5.621710777282715,5.577942371368408,5.0781660079956055,5.779727458953857,4.423628330230713],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tokens\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Training curve for my tiny demo model!\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d657c504-b9c0-4f64-b88a-1888977a57e1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "px.line(y=losses, x=np.arange(len(losses))*(model_cfg.n_ctx * batch_size), labels={\"y\":\"Loss\", \"x\":\"Tokens\"}, title=\"Training curve for my tiny demo model!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e350ea361a934380ac41178c2b1a40e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81f5b33c5b2d451ca5287a8196a560b0",
              "IPY_MODEL_76e78432ed9243a292f1d240f7a9c703",
              "IPY_MODEL_a14ea57bca2846d2b4175d0fcefa942f"
            ],
            "layout": "IPY_MODEL_e0250213510345439f1cc14fbebe59ab"
          }
        },
        "81f5b33c5b2d451ca5287a8196a560b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3390ff6b7844b24aa8f1a5471be3ffd",
            "placeholder": "​",
            "style": "IPY_MODEL_27231e1cb0d14ba49941d74c4cd9f83d",
            "value": "config.json: 100%"
          }
        },
        "76e78432ed9243a292f1d240f7a9c703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3775ea8db2a4a248b28b103965c9334",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1697750c8154d61954362b2d216e7ca",
            "value": 665
          }
        },
        "a14ea57bca2846d2b4175d0fcefa942f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fa31950055e491fbf3b9608aad8ebd3",
            "placeholder": "​",
            "style": "IPY_MODEL_46bf3bf765e849979828f18f6090ebe7",
            "value": " 665/665 [00:00&lt;00:00, 21.0kB/s]"
          }
        },
        "e0250213510345439f1cc14fbebe59ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3390ff6b7844b24aa8f1a5471be3ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27231e1cb0d14ba49941d74c4cd9f83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3775ea8db2a4a248b28b103965c9334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1697750c8154d61954362b2d216e7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fa31950055e491fbf3b9608aad8ebd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46bf3bf765e849979828f18f6090ebe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78d5853f3df3417ca3c628dfeb812e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d16d03a4cf564cfda346f7ec93547805",
              "IPY_MODEL_c05706a97cf240a48cb179f38e72837b",
              "IPY_MODEL_517241dd6a394400b35af1ccbc809a9b"
            ],
            "layout": "IPY_MODEL_c6e7b280110e420d956ddb71479883bb"
          }
        },
        "d16d03a4cf564cfda346f7ec93547805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b34c62871f447dd9d940207e05172ce",
            "placeholder": "​",
            "style": "IPY_MODEL_c15d59735dfe41c48f3140b8b5f2fc53",
            "value": "model.safetensors: 100%"
          }
        },
        "c05706a97cf240a48cb179f38e72837b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aefee8a74a9f49479faee58da5f56ba1",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfe978621ee74252ab4cdbef6299afb8",
            "value": 548105171
          }
        },
        "517241dd6a394400b35af1ccbc809a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_185bbf12618943cbabde24c5efb1d33d",
            "placeholder": "​",
            "style": "IPY_MODEL_97292055711546728224d1685e54a228",
            "value": " 548M/548M [00:07&lt;00:00, 105MB/s]"
          }
        },
        "c6e7b280110e420d956ddb71479883bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b34c62871f447dd9d940207e05172ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15d59735dfe41c48f3140b8b5f2fc53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aefee8a74a9f49479faee58da5f56ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe978621ee74252ab4cdbef6299afb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "185bbf12618943cbabde24c5efb1d33d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97292055711546728224d1685e54a228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71e85282d8704611b2755d6b5557cd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9071366ce5df47d7b5e261e811d5a765",
              "IPY_MODEL_6093ffece0e745a9b5d6e5a6ab7d7bce",
              "IPY_MODEL_982d4071738041e78570210f208e5433"
            ],
            "layout": "IPY_MODEL_84165e13f8c641c4b57b5e679a0a07cf"
          }
        },
        "9071366ce5df47d7b5e261e811d5a765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779c1b4cdfc3487a88213de9c8e0020e",
            "placeholder": "​",
            "style": "IPY_MODEL_17c4498a4fff4b9eb634e52953de249c",
            "value": "generation_config.json: 100%"
          }
        },
        "6093ffece0e745a9b5d6e5a6ab7d7bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d733d4f1585746f7863298db594c9621",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43826b8d8c404adbbbdda96ecc661a1a",
            "value": 124
          }
        },
        "982d4071738041e78570210f208e5433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7565ee864dcf4405b4fd38cfc45f5561",
            "placeholder": "​",
            "style": "IPY_MODEL_18ac3aa29ff04bf18290633cacef0943",
            "value": " 124/124 [00:00&lt;00:00, 6.50kB/s]"
          }
        },
        "84165e13f8c641c4b57b5e679a0a07cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "779c1b4cdfc3487a88213de9c8e0020e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c4498a4fff4b9eb634e52953de249c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d733d4f1585746f7863298db594c9621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43826b8d8c404adbbbdda96ecc661a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7565ee864dcf4405b4fd38cfc45f5561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ac3aa29ff04bf18290633cacef0943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4dfbc5d2b72488ea1a7c2f771fa6ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a52eb32defb34bc3b5841cbc4c5978cb",
              "IPY_MODEL_6cd51362b79547e28ae344a43e04f71e",
              "IPY_MODEL_e3fdca0d4f4743d4aebedcf705968186"
            ],
            "layout": "IPY_MODEL_36965bc3e4754d288fcb0845e87c3ce5"
          }
        },
        "a52eb32defb34bc3b5841cbc4c5978cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96edc89a81384cf69562b705d0b80142",
            "placeholder": "​",
            "style": "IPY_MODEL_1b953172cb5d4fab8fd7e119042b29de",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6cd51362b79547e28ae344a43e04f71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22842655b2b6441b9d8bb2b3939cb37b",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_690d3797228d4bedbd70409a1065e08b",
            "value": 26
          }
        },
        "e3fdca0d4f4743d4aebedcf705968186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f36f9c4421d4039b62bc4074e9c343b",
            "placeholder": "​",
            "style": "IPY_MODEL_902efca414644cf18e73f023a3e4266d",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.15kB/s]"
          }
        },
        "36965bc3e4754d288fcb0845e87c3ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96edc89a81384cf69562b705d0b80142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b953172cb5d4fab8fd7e119042b29de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22842655b2b6441b9d8bb2b3939cb37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "690d3797228d4bedbd70409a1065e08b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f36f9c4421d4039b62bc4074e9c343b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "902efca414644cf18e73f023a3e4266d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "331407cd9bb0475590e3938a704e02e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b8e5d6cfef945938f3d5b2d45194393",
              "IPY_MODEL_b491f576cc504b3796e35aed1a7624e0",
              "IPY_MODEL_bb2b0ba3aac34ae4b954f61320185ee1"
            ],
            "layout": "IPY_MODEL_aa53e49920e84e53a8cda4bff64dba45"
          }
        },
        "9b8e5d6cfef945938f3d5b2d45194393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc18ddd6414447d5aef1cfffe1e1592a",
            "placeholder": "​",
            "style": "IPY_MODEL_5c3bdaeca2134f01a6f2445e79dd42fb",
            "value": "vocab.json: 100%"
          }
        },
        "b491f576cc504b3796e35aed1a7624e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d87cc1346d4afca60285fd2bfaafee",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f73e341b42e417ca66e73fcbe2d0eb8",
            "value": 1042301
          }
        },
        "bb2b0ba3aac34ae4b954f61320185ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2725dbbdf6347fea93a7045d9156f7f",
            "placeholder": "​",
            "style": "IPY_MODEL_26f1f91dc32f4fbf84405262a80b89a1",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.91MB/s]"
          }
        },
        "aa53e49920e84e53a8cda4bff64dba45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc18ddd6414447d5aef1cfffe1e1592a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3bdaeca2134f01a6f2445e79dd42fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24d87cc1346d4afca60285fd2bfaafee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f73e341b42e417ca66e73fcbe2d0eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2725dbbdf6347fea93a7045d9156f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f1f91dc32f4fbf84405262a80b89a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "673657205482432b9c439a44f4120b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b679d30b84914eef84327fc756b262d7",
              "IPY_MODEL_6af0ffe555254c99bc743f27238473be",
              "IPY_MODEL_fa485ba66b3a41a5acdd9431415f3d44"
            ],
            "layout": "IPY_MODEL_1f1f6be7bbd740da84a8c5a7975edf27"
          }
        },
        "b679d30b84914eef84327fc756b262d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb46f5dbfd4e4afdb9a95ad44a0ff02a",
            "placeholder": "​",
            "style": "IPY_MODEL_f7f94e105fa94b008eeff37aa20cbaee",
            "value": "merges.txt: 100%"
          }
        },
        "6af0ffe555254c99bc743f27238473be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1473390d9540e0b662d46f88c4de80",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_420e0556bd5c4a1ab6a779fa27f0b6ac",
            "value": 456318
          }
        },
        "fa485ba66b3a41a5acdd9431415f3d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cffe27cedc30476b937694b267dda50c",
            "placeholder": "​",
            "style": "IPY_MODEL_630405df26c942d38f91cf729430ba8a",
            "value": " 456k/456k [00:00&lt;00:00, 1.25MB/s]"
          }
        },
        "1f1f6be7bbd740da84a8c5a7975edf27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb46f5dbfd4e4afdb9a95ad44a0ff02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7f94e105fa94b008eeff37aa20cbaee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c1473390d9540e0b662d46f88c4de80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420e0556bd5c4a1ab6a779fa27f0b6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cffe27cedc30476b937694b267dda50c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630405df26c942d38f91cf729430ba8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4452ee3fef694cd9a54e32cbdf6bd975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e98c365a794941cc9709bc4863908fd5",
              "IPY_MODEL_98f4df64bdb443cb8ef1d2595c034aab",
              "IPY_MODEL_023428caccaf4f909dee864e40849786"
            ],
            "layout": "IPY_MODEL_0021e097667b4a8bb1f1a30be6ef6050"
          }
        },
        "e98c365a794941cc9709bc4863908fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c017c7859ea4ce592059860c37dc0b4",
            "placeholder": "​",
            "style": "IPY_MODEL_42735bfcbddb4c1eb7d5f4ea64ee6dc3",
            "value": "tokenizer.json: 100%"
          }
        },
        "98f4df64bdb443cb8ef1d2595c034aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b75c72de4c451d9287c17092c9193d",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1119f18e738c4ff69bc1416d43f73f04",
            "value": 1355256
          }
        },
        "023428caccaf4f909dee864e40849786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a645f7fce0e42e7bb1556c966bcdb9c",
            "placeholder": "​",
            "style": "IPY_MODEL_050257aa8ae8405d8b19bfb8ff5c7e88",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 7.42MB/s]"
          }
        },
        "0021e097667b4a8bb1f1a30be6ef6050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c017c7859ea4ce592059860c37dc0b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42735bfcbddb4c1eb7d5f4ea64ee6dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9b75c72de4c451d9287c17092c9193d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1119f18e738c4ff69bc1416d43f73f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a645f7fce0e42e7bb1556c966bcdb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050257aa8ae8405d8b19bfb8ff5c7e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}